{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym.spaces.discrete import Discrete\n",
    "from gym_sokoban.envs import SokobanEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.dqn.policies import CnnPolicy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SokobanEnvFixated(SokobanEnv): \n",
    "    def __init__(self):\n",
    "        SokobanEnv.__init__(self,\n",
    "                            dim_room=(10, 10), \n",
    "                            max_steps=100, \n",
    "                            num_boxes=4, \n",
    "                            num_gen_steps=None, \n",
    "                            reset=False)\n",
    "        self.action_space = Discrete(5) # limit to push actions\n",
    "\n",
    "    def reset(self, second_player=False, render_mode='rgb_array'):\n",
    "\n",
    "        self.room_fixed = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 0, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "                                    [0, 1, 1, 1, 1, 2, 1, 1, 1, 0],\n",
    "                                    [0, 1, 1, 1, 2, 1, 1, 1, 1, 0],\n",
    "                                    [0, 1, 1, 1, 0, 1, 1, 2, 1, 0],\n",
    "                                    [0, 2, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "        self.room_state = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 0, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "                                    [0, 1, 1, 4, 5, 2, 1, 1, 1, 0],\n",
    "                                    [0, 1, 1, 1, 2, 4, 1, 4, 1, 0],\n",
    "                                    [0, 1, 1, 1, 0, 1, 1, 2, 1, 0],\n",
    "                                    [0, 2, 4, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "        self.box_mapping = {(6, 7): (5, 7), (5, 4): (5, 5), (4, 5): (4, 3), (7, 1): (7, 2)}\n",
    "\n",
    "        self.player_position = np.argwhere(self.room_state == 5)[0]\n",
    "        self.num_env_steps = 0\n",
    "        self.reward_last = 0\n",
    "        self.boxes_on_target = 0\n",
    "\n",
    "        starting_observation = self.render(render_mode)\n",
    "        return starting_observation # Close environment after testing\n",
    "\n",
    "def render_state(env, mode=\"rgb_array\"):\n",
    "    \"\"\"Renders the Sokoban environment as image and displays it.\"\"\"\n",
    "    image = env.render(mode)\n",
    "\n",
    "    plt.figure(dpi=200) \n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roger\\Documents\\Projekte\\vm-code-generation-with-knowledge-graph\\venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "c:\\Users\\roger\\Documents\\Projekte\\vm-code-generation-with-knowledge-graph\\venv\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 15.36GB > 4.89GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tensorboard_logs/log_sokoban_dqn_fixated_env_2_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roger\\Documents\\Projekte\\vm-code-generation-with-knowledge-graph\\venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "c:\\Users\\roger\\Documents\\Projekte\\vm-code-generation-with-knowledge-graph\\venv\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x000002833107C760> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000283030C8F40>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 400      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roger\\Documents\\Projekte\\vm-code-generation-with-knowledge-graph\\venv\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 800      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 1200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3e-05    |\n",
      "|    n_updates        | 49       |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.74e-06 |\n",
      "|    n_updates        | 124      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.94    |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 1600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.22e-05 |\n",
      "|    n_updates        | 149      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.82e-05 |\n",
      "|    n_updates        | 249      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 2000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.83    |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 2400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.58e-05 |\n",
      "|    n_updates        | 349      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e-05 |\n",
      "|    n_updates        | 374      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.86    |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 2800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000259 |\n",
      "|    n_updates        | 449      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.27e-05 |\n",
      "|    n_updates        | 499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.81    |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 3200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.27e-05 |\n",
      "|    n_updates        | 549      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00783  |\n",
      "|    n_updates        | 624      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.81    |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 3600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.08e-05 |\n",
      "|    n_updates        | 649      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000108 |\n",
      "|    n_updates        | 749      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 4000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 370      |\n",
      "|    total_timesteps  | 4400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 849      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000189 |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.81    |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 407      |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000179 |\n",
      "|    n_updates        | 949      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000154 |\n",
      "|    n_updates        | 999      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.81    |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 447      |\n",
      "|    total_timesteps  | 5200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000257 |\n",
      "|    n_updates        | 1049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 1124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 482      |\n",
      "|    total_timesteps  | 5600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000187 |\n",
      "|    n_updates        | 1149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 1249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 519      |\n",
      "|    total_timesteps  | 6000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 541      |\n",
      "|    total_timesteps  | 6400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000277 |\n",
      "|    n_updates        | 1349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000579 |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 581      |\n",
      "|    total_timesteps  | 6800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000104 |\n",
      "|    n_updates        | 1449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000118 |\n",
      "|    n_updates        | 1499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 616      |\n",
      "|    total_timesteps  | 7200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.36e-05 |\n",
      "|    n_updates        | 1549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000199 |\n",
      "|    n_updates        | 1624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.79    |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 652      |\n",
      "|    total_timesteps  | 7600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.84e-05 |\n",
      "|    n_updates        | 1649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0002   |\n",
      "|    n_updates        | 1749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.79    |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 691      |\n",
      "|    total_timesteps  | 8000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 713      |\n",
      "|    total_timesteps  | 8400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 1849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000322 |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.81    |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 750      |\n",
      "|    total_timesteps  | 8800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00019  |\n",
      "|    n_updates        | 1949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000201 |\n",
      "|    n_updates        | 1999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 785      |\n",
      "|    total_timesteps  | 9200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.75e-05 |\n",
      "|    n_updates        | 2049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000252 |\n",
      "|    n_updates        | 2124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 825      |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000128 |\n",
      "|    n_updates        | 2149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.16e-05 |\n",
      "|    n_updates        | 2249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.83    |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 859      |\n",
      "|    total_timesteps  | 10000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 882      |\n",
      "|    total_timesteps  | 10400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 2349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 918      |\n",
      "|    total_timesteps  | 10800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 2449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 11000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000635 |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 953      |\n",
      "|    total_timesteps  | 11200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000428 |\n",
      "|    n_updates        | 2549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=11500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 11500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 2624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 988      |\n",
      "|    total_timesteps  | 11600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0068   |\n",
      "|    n_updates        | 2649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000987 |\n",
      "|    n_updates        | 2749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.79    |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1032     |\n",
      "|    total_timesteps  | 12000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1056     |\n",
      "|    total_timesteps  | 12400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 2849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=12500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000373 |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1091     |\n",
      "|    total_timesteps  | 12800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000168 |\n",
      "|    n_updates        | 2949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=13000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 13000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000533 |\n",
      "|    n_updates        | 2999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1127     |\n",
      "|    total_timesteps  | 13200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000692 |\n",
      "|    n_updates        | 3049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=13500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 13500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000558 |\n",
      "|    n_updates        | 3124     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1166     |\n",
      "|    total_timesteps  | 13600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000252 |\n",
      "|    n_updates        | 3149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000998 |\n",
      "|    n_updates        | 3249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1207     |\n",
      "|    total_timesteps  | 14000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1229     |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00014  |\n",
      "|    n_updates        | 3349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=14500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 14500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000145 |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.74    |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1269     |\n",
      "|    total_timesteps  | 14800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000362 |\n",
      "|    n_updates        | 3449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000187 |\n",
      "|    n_updates        | 3499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1304     |\n",
      "|    total_timesteps  | 15200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00052  |\n",
      "|    n_updates        | 3549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000262 |\n",
      "|    n_updates        | 3624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1343     |\n",
      "|    total_timesteps  | 15600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000181 |\n",
      "|    n_updates        | 3649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000358 |\n",
      "|    n_updates        | 3749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1382     |\n",
      "|    total_timesteps  | 16000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1404     |\n",
      "|    total_timesteps  | 16400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000118 |\n",
      "|    n_updates        | 3849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=16500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 16500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000589 |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1446     |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00013  |\n",
      "|    n_updates        | 3949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=17000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 17000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000205 |\n",
      "|    n_updates        | 3999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1482     |\n",
      "|    total_timesteps  | 17200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.13e-05 |\n",
      "|    n_updates        | 4049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=17500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 17500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000641 |\n",
      "|    n_updates        | 4124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1519     |\n",
      "|    total_timesteps  | 17600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.92e-05 |\n",
      "|    n_updates        | 4149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.7e-05  |\n",
      "|    n_updates        | 4249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1561     |\n",
      "|    total_timesteps  | 18000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1583     |\n",
      "|    total_timesteps  | 18400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000222 |\n",
      "|    n_updates        | 4349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=18500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 18500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000183 |\n",
      "|    n_updates        | 4374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1622     |\n",
      "|    total_timesteps  | 18800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000297 |\n",
      "|    n_updates        | 4449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 19000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.64e-05 |\n",
      "|    n_updates        | 4499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1661     |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000259 |\n",
      "|    n_updates        | 4549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=19500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 19500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000149 |\n",
      "|    n_updates        | 4624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1700     |\n",
      "|    total_timesteps  | 19600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.83e-05 |\n",
      "|    n_updates        | 4649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.85e-05 |\n",
      "|    n_updates        | 4749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1739     |\n",
      "|    total_timesteps  | 20000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1762     |\n",
      "|    total_timesteps  | 20400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00511  |\n",
      "|    n_updates        | 4849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 4874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1800     |\n",
      "|    total_timesteps  | 20800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00389  |\n",
      "|    n_updates        | 4949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 21000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.73    |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1840     |\n",
      "|    total_timesteps  | 21200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 5049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=21500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 21500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 5124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1874     |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 5149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 5249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1919     |\n",
      "|    total_timesteps  | 22000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1940     |\n",
      "|    total_timesteps  | 22400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000833 |\n",
      "|    n_updates        | 5349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=22500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 22500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 1984     |\n",
      "|    total_timesteps  | 22800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 5449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 23000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000696 |\n",
      "|    n_updates        | 5499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2026     |\n",
      "|    total_timesteps  | 23200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000616 |\n",
      "|    n_updates        | 5549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=23500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 23500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000337 |\n",
      "|    n_updates        | 5624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2060     |\n",
      "|    total_timesteps  | 23600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 5649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 5749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2102     |\n",
      "|    total_timesteps  | 24000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2123     |\n",
      "|    total_timesteps  | 24400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000881 |\n",
      "|    n_updates        | 5849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=24500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 24500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000434 |\n",
      "|    n_updates        | 5874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2167     |\n",
      "|    total_timesteps  | 24800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000657 |\n",
      "|    n_updates        | 5949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000558 |\n",
      "|    n_updates        | 5999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2207     |\n",
      "|    total_timesteps  | 25200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00041  |\n",
      "|    n_updates        | 6049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 6124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2243     |\n",
      "|    total_timesteps  | 25600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000503 |\n",
      "|    n_updates        | 6149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=26000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000374 |\n",
      "|    n_updates        | 6249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2283     |\n",
      "|    total_timesteps  | 26000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.79    |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2304     |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00045  |\n",
      "|    n_updates        | 6349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=26500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 26500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 6374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2346     |\n",
      "|    total_timesteps  | 26800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000238 |\n",
      "|    n_updates        | 6449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=27000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 27000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000298 |\n",
      "|    n_updates        | 6499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2388     |\n",
      "|    total_timesteps  | 27200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000587 |\n",
      "|    n_updates        | 6549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=27500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 27500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000745 |\n",
      "|    n_updates        | 6624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2423     |\n",
      "|    total_timesteps  | 27600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00941  |\n",
      "|    n_updates        | 6649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000308 |\n",
      "|    n_updates        | 6749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2464     |\n",
      "|    total_timesteps  | 28000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2485     |\n",
      "|    total_timesteps  | 28400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000427 |\n",
      "|    n_updates        | 6849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=28500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 28500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000366 |\n",
      "|    n_updates        | 6874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2528     |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000423 |\n",
      "|    n_updates        | 6949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=29000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 29000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000212 |\n",
      "|    n_updates        | 6999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2566     |\n",
      "|    total_timesteps  | 29200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000388 |\n",
      "|    n_updates        | 7049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=29500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 29500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00056  |\n",
      "|    n_updates        | 7124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2604     |\n",
      "|    total_timesteps  | 29600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 7149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 7249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.74    |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2646     |\n",
      "|    total_timesteps  | 30000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.73    |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2667     |\n",
      "|    total_timesteps  | 30400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 7349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 7374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2707     |\n",
      "|    total_timesteps  | 30800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 7449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=31000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 31000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00509  |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2748     |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 7549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=31500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 31500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 7624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2781     |\n",
      "|    total_timesteps  | 31600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 7649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 7749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2823     |\n",
      "|    total_timesteps  | 32000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2846     |\n",
      "|    total_timesteps  | 32400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00087  |\n",
      "|    n_updates        | 7849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=32500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 32500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 7874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.74    |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2885     |\n",
      "|    total_timesteps  | 32800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 7949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=33000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 33000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 7999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2926     |\n",
      "|    total_timesteps  | 33200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000848 |\n",
      "|    n_updates        | 8049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=33500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 33500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00077  |\n",
      "|    n_updates        | 8124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.73    |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 2969     |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 8149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 8249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3003     |\n",
      "|    total_timesteps  | 34000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.71    |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3036     |\n",
      "|    total_timesteps  | 34400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 8349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=34500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 34500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000982 |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3069     |\n",
      "|    total_timesteps  | 34800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000792 |\n",
      "|    n_updates        | 8449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000419 |\n",
      "|    n_updates        | 8499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.71    |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3113     |\n",
      "|    total_timesteps  | 35200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 8549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000607 |\n",
      "|    n_updates        | 8624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.71    |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3146     |\n",
      "|    total_timesteps  | 35600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000733 |\n",
      "|    n_updates        | 8649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00062  |\n",
      "|    n_updates        | 8749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.69    |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3191     |\n",
      "|    total_timesteps  | 36000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3212     |\n",
      "|    total_timesteps  | 36400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00076  |\n",
      "|    n_updates        | 8849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=36500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 36500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000352 |\n",
      "|    n_updates        | 8874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3253     |\n",
      "|    total_timesteps  | 36800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000644 |\n",
      "|    n_updates        | 8949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=37000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 37000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000331 |\n",
      "|    n_updates        | 8999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3289     |\n",
      "|    total_timesteps  | 37200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 9049     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=37500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 37500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00093  |\n",
      "|    n_updates        | 9124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3332     |\n",
      "|    total_timesteps  | 37600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000221 |\n",
      "|    n_updates        | 9149     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=38000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000835 |\n",
      "|    n_updates        | 9249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3372     |\n",
      "|    total_timesteps  | 38000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.71    |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3393     |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 9349     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=38500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 38500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 9374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.71    |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3439     |\n",
      "|    total_timesteps  | 38800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000511 |\n",
      "|    n_updates        | 9449     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=39000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 39000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00035  |\n",
      "|    n_updates        | 9499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.71    |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3473     |\n",
      "|    total_timesteps  | 39200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000829 |\n",
      "|    n_updates        | 9549     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=39500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 39500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000406 |\n",
      "|    n_updates        | 9624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.69    |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3514     |\n",
      "|    total_timesteps  | 39600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000578 |\n",
      "|    n_updates        | 9649     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000723 |\n",
      "|    n_updates        | 9749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3553     |\n",
      "|    total_timesteps  | 40000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3575     |\n",
      "|    total_timesteps  | 40400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00785  |\n",
      "|    n_updates        | 9849     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00453  |\n",
      "|    n_updates        | 9874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.69    |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3613     |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00375  |\n",
      "|    n_updates        | 9949     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=41000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 41000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0084   |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3652     |\n",
      "|    total_timesteps  | 41200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0045   |\n",
      "|    n_updates        | 10049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=41500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 41500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 10124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3692     |\n",
      "|    total_timesteps  | 41600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 10149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 10249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3727     |\n",
      "|    total_timesteps  | 42000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3756     |\n",
      "|    total_timesteps  | 42400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00379  |\n",
      "|    n_updates        | 10349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=42500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 42500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 10374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3793     |\n",
      "|    total_timesteps  | 42800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000634 |\n",
      "|    n_updates        | 10449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=43000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 43000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 10499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.66    |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3832     |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000535 |\n",
      "|    n_updates        | 10549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=43500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 43500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 10624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3873     |\n",
      "|    total_timesteps  | 43600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 10649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000526 |\n",
      "|    n_updates        | 10749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3909     |\n",
      "|    total_timesteps  | 44000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3937     |\n",
      "|    total_timesteps  | 44400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 10849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=44500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 44500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000778 |\n",
      "|    n_updates        | 10874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.64    |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 3978     |\n",
      "|    total_timesteps  | 44800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000897 |\n",
      "|    n_updates        | 10949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000498 |\n",
      "|    n_updates        | 10999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4013     |\n",
      "|    total_timesteps  | 45200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000822 |\n",
      "|    n_updates        | 11049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000355 |\n",
      "|    n_updates        | 11124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4052     |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000357 |\n",
      "|    n_updates        | 11149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 11249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.66    |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4088     |\n",
      "|    total_timesteps  | 46000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4119     |\n",
      "|    total_timesteps  | 46400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 11349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=46500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 46500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4153     |\n",
      "|    total_timesteps  | 46800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 11449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=47000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 47000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000772 |\n",
      "|    n_updates        | 11499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4197     |\n",
      "|    total_timesteps  | 47200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000736 |\n",
      "|    n_updates        | 11549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=47500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 47500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 11624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4239     |\n",
      "|    total_timesteps  | 47600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 11649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0314   |\n",
      "|    n_updates        | 11749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4279     |\n",
      "|    total_timesteps  | 48000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4300     |\n",
      "|    total_timesteps  | 48400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 11849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=48500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 48500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000547 |\n",
      "|    n_updates        | 11874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4341     |\n",
      "|    total_timesteps  | 48800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000487 |\n",
      "|    n_updates        | 11949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=49000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 49000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000415 |\n",
      "|    n_updates        | 11999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.64    |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4383     |\n",
      "|    total_timesteps  | 49200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000626 |\n",
      "|    n_updates        | 12049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=49500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 49500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 12124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.66    |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4417     |\n",
      "|    total_timesteps  | 49600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 12149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000713 |\n",
      "|    n_updates        | 12249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4460     |\n",
      "|    total_timesteps  | 50000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.66    |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4481     |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00582  |\n",
      "|    n_updates        | 12349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 12374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4525     |\n",
      "|    total_timesteps  | 50800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00931  |\n",
      "|    n_updates        | 12449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=51000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 51000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 12499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.64    |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4567     |\n",
      "|    total_timesteps  | 51200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 12549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=51500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 51500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00829  |\n",
      "|    n_updates        | 12624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4601     |\n",
      "|    total_timesteps  | 51600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 12649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 52000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 12749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4646     |\n",
      "|    total_timesteps  | 52000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4667     |\n",
      "|    total_timesteps  | 52400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000828 |\n",
      "|    n_updates        | 12849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=52500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 52500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 12874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4704     |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000834 |\n",
      "|    n_updates        | 12949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=53000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 53000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 12999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.69    |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4747     |\n",
      "|    total_timesteps  | 53200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000919 |\n",
      "|    n_updates        | 13049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=53500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 53500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 13124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4781     |\n",
      "|    total_timesteps  | 53600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00282  |\n",
      "|    n_updates        | 13149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 54000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 13249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4822     |\n",
      "|    total_timesteps  | 54000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.73    |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4843     |\n",
      "|    total_timesteps  | 54400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 13349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=54500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 54500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 13374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.74    |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4888     |\n",
      "|    total_timesteps  | 54800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 13449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00066  |\n",
      "|    n_updates        | 13499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.74    |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4930     |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00093  |\n",
      "|    n_updates        | 13549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 13624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.73    |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 4966     |\n",
      "|    total_timesteps  | 55600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00327  |\n",
      "|    n_updates        | 13649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 56000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000673 |\n",
      "|    n_updates        | 13749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5010     |\n",
      "|    total_timesteps  | 56000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5031     |\n",
      "|    total_timesteps  | 56400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000611 |\n",
      "|    n_updates        | 13849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=56500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 56500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 13874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.69    |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5070     |\n",
      "|    total_timesteps  | 56800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00887  |\n",
      "|    n_updates        | 13949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=57000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 57000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00045  |\n",
      "|    n_updates        | 13999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5112     |\n",
      "|    total_timesteps  | 57200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000725 |\n",
      "|    n_updates        | 14049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=57500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 57500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000485 |\n",
      "|    n_updates        | 14124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5151     |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000301 |\n",
      "|    n_updates        | 14149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 58000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000525 |\n",
      "|    n_updates        | 14249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.66    |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5190     |\n",
      "|    total_timesteps  | 58000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.66    |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5211     |\n",
      "|    total_timesteps  | 58400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000621 |\n",
      "|    n_updates        | 14349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=58500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 58500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00054  |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.66    |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5253     |\n",
      "|    total_timesteps  | 58800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 14449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=59000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 59000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.001    |\n",
      "|    n_updates        | 14499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5290     |\n",
      "|    total_timesteps  | 59200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 14549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=59500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 59500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000424 |\n",
      "|    n_updates        | 14624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.64    |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5332     |\n",
      "|    total_timesteps  | 59600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000519 |\n",
      "|    n_updates        | 14649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 14749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.62    |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5369     |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5393     |\n",
      "|    total_timesteps  | 60400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00624  |\n",
      "|    n_updates        | 14849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0076   |\n",
      "|    n_updates        | 14874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5435     |\n",
      "|    total_timesteps  | 60800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 14949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=61000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 61000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0069   |\n",
      "|    n_updates        | 14999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.69    |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5474     |\n",
      "|    total_timesteps  | 61200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00528  |\n",
      "|    n_updates        | 15049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=61500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 61500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 15124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.69    |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5510     |\n",
      "|    total_timesteps  | 61600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 15149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=62000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 62000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00356  |\n",
      "|    n_updates        | 15249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5557     |\n",
      "|    total_timesteps  | 62000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5581     |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 15349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=62500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 62500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 15374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.62    |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5624     |\n",
      "|    total_timesteps  | 62800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 15449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=63000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 63000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 15499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.62    |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5664     |\n",
      "|    total_timesteps  | 63200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000551 |\n",
      "|    n_updates        | 15549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=63500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 63500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 15624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.6     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5706     |\n",
      "|    total_timesteps  | 63600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 15649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 64000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000867 |\n",
      "|    n_updates        | 15749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5742     |\n",
      "|    total_timesteps  | 64000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5769     |\n",
      "|    total_timesteps  | 64400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 15849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=64500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 64500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 15874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.62    |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5803     |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 15949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000916 |\n",
      "|    n_updates        | 15999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.61    |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5848     |\n",
      "|    total_timesteps  | 65200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 16049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000597 |\n",
      "|    n_updates        | 16124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.61    |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5892     |\n",
      "|    total_timesteps  | 65600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 16149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=66000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 66000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 16249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.61    |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5935     |\n",
      "|    total_timesteps  | 66000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.6     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 5957     |\n",
      "|    total_timesteps  | 66400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00345  |\n",
      "|    n_updates        | 16349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=66500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 66500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 16374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.61    |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6000     |\n",
      "|    total_timesteps  | 66800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00062  |\n",
      "|    n_updates        | 16449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=67000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 67000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 16499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.62    |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6035     |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00071  |\n",
      "|    n_updates        | 16549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=67500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 67500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000632 |\n",
      "|    n_updates        | 16624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.59    |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6079     |\n",
      "|    total_timesteps  | 67600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000945 |\n",
      "|    n_updates        | 16649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 68000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000839 |\n",
      "|    n_updates        | 16749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.62    |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6121     |\n",
      "|    total_timesteps  | 68000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.62    |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6145     |\n",
      "|    total_timesteps  | 68400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 16849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=68500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 68500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000368 |\n",
      "|    n_updates        | 16874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.59    |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6189     |\n",
      "|    total_timesteps  | 68800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 16949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=69000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 69000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000466 |\n",
      "|    n_updates        | 16999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.61    |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6223     |\n",
      "|    total_timesteps  | 69200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000534 |\n",
      "|    n_updates        | 17049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=69500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 69500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000453 |\n",
      "|    n_updates        | 17124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6263     |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00437  |\n",
      "|    n_updates        | 17149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 17249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6303     |\n",
      "|    total_timesteps  | 70000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.58    |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6325     |\n",
      "|    total_timesteps  | 70400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00935  |\n",
      "|    n_updates        | 17349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00569  |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6368     |\n",
      "|    total_timesteps  | 70800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00268  |\n",
      "|    n_updates        | 17449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=71000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 71000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 17499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6408     |\n",
      "|    total_timesteps  | 71200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 17549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=71500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 71500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 17624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.53    |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6445     |\n",
      "|    total_timesteps  | 71600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 17649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 17749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6483     |\n",
      "|    total_timesteps  | 72000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.55    |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6507     |\n",
      "|    total_timesteps  | 72400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 17849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=72500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 72500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 17874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6546     |\n",
      "|    total_timesteps  | 72800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 17949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=73000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 73000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 17999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6587     |\n",
      "|    total_timesteps  | 73200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 18049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=73500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 73500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 18124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.53    |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6627     |\n",
      "|    total_timesteps  | 73600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 18149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=74000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 74000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 18249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6662     |\n",
      "|    total_timesteps  | 74000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6689     |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000914 |\n",
      "|    n_updates        | 18349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=74500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 74500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 18374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6734     |\n",
      "|    total_timesteps  | 74800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00086  |\n",
      "|    n_updates        | 18449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000781 |\n",
      "|    n_updates        | 18499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6767     |\n",
      "|    total_timesteps  | 75200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000839 |\n",
      "|    n_updates        | 18549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000912 |\n",
      "|    n_updates        | 18624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.5     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6808     |\n",
      "|    total_timesteps  | 75600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 18649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 76000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 18749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.5     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6845     |\n",
      "|    total_timesteps  | 76000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6870     |\n",
      "|    total_timesteps  | 76400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 18849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=76500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 76500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 18874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6912     |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000414 |\n",
      "|    n_updates        | 18949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=77000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 77000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 18999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6950     |\n",
      "|    total_timesteps  | 77200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 19049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=77500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 77500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 19124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 6988     |\n",
      "|    total_timesteps  | 77600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 19149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 78000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000479 |\n",
      "|    n_updates        | 19249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.53    |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7029     |\n",
      "|    total_timesteps  | 78000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.53    |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7050     |\n",
      "|    total_timesteps  | 78400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 19349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=78500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 78500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000856 |\n",
      "|    n_updates        | 19374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.56    |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7095     |\n",
      "|    total_timesteps  | 78800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000502 |\n",
      "|    n_updates        | 19449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=79000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 79000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000713 |\n",
      "|    n_updates        | 19499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.55    |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7130     |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000585 |\n",
      "|    n_updates        | 19549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=79500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 79500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000899 |\n",
      "|    n_updates        | 19624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7175     |\n",
      "|    total_timesteps  | 79600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0008   |\n",
      "|    n_updates        | 19649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000621 |\n",
      "|    n_updates        | 19749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7212     |\n",
      "|    total_timesteps  | 80000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.56    |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7241     |\n",
      "|    total_timesteps  | 80400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 19849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 19874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.57    |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7276     |\n",
      "|    total_timesteps  | 80800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00658  |\n",
      "|    n_updates        | 19949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=81000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 81000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 19999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.57    |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7315     |\n",
      "|    total_timesteps  | 81200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 20049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=81500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 81500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 20124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.58    |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7355     |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 20149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=82000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 82000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000987 |\n",
      "|    n_updates        | 20249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.56    |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7390     |\n",
      "|    total_timesteps  | 82000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.57    |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7420     |\n",
      "|    total_timesteps  | 82400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 20349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=82500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 82500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.56    |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7457     |\n",
      "|    total_timesteps  | 82800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 20449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=83000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 83000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 20499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.55    |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7504     |\n",
      "|    total_timesteps  | 83200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000411 |\n",
      "|    n_updates        | 20549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=83500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 83500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 20624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.53    |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7539     |\n",
      "|    total_timesteps  | 83600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 20649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00063  |\n",
      "|    n_updates        | 20749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.49    |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7584     |\n",
      "|    total_timesteps  | 84000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.48    |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7605     |\n",
      "|    total_timesteps  | 84400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00505  |\n",
      "|    n_updates        | 20849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=84500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 84500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000821 |\n",
      "|    n_updates        | 20874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.48    |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7648     |\n",
      "|    total_timesteps  | 84800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 20949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 20999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.5     |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7685     |\n",
      "|    total_timesteps  | 85200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 21049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000606 |\n",
      "|    n_updates        | 21124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.47    |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7724     |\n",
      "|    total_timesteps  | 85600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00397  |\n",
      "|    n_updates        | 21149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=86000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 86000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000493 |\n",
      "|    n_updates        | 21249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.48    |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7768     |\n",
      "|    total_timesteps  | 86000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.47    |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7789     |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 21349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=86500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 86500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000603 |\n",
      "|    n_updates        | 21374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.45    |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7833     |\n",
      "|    total_timesteps  | 86800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 21449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=87000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 87000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00055  |\n",
      "|    n_updates        | 21499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.46    |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7875     |\n",
      "|    total_timesteps  | 87200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000439 |\n",
      "|    n_updates        | 21549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=87500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 87500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000381 |\n",
      "|    n_updates        | 21624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.44    |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7910     |\n",
      "|    total_timesteps  | 87600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000793 |\n",
      "|    n_updates        | 21649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 88000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00294  |\n",
      "|    n_updates        | 21749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7949     |\n",
      "|    total_timesteps  | 88000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.39    |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 7972     |\n",
      "|    total_timesteps  | 88400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00048  |\n",
      "|    n_updates        | 21849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=88500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 88500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000787 |\n",
      "|    n_updates        | 21874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8009     |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000313 |\n",
      "|    n_updates        | 21949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=89000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 89000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00055  |\n",
      "|    n_updates        | 21999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8050     |\n",
      "|    total_timesteps  | 89200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 22049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=89500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 89500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00578  |\n",
      "|    n_updates        | 22124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8086     |\n",
      "|    total_timesteps  | 89600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 22149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000675 |\n",
      "|    n_updates        | 22249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8126     |\n",
      "|    total_timesteps  | 90000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.39    |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8148     |\n",
      "|    total_timesteps  | 90400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00593  |\n",
      "|    n_updates        | 22349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 22374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8189     |\n",
      "|    total_timesteps  | 90800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 22449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=91000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 91000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000412 |\n",
      "|    n_updates        | 22499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8227     |\n",
      "|    total_timesteps  | 91200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 22549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=91500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 91500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00437  |\n",
      "|    n_updates        | 22624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8264     |\n",
      "|    total_timesteps  | 91600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 22649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 92000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000659 |\n",
      "|    n_updates        | 22749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8302     |\n",
      "|    total_timesteps  | 92000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8327     |\n",
      "|    total_timesteps  | 92400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00356  |\n",
      "|    n_updates        | 22849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=92500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 92500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000789 |\n",
      "|    n_updates        | 22874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8366     |\n",
      "|    total_timesteps  | 92800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000843 |\n",
      "|    n_updates        | 22949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=93000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 93000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 22999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8405     |\n",
      "|    total_timesteps  | 93200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 23049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=93500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 93500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00382  |\n",
      "|    n_updates        | 23124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8446     |\n",
      "|    total_timesteps  | 93600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 23149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=94000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 94000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00791  |\n",
      "|    n_updates        | 23249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8484     |\n",
      "|    total_timesteps  | 94000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8511     |\n",
      "|    total_timesteps  | 94400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 23349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=94500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 94500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00645  |\n",
      "|    n_updates        | 23374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8547     |\n",
      "|    total_timesteps  | 94800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000854 |\n",
      "|    n_updates        | 23449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 95000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 23499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.32    |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8591     |\n",
      "|    total_timesteps  | 95200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000749 |\n",
      "|    n_updates        | 23549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=95500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 95500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 23624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8634     |\n",
      "|    total_timesteps  | 95600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000533 |\n",
      "|    n_updates        | 23649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 96000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000574 |\n",
      "|    n_updates        | 23749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8676     |\n",
      "|    total_timesteps  | 96000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8698     |\n",
      "|    total_timesteps  | 96400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 23849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=96500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 96500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000696 |\n",
      "|    n_updates        | 23874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8738     |\n",
      "|    total_timesteps  | 96800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000338 |\n",
      "|    n_updates        | 23949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=97000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 97000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000328 |\n",
      "|    n_updates        | 23999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8773     |\n",
      "|    total_timesteps  | 97200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000492 |\n",
      "|    n_updates        | 24049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=97500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 97500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000725 |\n",
      "|    n_updates        | 24124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8814     |\n",
      "|    total_timesteps  | 97600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000749 |\n",
      "|    n_updates        | 24149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=98000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 98000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 24249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8857     |\n",
      "|    total_timesteps  | 98000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8878     |\n",
      "|    total_timesteps  | 98400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000464 |\n",
      "|    n_updates        | 24349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=98500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 98500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000236 |\n",
      "|    n_updates        | 24374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8921     |\n",
      "|    total_timesteps  | 98800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000392 |\n",
      "|    n_updates        | 24449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=99000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 99000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000797 |\n",
      "|    n_updates        | 24499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8963     |\n",
      "|    total_timesteps  | 99200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000828 |\n",
      "|    n_updates        | 24549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=99500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 99500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 24624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 8997     |\n",
      "|    total_timesteps  | 99600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 24649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000181 |\n",
      "|    n_updates        | 24749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9040     |\n",
      "|    total_timesteps  | 100000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9063     |\n",
      "|    total_timesteps  | 100400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 24849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 24874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.26    |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9106     |\n",
      "|    total_timesteps  | 100800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 24949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=101000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 101000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 24999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.27    |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9140     |\n",
      "|    total_timesteps  | 101200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 25049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=101500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 101500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 25124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9185     |\n",
      "|    total_timesteps  | 101600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 25149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=102000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 102000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 25249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9222     |\n",
      "|    total_timesteps  | 102000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9246     |\n",
      "|    total_timesteps  | 102400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 25349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=102500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 102500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000861 |\n",
      "|    n_updates        | 25374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9284     |\n",
      "|    total_timesteps  | 102800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 25449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=103000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 103000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000504 |\n",
      "|    n_updates        | 25499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9325     |\n",
      "|    total_timesteps  | 103200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 25549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=103500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 103500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000518 |\n",
      "|    n_updates        | 25624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9361     |\n",
      "|    total_timesteps  | 103600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00066  |\n",
      "|    n_updates        | 25649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 104000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000758 |\n",
      "|    n_updates        | 25749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9407     |\n",
      "|    total_timesteps  | 104000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9431     |\n",
      "|    total_timesteps  | 104400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000643 |\n",
      "|    n_updates        | 25849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=104500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 104500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 25874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9468     |\n",
      "|    total_timesteps  | 104800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000572 |\n",
      "|    n_updates        | 25949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 105000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 25999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.42    |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9503     |\n",
      "|    total_timesteps  | 105200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000613 |\n",
      "|    n_updates        | 26049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=105500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 105500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00406  |\n",
      "|    n_updates        | 26124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9549     |\n",
      "|    total_timesteps  | 105600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 26149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=106000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 106000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0007   |\n",
      "|    n_updates        | 26249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.45    |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9584     |\n",
      "|    total_timesteps  | 106000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.47    |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9609     |\n",
      "|    total_timesteps  | 106400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000889 |\n",
      "|    n_updates        | 26349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=106500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 106500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000694 |\n",
      "|    n_updates        | 26374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.42    |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9651     |\n",
      "|    total_timesteps  | 106800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 26449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=107000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 107000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000405 |\n",
      "|    n_updates        | 26499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9687     |\n",
      "|    total_timesteps  | 107200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 26549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=107500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 107500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000577 |\n",
      "|    n_updates        | 26624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9731     |\n",
      "|    total_timesteps  | 107600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000676 |\n",
      "|    n_updates        | 26649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=108000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 108000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000631 |\n",
      "|    n_updates        | 26749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.46    |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9765     |\n",
      "|    total_timesteps  | 108000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.47    |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9796     |\n",
      "|    total_timesteps  | 108400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000678 |\n",
      "|    n_updates        | 26849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=108500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 108500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 26874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.47    |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9830     |\n",
      "|    total_timesteps  | 108800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000989 |\n",
      "|    n_updates        | 26949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=109000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 109000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000663 |\n",
      "|    n_updates        | 26999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.47    |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9875     |\n",
      "|    total_timesteps  | 109200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 27049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=109500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 109500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000453 |\n",
      "|    n_updates        | 27124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.46    |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9916     |\n",
      "|    total_timesteps  | 109600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000568 |\n",
      "|    n_updates        | 27149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 110000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000226 |\n",
      "|    n_updates        | 27249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.48    |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9956     |\n",
      "|    total_timesteps  | 110000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 9978     |\n",
      "|    total_timesteps  | 110400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 27349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 110500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 27374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10026    |\n",
      "|    total_timesteps  | 110800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 27449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=111000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 111000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00483  |\n",
      "|    n_updates        | 27499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10061    |\n",
      "|    total_timesteps  | 111200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 27549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=111500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 111500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000541 |\n",
      "|    n_updates        | 27624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.53    |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10103    |\n",
      "|    total_timesteps  | 111600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 27649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 112000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000933 |\n",
      "|    n_updates        | 27749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10142    |\n",
      "|    total_timesteps  | 112000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10164    |\n",
      "|    total_timesteps  | 112400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000825 |\n",
      "|    n_updates        | 27849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=112500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 112500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 27874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10206    |\n",
      "|    total_timesteps  | 112800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 27949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=113000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 113000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 27999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10249    |\n",
      "|    total_timesteps  | 113200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000488 |\n",
      "|    n_updates        | 28049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=113500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 113500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 28124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.5     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10286    |\n",
      "|    total_timesteps  | 113600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000886 |\n",
      "|    n_updates        | 28149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=114000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 114000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000796 |\n",
      "|    n_updates        | 28249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.46    |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10325    |\n",
      "|    total_timesteps  | 114000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.45    |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10352    |\n",
      "|    total_timesteps  | 114400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 28349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=114500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 114500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 28374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.42    |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10389    |\n",
      "|    total_timesteps  | 114800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000709 |\n",
      "|    n_updates        | 28449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 115000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 28499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10426    |\n",
      "|    total_timesteps  | 115200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000651 |\n",
      "|    n_updates        | 28549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=115500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 115500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 28624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.37    |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10467    |\n",
      "|    total_timesteps  | 115600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000944 |\n",
      "|    n_updates        | 28649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=116000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 116000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000523 |\n",
      "|    n_updates        | 28749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10502    |\n",
      "|    total_timesteps  | 116000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10531    |\n",
      "|    total_timesteps  | 116400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000401 |\n",
      "|    n_updates        | 28849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=116500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 116500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000901 |\n",
      "|    n_updates        | 28874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10565    |\n",
      "|    total_timesteps  | 116800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000731 |\n",
      "|    n_updates        | 28949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=117000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 117000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000857 |\n",
      "|    n_updates        | 28999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.32    |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10607    |\n",
      "|    total_timesteps  | 117200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000538 |\n",
      "|    n_updates        | 29049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=117500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 117500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0077   |\n",
      "|    n_updates        | 29124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.32    |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10651    |\n",
      "|    total_timesteps  | 117600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00494  |\n",
      "|    n_updates        | 29149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=118000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 118000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00067  |\n",
      "|    n_updates        | 29249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10686    |\n",
      "|    total_timesteps  | 118000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.32    |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10712    |\n",
      "|    total_timesteps  | 118400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00079  |\n",
      "|    n_updates        | 29349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=118500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 118500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000709 |\n",
      "|    n_updates        | 29374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10751    |\n",
      "|    total_timesteps  | 118800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000748 |\n",
      "|    n_updates        | 29449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=119000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 119000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000349 |\n",
      "|    n_updates        | 29499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10794    |\n",
      "|    total_timesteps  | 119200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 29549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=119500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 119500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000466 |\n",
      "|    n_updates        | 29624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10827    |\n",
      "|    total_timesteps  | 119600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000647 |\n",
      "|    n_updates        | 29649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000882 |\n",
      "|    n_updates        | 29749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.32    |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10870    |\n",
      "|    total_timesteps  | 120000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10899    |\n",
      "|    total_timesteps  | 120400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 29849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 120500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 29874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10934    |\n",
      "|    total_timesteps  | 120800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000593 |\n",
      "|    n_updates        | 29949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=121000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 121000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 29999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10977    |\n",
      "|    total_timesteps  | 121200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 30049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=121500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 121500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 30124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11019    |\n",
      "|    total_timesteps  | 121600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000548 |\n",
      "|    n_updates        | 30149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=122000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 122000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 30249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11054    |\n",
      "|    total_timesteps  | 122000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11083    |\n",
      "|    total_timesteps  | 122400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000613 |\n",
      "|    n_updates        | 30349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=122500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 122500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 30374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.27    |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11118    |\n",
      "|    total_timesteps  | 122800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000984 |\n",
      "|    n_updates        | 30449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=123000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 123000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000772 |\n",
      "|    n_updates        | 30499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.27    |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11162    |\n",
      "|    total_timesteps  | 123200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 30549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=123500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 123500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000879 |\n",
      "|    n_updates        | 30624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.27    |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11198    |\n",
      "|    total_timesteps  | 123600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 30649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=124000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 124000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 30749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11241    |\n",
      "|    total_timesteps  | 124000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11271    |\n",
      "|    total_timesteps  | 124400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000616 |\n",
      "|    n_updates        | 30849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=124500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 124500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 30874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11305    |\n",
      "|    total_timesteps  | 124800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000242 |\n",
      "|    n_updates        | 30949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 125000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000385 |\n",
      "|    n_updates        | 30999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.37    |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11352    |\n",
      "|    total_timesteps  | 125200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000883 |\n",
      "|    n_updates        | 31049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=125500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 125500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00068  |\n",
      "|    n_updates        | 31124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.39    |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11387    |\n",
      "|    total_timesteps  | 125600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000679 |\n",
      "|    n_updates        | 31149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=126000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 126000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000847 |\n",
      "|    n_updates        | 31249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11429    |\n",
      "|    total_timesteps  | 126000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11451    |\n",
      "|    total_timesteps  | 126400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 31349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=126500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 126500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000505 |\n",
      "|    n_updates        | 31374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11496    |\n",
      "|    total_timesteps  | 126800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000798 |\n",
      "|    n_updates        | 31449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=127000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 127000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000731 |\n",
      "|    n_updates        | 31499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11536    |\n",
      "|    total_timesteps  | 127200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000878 |\n",
      "|    n_updates        | 31549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=127500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 127500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000602 |\n",
      "|    n_updates        | 31624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.44    |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11574    |\n",
      "|    total_timesteps  | 127600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 31649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 128000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 31749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11620    |\n",
      "|    total_timesteps  | 128000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11641    |\n",
      "|    total_timesteps  | 128400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00445  |\n",
      "|    n_updates        | 31849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=128500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 128500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000824 |\n",
      "|    n_updates        | 31874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.42    |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11681    |\n",
      "|    total_timesteps  | 128800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 31949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=129000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 129000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 31999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11721    |\n",
      "|    total_timesteps  | 129200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000583 |\n",
      "|    n_updates        | 32049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=129500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 129500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000436 |\n",
      "|    n_updates        | 32124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11756    |\n",
      "|    total_timesteps  | 129600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000406 |\n",
      "|    n_updates        | 32149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 130000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000544 |\n",
      "|    n_updates        | 32249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.37    |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11802    |\n",
      "|    total_timesteps  | 130000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11824    |\n",
      "|    total_timesteps  | 130400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 32349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 130500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 32374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.39    |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11867    |\n",
      "|    total_timesteps  | 130800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 32449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=131000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 131000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000959 |\n",
      "|    n_updates        | 32499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11903    |\n",
      "|    total_timesteps  | 131200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 32549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=131500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 131500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000771 |\n",
      "|    n_updates        | 32624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11945    |\n",
      "|    total_timesteps  | 131600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000764 |\n",
      "|    n_updates        | 32649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=132000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 132000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000865 |\n",
      "|    n_updates        | 32749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11985    |\n",
      "|    total_timesteps  | 132000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12009    |\n",
      "|    total_timesteps  | 132400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 32849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=132500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 132500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000955 |\n",
      "|    n_updates        | 32874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12052    |\n",
      "|    total_timesteps  | 132800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 32949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=133000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 133000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000434 |\n",
      "|    n_updates        | 32999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12088    |\n",
      "|    total_timesteps  | 133200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 33049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=133500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 133500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 33124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.39    |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12126    |\n",
      "|    total_timesteps  | 133600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000859 |\n",
      "|    n_updates        | 33149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=134000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 134000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 33249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.39    |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12166    |\n",
      "|    total_timesteps  | 134000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12194    |\n",
      "|    total_timesteps  | 134400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000906 |\n",
      "|    n_updates        | 33349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=134500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 134500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000592 |\n",
      "|    n_updates        | 33374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12229    |\n",
      "|    total_timesteps  | 134800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 33449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 135000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000621 |\n",
      "|    n_updates        | 33499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12274    |\n",
      "|    total_timesteps  | 135200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 33549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=135500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 135500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000746 |\n",
      "|    n_updates        | 33624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.32    |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12310    |\n",
      "|    total_timesteps  | 135600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000691 |\n",
      "|    n_updates        | 33649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 136000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00531  |\n",
      "|    n_updates        | 33749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12350    |\n",
      "|    total_timesteps  | 136000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12371    |\n",
      "|    total_timesteps  | 136400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000499 |\n",
      "|    n_updates        | 33849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=136500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 136500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 33874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12414    |\n",
      "|    total_timesteps  | 136800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00057  |\n",
      "|    n_updates        | 33949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=137000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 137000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 33999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12455    |\n",
      "|    total_timesteps  | 137200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0055   |\n",
      "|    n_updates        | 34049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=137500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 137500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 34124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12499    |\n",
      "|    total_timesteps  | 137600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 34149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=138000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 138000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000506 |\n",
      "|    n_updates        | 34249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12533    |\n",
      "|    total_timesteps  | 138000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12558    |\n",
      "|    total_timesteps  | 138400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 34349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=138500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 138500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000951 |\n",
      "|    n_updates        | 34374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12595    |\n",
      "|    total_timesteps  | 138800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 34449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=139000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 139000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 34499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12637    |\n",
      "|    total_timesteps  | 139200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 34549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=139500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 139500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000647 |\n",
      "|    n_updates        | 34624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.25    |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12677    |\n",
      "|    total_timesteps  | 139600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000417 |\n",
      "|    n_updates        | 34649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 140000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 34749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.24    |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12714    |\n",
      "|    total_timesteps  | 140000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12736    |\n",
      "|    total_timesteps  | 140400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 34849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 140500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 34874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12780    |\n",
      "|    total_timesteps  | 140800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 34949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=141000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 141000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 34999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.19    |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12815    |\n",
      "|    total_timesteps  | 141200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000896 |\n",
      "|    n_updates        | 35049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=141500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 141500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 35124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.17    |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12858    |\n",
      "|    total_timesteps  | 141600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 35149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=142000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 142000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 35249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12900    |\n",
      "|    total_timesteps  | 142000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12922    |\n",
      "|    total_timesteps  | 142400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 35349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=142500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 142500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000686 |\n",
      "|    n_updates        | 35374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12967    |\n",
      "|    total_timesteps  | 142800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00066  |\n",
      "|    n_updates        | 35449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=143000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 143000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000492 |\n",
      "|    n_updates        | 35499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13008    |\n",
      "|    total_timesteps  | 143200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000905 |\n",
      "|    n_updates        | 35549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=143500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 143500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00819  |\n",
      "|    n_updates        | 35624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13043    |\n",
      "|    total_timesteps  | 143600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 35649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 144000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000938 |\n",
      "|    n_updates        | 35749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13086    |\n",
      "|    total_timesteps  | 144000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13108    |\n",
      "|    total_timesteps  | 144400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000752 |\n",
      "|    n_updates        | 35849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=144500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 144500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000538 |\n",
      "|    n_updates        | 35874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13156    |\n",
      "|    total_timesteps  | 144800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000851 |\n",
      "|    n_updates        | 35949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 145000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000623 |\n",
      "|    n_updates        | 35999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13197    |\n",
      "|    total_timesteps  | 145200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 36049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=145500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 145500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000629 |\n",
      "|    n_updates        | 36124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13240    |\n",
      "|    total_timesteps  | 145600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000602 |\n",
      "|    n_updates        | 36149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=146000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 146000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00069  |\n",
      "|    n_updates        | 36249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13274    |\n",
      "|    total_timesteps  | 146000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13306    |\n",
      "|    total_timesteps  | 146400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000635 |\n",
      "|    n_updates        | 36349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=146500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 146500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000786 |\n",
      "|    n_updates        | 36374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13341    |\n",
      "|    total_timesteps  | 146800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000471 |\n",
      "|    n_updates        | 36449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=147000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 147000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000829 |\n",
      "|    n_updates        | 36499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13379    |\n",
      "|    total_timesteps  | 147200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000364 |\n",
      "|    n_updates        | 36549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=147500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 147500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 36624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13423    |\n",
      "|    total_timesteps  | 147600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000372 |\n",
      "|    n_updates        | 36649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=148000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 148000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 36749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13463    |\n",
      "|    total_timesteps  | 148000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13488    |\n",
      "|    total_timesteps  | 148400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000424 |\n",
      "|    n_updates        | 36849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=148500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 148500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000643 |\n",
      "|    n_updates        | 36874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13531    |\n",
      "|    total_timesteps  | 148800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000746 |\n",
      "|    n_updates        | 36949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=149000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 149000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000788 |\n",
      "|    n_updates        | 36999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13566    |\n",
      "|    total_timesteps  | 149200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000619 |\n",
      "|    n_updates        | 37049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=149500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 149500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00096  |\n",
      "|    n_updates        | 37124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.22    |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13606    |\n",
      "|    total_timesteps  | 149600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000653 |\n",
      "|    n_updates        | 37149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000811 |\n",
      "|    n_updates        | 37249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.25    |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13644    |\n",
      "|    total_timesteps  | 150000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13675    |\n",
      "|    total_timesteps  | 150400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 37349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 37374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 13709    |\n",
      "|    total_timesteps  | 150800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 37449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=151000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 151000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 37499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13755    |\n",
      "|    total_timesteps  | 151200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0242   |\n",
      "|    n_updates        | 37549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=151500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 151500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 37624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13791    |\n",
      "|    total_timesteps  | 151600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 37649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 152000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000811 |\n",
      "|    n_updates        | 37749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13830    |\n",
      "|    total_timesteps  | 152000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13858    |\n",
      "|    total_timesteps  | 152400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000695 |\n",
      "|    n_updates        | 37849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=152500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 152500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0078   |\n",
      "|    n_updates        | 37874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13893    |\n",
      "|    total_timesteps  | 152800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 37949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=153000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 153000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00379  |\n",
      "|    n_updates        | 37999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13938    |\n",
      "|    total_timesteps  | 153200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000724 |\n",
      "|    n_updates        | 38049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=153500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 153500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 38124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13980    |\n",
      "|    total_timesteps  | 153600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 38149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=154000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 154000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00716  |\n",
      "|    n_updates        | 38249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14018    |\n",
      "|    total_timesteps  | 154000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14041    |\n",
      "|    total_timesteps  | 154400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000601 |\n",
      "|    n_updates        | 38349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=154500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 154500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000602 |\n",
      "|    n_updates        | 38374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14084    |\n",
      "|    total_timesteps  | 154800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000696 |\n",
      "|    n_updates        | 38449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 155000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000325 |\n",
      "|    n_updates        | 38499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14119    |\n",
      "|    total_timesteps  | 155200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000481 |\n",
      "|    n_updates        | 38549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=155500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 155500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 38624    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14162    |\n",
      "|    total_timesteps  | 155600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000577 |\n",
      "|    n_updates        | 38649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=156000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 156000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 38749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14209    |\n",
      "|    total_timesteps  | 156000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14230    |\n",
      "|    total_timesteps  | 156400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000986 |\n",
      "|    n_updates        | 38849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=156500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 156500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000986 |\n",
      "|    n_updates        | 38874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.33    |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14272    |\n",
      "|    total_timesteps  | 156800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00048  |\n",
      "|    n_updates        | 38949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=157000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 157000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000373 |\n",
      "|    n_updates        | 38999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14310    |\n",
      "|    total_timesteps  | 157200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000617 |\n",
      "|    n_updates        | 39049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=157500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 157500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 39124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14350    |\n",
      "|    total_timesteps  | 157600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000532 |\n",
      "|    n_updates        | 39149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=158000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 158000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000311 |\n",
      "|    n_updates        | 39249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.32    |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14394    |\n",
      "|    total_timesteps  | 158000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14416    |\n",
      "|    total_timesteps  | 158400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00062  |\n",
      "|    n_updates        | 39349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=158500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 158500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 39374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14460    |\n",
      "|    total_timesteps  | 158800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000377 |\n",
      "|    n_updates        | 39449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=159000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 159000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000553 |\n",
      "|    n_updates        | 39499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14506    |\n",
      "|    total_timesteps  | 159200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000948 |\n",
      "|    n_updates        | 39549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=159500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 159500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000541 |\n",
      "|    n_updates        | 39624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.23    |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14540    |\n",
      "|    total_timesteps  | 159600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000341 |\n",
      "|    n_updates        | 39649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 39749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.22    |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14583    |\n",
      "|    total_timesteps  | 160000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14610    |\n",
      "|    total_timesteps  | 160400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 39849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 160500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000641 |\n",
      "|    n_updates        | 39874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14649    |\n",
      "|    total_timesteps  | 160800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000568 |\n",
      "|    n_updates        | 39949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=161000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 161000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 39999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.18    |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14695    |\n",
      "|    total_timesteps  | 161200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00402  |\n",
      "|    n_updates        | 40049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=161500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 161500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 40124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.2     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14732    |\n",
      "|    total_timesteps  | 161600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000709 |\n",
      "|    n_updates        | 40149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=162000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 162000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 40249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.2     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14769    |\n",
      "|    total_timesteps  | 162000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.24    |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14799    |\n",
      "|    total_timesteps  | 162400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000854 |\n",
      "|    n_updates        | 40349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=162500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 162500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000598 |\n",
      "|    n_updates        | 40374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.23    |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14841    |\n",
      "|    total_timesteps  | 162800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000779 |\n",
      "|    n_updates        | 40449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=163000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 163000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00463  |\n",
      "|    n_updates        | 40499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.2     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14877    |\n",
      "|    total_timesteps  | 163200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000567 |\n",
      "|    n_updates        | 40549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=163500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 163500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000952 |\n",
      "|    n_updates        | 40624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14919    |\n",
      "|    total_timesteps  | 163600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000637 |\n",
      "|    n_updates        | 40649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=164000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 164000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000691 |\n",
      "|    n_updates        | 40749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.22    |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14957    |\n",
      "|    total_timesteps  | 164000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.19    |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14982    |\n",
      "|    total_timesteps  | 164400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000414 |\n",
      "|    n_updates        | 40849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=164500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 164500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 40874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15027    |\n",
      "|    total_timesteps  | 164800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000521 |\n",
      "|    n_updates        | 40949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 165000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00052  |\n",
      "|    n_updates        | 40999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15061    |\n",
      "|    total_timesteps  | 165200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0093   |\n",
      "|    n_updates        | 41049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=165500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 165500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 41124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.2     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15106    |\n",
      "|    total_timesteps  | 165600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000648 |\n",
      "|    n_updates        | 41149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=166000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 166000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0007   |\n",
      "|    n_updates        | 41249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.18    |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15152    |\n",
      "|    total_timesteps  | 166000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.22    |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15174    |\n",
      "|    total_timesteps  | 166400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00613  |\n",
      "|    n_updates        | 41349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=166500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 166500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000634 |\n",
      "|    n_updates        | 41374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15211    |\n",
      "|    total_timesteps  | 166800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00678  |\n",
      "|    n_updates        | 41449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=167000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 167000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 41499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15253    |\n",
      "|    total_timesteps  | 167200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00047  |\n",
      "|    n_updates        | 41549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=167500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 167500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 41624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15298    |\n",
      "|    total_timesteps  | 167600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000959 |\n",
      "|    n_updates        | 41649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 168000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000388 |\n",
      "|    n_updates        | 41749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15334    |\n",
      "|    total_timesteps  | 168000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15366    |\n",
      "|    total_timesteps  | 168400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000461 |\n",
      "|    n_updates        | 41849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=168500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 168500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00072  |\n",
      "|    n_updates        | 41874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15401    |\n",
      "|    total_timesteps  | 168800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000732 |\n",
      "|    n_updates        | 41949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=169000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 169000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000439 |\n",
      "|    n_updates        | 41999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15441    |\n",
      "|    total_timesteps  | 169200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000477 |\n",
      "|    n_updates        | 42049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=169500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 169500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000318 |\n",
      "|    n_updates        | 42124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15487    |\n",
      "|    total_timesteps  | 169600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000312 |\n",
      "|    n_updates        | 42149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 170000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000931 |\n",
      "|    n_updates        | 42249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15523    |\n",
      "|    total_timesteps  | 170000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15549    |\n",
      "|    total_timesteps  | 170400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 42349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 170500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 42374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15592    |\n",
      "|    total_timesteps  | 170800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 42449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=171000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 171000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000639 |\n",
      "|    n_updates        | 42499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1712     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15627    |\n",
      "|    total_timesteps  | 171200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 42549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=171500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 171500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000688 |\n",
      "|    n_updates        | 42624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1716     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15672    |\n",
      "|    total_timesteps  | 171600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 42649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=172000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 172000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 42749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15715    |\n",
      "|    total_timesteps  | 172000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1724     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15737    |\n",
      "|    total_timesteps  | 172400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000524 |\n",
      "|    n_updates        | 42849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=172500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 172500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000638 |\n",
      "|    n_updates        | 42874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1728     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15777    |\n",
      "|    total_timesteps  | 172800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000576 |\n",
      "|    n_updates        | 42949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=173000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 173000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 42999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1732     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15817    |\n",
      "|    total_timesteps  | 173200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000461 |\n",
      "|    n_updates        | 43049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=173500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 173500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000959 |\n",
      "|    n_updates        | 43124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1736     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15862    |\n",
      "|    total_timesteps  | 173600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 43149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=174000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 174000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 43249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15898    |\n",
      "|    total_timesteps  | 174000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1744     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15929    |\n",
      "|    total_timesteps  | 174400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000683 |\n",
      "|    n_updates        | 43349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=174500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 174500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000824 |\n",
      "|    n_updates        | 43374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1748     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15965    |\n",
      "|    total_timesteps  | 174800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000707 |\n",
      "|    n_updates        | 43449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 175000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 43499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1752     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16007    |\n",
      "|    total_timesteps  | 175200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000763 |\n",
      "|    n_updates        | 43549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=175500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 175500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000505 |\n",
      "|    n_updates        | 43624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1756     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16047    |\n",
      "|    total_timesteps  | 175600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000669 |\n",
      "|    n_updates        | 43649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 176000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000867 |\n",
      "|    n_updates        | 43749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16091    |\n",
      "|    total_timesteps  | 176000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1764     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16114    |\n",
      "|    total_timesteps  | 176400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 43849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=176500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 176500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000736 |\n",
      "|    n_updates        | 43874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1768     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16157    |\n",
      "|    total_timesteps  | 176800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 43949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=177000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 177000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000585 |\n",
      "|    n_updates        | 43999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1772     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16194    |\n",
      "|    total_timesteps  | 177200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000453 |\n",
      "|    n_updates        | 44049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=177500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 177500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00033  |\n",
      "|    n_updates        | 44124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1776     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16234    |\n",
      "|    total_timesteps  | 177600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000372 |\n",
      "|    n_updates        | 44149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=178000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 178000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000477 |\n",
      "|    n_updates        | 44249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16279    |\n",
      "|    total_timesteps  | 178000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1784     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16301    |\n",
      "|    total_timesteps  | 178400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000493 |\n",
      "|    n_updates        | 44349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=178500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 178500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000944 |\n",
      "|    n_updates        | 44374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1788     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16346    |\n",
      "|    total_timesteps  | 178800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 44449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=179000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 179000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 44499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1792     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16384    |\n",
      "|    total_timesteps  | 179200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00075  |\n",
      "|    n_updates        | 44549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=179500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 179500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000451 |\n",
      "|    n_updates        | 44624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1796     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16423    |\n",
      "|    total_timesteps  | 179600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000599 |\n",
      "|    n_updates        | 44649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 180000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 44749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16465    |\n",
      "|    total_timesteps  | 180000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1804     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16496    |\n",
      "|    total_timesteps  | 180400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 44849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 180500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 44874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.02    |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1808     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16531    |\n",
      "|    total_timesteps  | 180800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000767 |\n",
      "|    n_updates        | 44949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=181000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 181000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000918 |\n",
      "|    n_updates        | 44999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1812     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16574    |\n",
      "|    total_timesteps  | 181200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 45049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=181500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 181500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 45124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1816     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16618    |\n",
      "|    total_timesteps  | 181600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00559  |\n",
      "|    n_updates        | 45149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=182000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 182000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000582 |\n",
      "|    n_updates        | 45249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16652    |\n",
      "|    total_timesteps  | 182000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1824     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16680    |\n",
      "|    total_timesteps  | 182400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 45349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=182500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 182500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 45374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1828     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16719    |\n",
      "|    total_timesteps  | 182800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000892 |\n",
      "|    n_updates        | 45449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=183000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 183000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000755 |\n",
      "|    n_updates        | 45499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1832     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16757    |\n",
      "|    total_timesteps  | 183200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000319 |\n",
      "|    n_updates        | 45549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=183500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 183500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000707 |\n",
      "|    n_updates        | 45624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1836     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16798    |\n",
      "|    total_timesteps  | 183600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 45649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 184000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000594 |\n",
      "|    n_updates        | 45749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16844    |\n",
      "|    total_timesteps  | 184000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1844     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16867    |\n",
      "|    total_timesteps  | 184400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000603 |\n",
      "|    n_updates        | 45849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=184500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 184500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000686 |\n",
      "|    n_updates        | 45874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1848     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16909    |\n",
      "|    total_timesteps  | 184800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000701 |\n",
      "|    n_updates        | 45949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 185000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00761  |\n",
      "|    n_updates        | 45999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1852     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16944    |\n",
      "|    total_timesteps  | 185200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000282 |\n",
      "|    n_updates        | 46049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=185500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 185500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000588 |\n",
      "|    n_updates        | 46124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1856     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16988    |\n",
      "|    total_timesteps  | 185600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000709 |\n",
      "|    n_updates        | 46149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=186000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 186000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000684 |\n",
      "|    n_updates        | 46249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17034    |\n",
      "|    total_timesteps  | 186000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1864     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17056    |\n",
      "|    total_timesteps  | 186400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 46349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=186500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 186500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000915 |\n",
      "|    n_updates        | 46374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.778    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1868     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17099    |\n",
      "|    total_timesteps  | 186800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0005   |\n",
      "|    n_updates        | 46449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=187000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.778    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 187000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00349  |\n",
      "|    n_updates        | 46499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.778    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1872     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17142    |\n",
      "|    total_timesteps  | 187200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 46549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=187500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 187500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000491 |\n",
      "|    n_updates        | 46624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1876     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17178    |\n",
      "|    total_timesteps  | 187600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000406 |\n",
      "|    n_updates        | 46649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=188000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 188000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00078  |\n",
      "|    n_updates        | 46749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17221    |\n",
      "|    total_timesteps  | 188000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1884     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17243    |\n",
      "|    total_timesteps  | 188400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000742 |\n",
      "|    n_updates        | 46849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=188500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 188500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000788 |\n",
      "|    n_updates        | 46874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1888     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17285    |\n",
      "|    total_timesteps  | 188800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000596 |\n",
      "|    n_updates        | 46949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=189000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 189000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000322 |\n",
      "|    n_updates        | 46999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.775    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1892     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17325    |\n",
      "|    total_timesteps  | 189200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000231 |\n",
      "|    n_updates        | 47049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=189500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.775    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 189500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000479 |\n",
      "|    n_updates        | 47124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.775    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1896     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17364    |\n",
      "|    total_timesteps  | 189600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000491 |\n",
      "|    n_updates        | 47149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 190000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000761 |\n",
      "|    n_updates        | 47249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17409    |\n",
      "|    total_timesteps  | 190000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1904     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17431    |\n",
      "|    total_timesteps  | 190400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 47349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=190500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 190500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00091  |\n",
      "|    n_updates        | 47374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.02    |\n",
      "|    exploration_rate | 0.773    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1908     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17475    |\n",
      "|    total_timesteps  | 190800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 47449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=191000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.773    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 191000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000429 |\n",
      "|    n_updates        | 47499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.773    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1912     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17516    |\n",
      "|    total_timesteps  | 191200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 47549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=191500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.773    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 191500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 47624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1916     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17552    |\n",
      "|    total_timesteps  | 191600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000773 |\n",
      "|    n_updates        | 47649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 192000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00923  |\n",
      "|    n_updates        | 47749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17597    |\n",
      "|    total_timesteps  | 192000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1924     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17620    |\n",
      "|    total_timesteps  | 192400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00466  |\n",
      "|    n_updates        | 47849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=192500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.771    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 192500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00938  |\n",
      "|    n_updates        | 47874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.771    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1928     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17663    |\n",
      "|    total_timesteps  | 192800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000988 |\n",
      "|    n_updates        | 47949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=193000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.771    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 193000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0006   |\n",
      "|    n_updates        | 47999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.771    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1932     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17706    |\n",
      "|    total_timesteps  | 193200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00057  |\n",
      "|    n_updates        | 48049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=193500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 193500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 48124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1936     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17753    |\n",
      "|    total_timesteps  | 193600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 48149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=194000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 194000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000765 |\n",
      "|    n_updates        | 48249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.02    |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17788    |\n",
      "|    total_timesteps  | 194000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.769    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1944     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17813    |\n",
      "|    total_timesteps  | 194400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000269 |\n",
      "|    n_updates        | 48349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=194500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.769    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 194500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000156 |\n",
      "|    n_updates        | 48374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.769    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1948     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17855    |\n",
      "|    total_timesteps  | 194800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000591 |\n",
      "|    n_updates        | 48449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 195000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00043  |\n",
      "|    n_updates        | 48499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1952     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17890    |\n",
      "|    total_timesteps  | 195200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00978  |\n",
      "|    n_updates        | 48549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=195500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 195500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000852 |\n",
      "|    n_updates        | 48624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1956     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17934    |\n",
      "|    total_timesteps  | 195600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 48649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=196000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.767    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 196000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000329 |\n",
      "|    n_updates        | 48749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.767    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17980    |\n",
      "|    total_timesteps  | 196000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.767    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1964     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18002    |\n",
      "|    total_timesteps  | 196400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000601 |\n",
      "|    n_updates        | 48849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=196500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.767    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 196500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 48874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.766    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1968     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18046    |\n",
      "|    total_timesteps  | 196800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 48949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=197000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.766    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 197000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000932 |\n",
      "|    n_updates        | 48999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.766    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1972     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18083    |\n",
      "|    total_timesteps  | 197200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 49049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=197500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 197500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000294 |\n",
      "|    n_updates        | 49124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1976     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18124    |\n",
      "|    total_timesteps  | 197600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000495 |\n",
      "|    n_updates        | 49149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=198000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 198000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000436 |\n",
      "|    n_updates        | 49249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18170    |\n",
      "|    total_timesteps  | 198000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.764    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1984     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18193    |\n",
      "|    total_timesteps  | 198400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 49349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=198500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.764    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 198500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000759 |\n",
      "|    n_updates        | 49374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.764    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1988     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18231    |\n",
      "|    total_timesteps  | 198800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000589 |\n",
      "|    n_updates        | 49449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=199000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.764    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 199000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000625 |\n",
      "|    n_updates        | 49499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1992     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18271    |\n",
      "|    total_timesteps  | 199200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000887 |\n",
      "|    n_updates        | 49549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=199500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 199500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000314 |\n",
      "|    n_updates        | 49624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1996     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18315    |\n",
      "|    total_timesteps  | 199600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00517  |\n",
      "|    n_updates        | 49649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00035  |\n",
      "|    n_updates        | 49749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18352    |\n",
      "|    total_timesteps  | 200000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2004     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18382    |\n",
      "|    total_timesteps  | 200400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 49849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 49874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2008     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18417    |\n",
      "|    total_timesteps  | 200800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000904 |\n",
      "|    n_updates        | 49949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=201000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 201000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 49999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2012     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18461    |\n",
      "|    total_timesteps  | 201200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00516  |\n",
      "|    n_updates        | 50049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=201500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 201500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 50124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2016     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18505    |\n",
      "|    total_timesteps  | 201600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000682 |\n",
      "|    n_updates        | 50149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=202000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 202000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00796  |\n",
      "|    n_updates        | 50249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18540    |\n",
      "|    total_timesteps  | 202000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2024     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18573    |\n",
      "|    total_timesteps  | 202400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 50349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=202500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 202500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 50374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2028     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18612    |\n",
      "|    total_timesteps  | 202800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000685 |\n",
      "|    n_updates        | 50449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=203000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 203000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000694 |\n",
      "|    n_updates        | 50499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2032     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18653    |\n",
      "|    total_timesteps  | 203200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000356 |\n",
      "|    n_updates        | 50549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=203500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 203500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000617 |\n",
      "|    n_updates        | 50624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2036     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18693    |\n",
      "|    total_timesteps  | 203600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 50649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=204000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 204000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00569  |\n",
      "|    n_updates        | 50749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18730    |\n",
      "|    total_timesteps  | 204000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2044     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18762    |\n",
      "|    total_timesteps  | 204400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00983  |\n",
      "|    n_updates        | 50849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=204500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 204500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 50874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2048     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18798    |\n",
      "|    total_timesteps  | 204800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 50949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 205000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 50999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.756    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2052     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18842    |\n",
      "|    total_timesteps  | 205200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 51049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=205500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.756    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 205500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 51124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.756    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2056     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18879    |\n",
      "|    total_timesteps  | 205600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000717 |\n",
      "|    n_updates        | 51149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=206000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 206000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000493 |\n",
      "|    n_updates        | 51249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18923    |\n",
      "|    total_timesteps  | 206000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2064     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18948    |\n",
      "|    total_timesteps  | 206400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00422  |\n",
      "|    n_updates        | 51349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=206500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 206500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000931 |\n",
      "|    n_updates        | 51374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2068     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 18994    |\n",
      "|    total_timesteps  | 206800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000643 |\n",
      "|    n_updates        | 51449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=207000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 207000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000362 |\n",
      "|    n_updates        | 51499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2072     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19038    |\n",
      "|    total_timesteps  | 207200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 51549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=207500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 207500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 51624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.753    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2076     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19074    |\n",
      "|    total_timesteps  | 207600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000875 |\n",
      "|    n_updates        | 51649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.753    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 208000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000618 |\n",
      "|    n_updates        | 51749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.753    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19120    |\n",
      "|    total_timesteps  | 208000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.753    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2084     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19142    |\n",
      "|    total_timesteps  | 208400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 51849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=208500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 208500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000293 |\n",
      "|    n_updates        | 51874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.02    |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2088     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19183    |\n",
      "|    total_timesteps  | 208800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000656 |\n",
      "|    n_updates        | 51949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=209000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 209000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 51999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2092     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19223    |\n",
      "|    total_timesteps  | 209200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000746 |\n",
      "|    n_updates        | 52049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=209500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 209500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 52124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2096     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19265    |\n",
      "|    total_timesteps  | 209600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 52149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 210000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 52249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19311    |\n",
      "|    total_timesteps  | 210000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.75     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2104     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19334    |\n",
      "|    total_timesteps  | 210400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 52349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=210500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.75     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 210500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 52374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.75     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2108     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19376    |\n",
      "|    total_timesteps  | 210800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 52449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=211000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 211000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00094  |\n",
      "|    n_updates        | 52499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2112     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19413    |\n",
      "|    total_timesteps  | 211200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000928 |\n",
      "|    n_updates        | 52549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=211500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 211500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000558 |\n",
      "|    n_updates        | 52624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2116     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19459    |\n",
      "|    total_timesteps  | 211600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000304 |\n",
      "|    n_updates        | 52649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=212000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 212000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 52749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19504    |\n",
      "|    total_timesteps  | 212000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2124     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19527    |\n",
      "|    total_timesteps  | 212400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00633  |\n",
      "|    n_updates        | 52849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=212500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 212500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000501 |\n",
      "|    n_updates        | 52874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.08    |\n",
      "|    exploration_rate | 0.747    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2128     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19567    |\n",
      "|    total_timesteps  | 212800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00039  |\n",
      "|    n_updates        | 52949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=213000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.747    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 213000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000679 |\n",
      "|    n_updates        | 52999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.747    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2132     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19607    |\n",
      "|    total_timesteps  | 213200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 53049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=213500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.746    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 213500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000492 |\n",
      "|    n_updates        | 53124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.746    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2136     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19651    |\n",
      "|    total_timesteps  | 213600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000375 |\n",
      "|    n_updates        | 53149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=214000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.746    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 214000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00957  |\n",
      "|    n_updates        | 53249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.746    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19691    |\n",
      "|    total_timesteps  | 214000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2144     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19714    |\n",
      "|    total_timesteps  | 214400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000801 |\n",
      "|    n_updates        | 53349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=214500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 214500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000653 |\n",
      "|    n_updates        | 53374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2148     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19761    |\n",
      "|    total_timesteps  | 214800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000309 |\n",
      "|    n_updates        | 53449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 215000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 53499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.744    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2152     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19799    |\n",
      "|    total_timesteps  | 215200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 53549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=215500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.744    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 215500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000639 |\n",
      "|    n_updates        | 53624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.17    |\n",
      "|    exploration_rate | 0.744    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2156     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19839    |\n",
      "|    total_timesteps  | 215600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000906 |\n",
      "|    n_updates        | 53649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=216000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.744    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 216000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 53749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.18    |\n",
      "|    exploration_rate | 0.744    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19882    |\n",
      "|    total_timesteps  | 216000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2164     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19906    |\n",
      "|    total_timesteps  | 216400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00073  |\n",
      "|    n_updates        | 53849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=216500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 216500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000459 |\n",
      "|    n_updates        | 53874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2168     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19950    |\n",
      "|    total_timesteps  | 216800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00087  |\n",
      "|    n_updates        | 53949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=217000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 217000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000839 |\n",
      "|    n_updates        | 53999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2172     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 19994    |\n",
      "|    total_timesteps  | 217200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000778 |\n",
      "|    n_updates        | 54049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=217500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 217500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 54124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2176     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20029    |\n",
      "|    total_timesteps  | 217600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 54149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=218000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 218000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000634 |\n",
      "|    n_updates        | 54249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20073    |\n",
      "|    total_timesteps  | 218000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2184     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20104    |\n",
      "|    total_timesteps  | 218400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000472 |\n",
      "|    n_updates        | 54349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=218500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 218500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000633 |\n",
      "|    n_updates        | 54374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.74     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2188     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20147    |\n",
      "|    total_timesteps  | 218800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000658 |\n",
      "|    n_updates        | 54449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=219000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.74     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 219000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000999 |\n",
      "|    n_updates        | 54499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.74     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2192     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20183    |\n",
      "|    total_timesteps  | 219200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000907 |\n",
      "|    n_updates        | 54549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=219500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 219500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 54624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2196     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20227    |\n",
      "|    total_timesteps  | 219600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000373 |\n",
      "|    n_updates        | 54649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 220000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000413 |\n",
      "|    n_updates        | 54749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20268    |\n",
      "|    total_timesteps  | 220000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2204     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20297    |\n",
      "|    total_timesteps  | 220400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 54849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=220500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 220500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 54874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2208     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20338    |\n",
      "|    total_timesteps  | 220800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00301  |\n",
      "|    n_updates        | 54949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=221000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 221000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 54999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.737    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2212     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20381    |\n",
      "|    total_timesteps  | 221200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000878 |\n",
      "|    n_updates        | 55049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=221500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.737    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 221500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000721 |\n",
      "|    n_updates        | 55124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.02    |\n",
      "|    exploration_rate | 0.737    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2216     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20424    |\n",
      "|    total_timesteps  | 221600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 55149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=222000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 222000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000836 |\n",
      "|    n_updates        | 55249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.02    |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20462    |\n",
      "|    total_timesteps  | 222000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2224     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20491    |\n",
      "|    total_timesteps  | 222400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 55349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=222500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 222500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000885 |\n",
      "|    n_updates        | 55374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2228     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20538    |\n",
      "|    total_timesteps  | 222800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000888 |\n",
      "|    n_updates        | 55449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=223000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 223000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 55499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2232     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20573    |\n",
      "|    total_timesteps  | 223200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000935 |\n",
      "|    n_updates        | 55549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=223500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 223500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000715 |\n",
      "|    n_updates        | 55624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2236     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20614    |\n",
      "|    total_timesteps  | 223600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000539 |\n",
      "|    n_updates        | 55649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 224000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000694 |\n",
      "|    n_updates        | 55749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20658    |\n",
      "|    total_timesteps  | 224000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2244     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20682    |\n",
      "|    total_timesteps  | 224400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000365 |\n",
      "|    n_updates        | 55849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=224500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.733    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 224500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000558 |\n",
      "|    n_updates        | 55874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.733    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2248     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20722    |\n",
      "|    total_timesteps  | 224800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000822 |\n",
      "|    n_updates        | 55949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.733    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 225000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000735 |\n",
      "|    n_updates        | 55999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.733    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2252     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20763    |\n",
      "|    total_timesteps  | 225200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000688 |\n",
      "|    n_updates        | 56049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=225500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.732    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 225500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000442 |\n",
      "|    n_updates        | 56124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.732    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2256     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20806    |\n",
      "|    total_timesteps  | 225600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 56149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=226000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.732    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 226000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000803 |\n",
      "|    n_updates        | 56249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.732    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20849    |\n",
      "|    total_timesteps  | 226000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.731    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2264     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20872    |\n",
      "|    total_timesteps  | 226400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000615 |\n",
      "|    n_updates        | 56349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=226500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.731    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 226500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 56374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.731    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2268     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20917    |\n",
      "|    total_timesteps  | 226800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000534 |\n",
      "|    n_updates        | 56449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=227000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 227000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000316 |\n",
      "|    n_updates        | 56499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2272     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 20964    |\n",
      "|    total_timesteps  | 227200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000292 |\n",
      "|    n_updates        | 56549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=227500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 227500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 56624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2276     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21000    |\n",
      "|    total_timesteps  | 227600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 56649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=228000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.729    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 228000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 56749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.729    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21046    |\n",
      "|    total_timesteps  | 228000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.729    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2284     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21069    |\n",
      "|    total_timesteps  | 228400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000396 |\n",
      "|    n_updates        | 56849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=228500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.729    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 228500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 56874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.82    |\n",
      "|    exploration_rate | 0.728    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2288     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21116    |\n",
      "|    total_timesteps  | 228800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 56949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=229000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.728    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 229000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 56999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.728    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2292     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21155    |\n",
      "|    total_timesteps  | 229200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000552 |\n",
      "|    n_updates        | 57049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=229500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 229500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000407 |\n",
      "|    n_updates        | 57124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2296     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21197    |\n",
      "|    total_timesteps  | 229600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000419 |\n",
      "|    n_updates        | 57149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 230000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 57249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21239    |\n",
      "|    total_timesteps  | 230000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2304     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21263    |\n",
      "|    total_timesteps  | 230400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000982 |\n",
      "|    n_updates        | 57349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=230500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 230500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 57374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.82    |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2308     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21307    |\n",
      "|    total_timesteps  | 230800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000778 |\n",
      "|    n_updates        | 57449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=231000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 231000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 57499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.725    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2312     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21348    |\n",
      "|    total_timesteps  | 231200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000626 |\n",
      "|    n_updates        | 57549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=231500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.725    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 231500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 57624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.725    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2316     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21387    |\n",
      "|    total_timesteps  | 231600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000733 |\n",
      "|    n_updates        | 57649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=232000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.725    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 232000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 57749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.82    |\n",
      "|    exploration_rate | 0.725    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21426    |\n",
      "|    total_timesteps  | 232000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2324     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21461    |\n",
      "|    total_timesteps  | 232400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000431 |\n",
      "|    n_updates        | 57849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=232500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 232500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000724 |\n",
      "|    n_updates        | 57874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2328     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21499    |\n",
      "|    total_timesteps  | 232800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 57949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=233000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 233000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000988 |\n",
      "|    n_updates        | 57999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2332     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21543    |\n",
      "|    total_timesteps  | 233200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000576 |\n",
      "|    n_updates        | 58049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=233500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 233500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00049  |\n",
      "|    n_updates        | 58124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2336     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21588    |\n",
      "|    total_timesteps  | 233600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 58149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=234000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 234000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00671  |\n",
      "|    n_updates        | 58249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.78    |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21624    |\n",
      "|    total_timesteps  | 234000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2344     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21652    |\n",
      "|    total_timesteps  | 234400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000852 |\n",
      "|    n_updates        | 58349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=234500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 234500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00039  |\n",
      "|    n_updates        | 58374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2348     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21692    |\n",
      "|    total_timesteps  | 234800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000645 |\n",
      "|    n_updates        | 58449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 235000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 58499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2352     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21733    |\n",
      "|    total_timesteps  | 235200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 58549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=235500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 235500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000502 |\n",
      "|    n_updates        | 58624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2356     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21774    |\n",
      "|    total_timesteps  | 235600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 58649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=236000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 236000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000982 |\n",
      "|    n_updates        | 58749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21814    |\n",
      "|    total_timesteps  | 236000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2364     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21839    |\n",
      "|    total_timesteps  | 236400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000832 |\n",
      "|    n_updates        | 58849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=236500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 236500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000575 |\n",
      "|    n_updates        | 58874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2368     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21878    |\n",
      "|    total_timesteps  | 236800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0074   |\n",
      "|    n_updates        | 58949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=237000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 237000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000398 |\n",
      "|    n_updates        | 58999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.718    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2372     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21920    |\n",
      "|    total_timesteps  | 237200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000711 |\n",
      "|    n_updates        | 59049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=237500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.718    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 237500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 59124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.718    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2376     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 21965    |\n",
      "|    total_timesteps  | 237600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000913 |\n",
      "|    n_updates        | 59149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=238000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.717    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 238000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 59249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.717    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22009    |\n",
      "|    total_timesteps  | 238000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.717    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2384     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22032    |\n",
      "|    total_timesteps  | 238400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 59349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=238500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.717    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 238500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 59374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2388     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22076    |\n",
      "|    total_timesteps  | 238800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00086  |\n",
      "|    n_updates        | 59449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=239000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 239000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000937 |\n",
      "|    n_updates        | 59499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2392     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22117    |\n",
      "|    total_timesteps  | 239200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000464 |\n",
      "|    n_updates        | 59549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=239500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 239500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000684 |\n",
      "|    n_updates        | 59624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2396     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22156    |\n",
      "|    total_timesteps  | 239600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000887 |\n",
      "|    n_updates        | 59649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 240000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000472 |\n",
      "|    n_updates        | 59749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22201    |\n",
      "|    total_timesteps  | 240000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2404     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22226    |\n",
      "|    total_timesteps  | 240400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 59849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=240500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 240500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 59874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2408     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22271    |\n",
      "|    total_timesteps  | 240800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 59949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=241000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 241000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 59999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2412     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22309    |\n",
      "|    total_timesteps  | 241200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000478 |\n",
      "|    n_updates        | 60049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=241500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 241500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000503 |\n",
      "|    n_updates        | 60124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2416     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22355    |\n",
      "|    total_timesteps  | 241600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 60149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=242000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 242000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00631  |\n",
      "|    n_updates        | 60249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22392    |\n",
      "|    total_timesteps  | 242000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2424     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22423    |\n",
      "|    total_timesteps  | 242400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000857 |\n",
      "|    n_updates        | 60349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=242500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 242500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000802 |\n",
      "|    n_updates        | 60374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2428     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22461    |\n",
      "|    total_timesteps  | 242800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 60449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=243000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 243000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 60499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2432     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22506    |\n",
      "|    total_timesteps  | 243200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000407 |\n",
      "|    n_updates        | 60549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=243500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 243500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000566 |\n",
      "|    n_updates        | 60624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2436     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22551    |\n",
      "|    total_timesteps  | 243600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 60649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=244000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.71     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 244000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000696 |\n",
      "|    n_updates        | 60749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.71     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22588    |\n",
      "|    total_timesteps  | 244000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.71     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2444     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22624    |\n",
      "|    total_timesteps  | 244400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000796 |\n",
      "|    n_updates        | 60849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=244500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.71     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 244500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000431 |\n",
      "|    n_updates        | 60874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.709    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2448     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22660    |\n",
      "|    total_timesteps  | 244800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 60949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.709    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 245000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 60999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.709    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2452     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22706    |\n",
      "|    total_timesteps  | 245200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0006   |\n",
      "|    n_updates        | 61049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=245500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 245500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000662 |\n",
      "|    n_updates        | 61124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22744    |\n",
      "|    total_timesteps  | 245600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000735 |\n",
      "|    n_updates        | 61149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=246000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 246000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000954 |\n",
      "|    n_updates        | 61249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22788    |\n",
      "|    total_timesteps  | 246000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.707    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2464     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22813    |\n",
      "|    total_timesteps  | 246400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00054  |\n",
      "|    n_updates        | 61349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=246500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.707    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 246500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 61374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.707    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2468     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22858    |\n",
      "|    total_timesteps  | 246800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000754 |\n",
      "|    n_updates        | 61449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=247000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.707    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 247000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0044   |\n",
      "|    n_updates        | 61499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2472     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22894    |\n",
      "|    total_timesteps  | 247200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 61549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=247500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 247500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00431  |\n",
      "|    n_updates        | 61624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22941    |\n",
      "|    total_timesteps  | 247600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00099  |\n",
      "|    n_updates        | 61649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=248000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 248000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 61749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 22986    |\n",
      "|    total_timesteps  | 248000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2484     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23009    |\n",
      "|    total_timesteps  | 248400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00035  |\n",
      "|    n_updates        | 61849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=248500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 248500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000998 |\n",
      "|    n_updates        | 61874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23053    |\n",
      "|    total_timesteps  | 248800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0008   |\n",
      "|    n_updates        | 61949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=249000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.704    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 249000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0005   |\n",
      "|    n_updates        | 61999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.704    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23091    |\n",
      "|    total_timesteps  | 249200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000683 |\n",
      "|    n_updates        | 62049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=249500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.704    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 249500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 62124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.704    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23133    |\n",
      "|    total_timesteps  | 249600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000598 |\n",
      "|    n_updates        | 62149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 62249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23176    |\n",
      "|    total_timesteps  | 250000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23200    |\n",
      "|    total_timesteps  | 250400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000577 |\n",
      "|    n_updates        | 62349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=250500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 62374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.702    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2508     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23242    |\n",
      "|    total_timesteps  | 250800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 62449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=251000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.702    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 251000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000969 |\n",
      "|    n_updates        | 62499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.702    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23284    |\n",
      "|    total_timesteps  | 251200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 62549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=251500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 251500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 62624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23328    |\n",
      "|    total_timesteps  | 251600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000776 |\n",
      "|    n_updates        | 62649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=252000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 252000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000523 |\n",
      "|    n_updates        | 62749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23373    |\n",
      "|    total_timesteps  | 252000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.7      |\n",
      "| time/               |          |\n",
      "|    episodes         | 2524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23397    |\n",
      "|    total_timesteps  | 252400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000855 |\n",
      "|    n_updates        | 62849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=252500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.7      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 252500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 62874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.7      |\n",
      "| time/               |          |\n",
      "|    episodes         | 2528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23444    |\n",
      "|    total_timesteps  | 252800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 62949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=253000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.7      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 253000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 62999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23480    |\n",
      "|    total_timesteps  | 253200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000778 |\n",
      "|    n_updates        | 63049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=253500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 253500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 63124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23527    |\n",
      "|    total_timesteps  | 253600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000503 |\n",
      "|    n_updates        | 63149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=254000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 254000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 63249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23571    |\n",
      "|    total_timesteps  | 254000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23595    |\n",
      "|    total_timesteps  | 254400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000616 |\n",
      "|    n_updates        | 63349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=254500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 254500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000625 |\n",
      "|    n_updates        | 63374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23641    |\n",
      "|    total_timesteps  | 254800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000857 |\n",
      "|    n_updates        | 63449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 255000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000631 |\n",
      "|    n_updates        | 63499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23679    |\n",
      "|    total_timesteps  | 255200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 63549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=255500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 255500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 63624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23721    |\n",
      "|    total_timesteps  | 255600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 63649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 256000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000595 |\n",
      "|    n_updates        | 63749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.78    |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23765    |\n",
      "|    total_timesteps  | 256000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.78    |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23791    |\n",
      "|    total_timesteps  | 256400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000472 |\n",
      "|    n_updates        | 63849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=256500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 256500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000705 |\n",
      "|    n_updates        | 63874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23832    |\n",
      "|    total_timesteps  | 256800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000731 |\n",
      "|    n_updates        | 63949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=257000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 257000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000507 |\n",
      "|    n_updates        | 63999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23880    |\n",
      "|    total_timesteps  | 257200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 64049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=257500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 257500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000676 |\n",
      "|    n_updates        | 64124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23916    |\n",
      "|    total_timesteps  | 257600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 64149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=258000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 258000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000559 |\n",
      "|    n_updates        | 64249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.78    |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23960    |\n",
      "|    total_timesteps  | 258000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 23984    |\n",
      "|    total_timesteps  | 258400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 64349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=258500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 258500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 64374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24029    |\n",
      "|    total_timesteps  | 258800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 64449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=259000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 259000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000804 |\n",
      "|    n_updates        | 64499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24068    |\n",
      "|    total_timesteps  | 259200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00091  |\n",
      "|    n_updates        | 64549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=259500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 259500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000389 |\n",
      "|    n_updates        | 64624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24114    |\n",
      "|    total_timesteps  | 259600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000334 |\n",
      "|    n_updates        | 64649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 260000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000289 |\n",
      "|    n_updates        | 64749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24150    |\n",
      "|    total_timesteps  | 260000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24183    |\n",
      "|    total_timesteps  | 260400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00063  |\n",
      "|    n_updates        | 64849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=260500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 260500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000837 |\n",
      "|    n_updates        | 64874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.69     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24222    |\n",
      "|    total_timesteps  | 260800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000657 |\n",
      "|    n_updates        | 64949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=261000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.69     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 261000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000902 |\n",
      "|    n_updates        | 64999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.69     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24265    |\n",
      "|    total_timesteps  | 261200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 65049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=261500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.689    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 261500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 65124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.689    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24312    |\n",
      "|    total_timesteps  | 261600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 65149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=262000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.689    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 262000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000834 |\n",
      "|    n_updates        | 65249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.689    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24349    |\n",
      "|    total_timesteps  | 262000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24381    |\n",
      "|    total_timesteps  | 262400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 65349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=262500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 262500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000908 |\n",
      "|    n_updates        | 65374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24418    |\n",
      "|    total_timesteps  | 262800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000862 |\n",
      "|    n_updates        | 65449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=263000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 263000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 65499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.687    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24465    |\n",
      "|    total_timesteps  | 263200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000488 |\n",
      "|    n_updates        | 65549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=263500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.687    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 263500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00042  |\n",
      "|    n_updates        | 65624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.687    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24509    |\n",
      "|    total_timesteps  | 263600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000806 |\n",
      "|    n_updates        | 65649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=264000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.687    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 264000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000828 |\n",
      "|    n_updates        | 65749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24546    |\n",
      "|    total_timesteps  | 264000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24577    |\n",
      "|    total_timesteps  | 264400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00096  |\n",
      "|    n_updates        | 65849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=264500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 264500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000808 |\n",
      "|    n_updates        | 65874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24620    |\n",
      "|    total_timesteps  | 264800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000835 |\n",
      "|    n_updates        | 65949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.685    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 265000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 65999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.685    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24658    |\n",
      "|    total_timesteps  | 265200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 66049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=265500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.685    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 265500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000359 |\n",
      "|    n_updates        | 66124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.685    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24700    |\n",
      "|    total_timesteps  | 265600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000486 |\n",
      "|    n_updates        | 66149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=266000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 266000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000748 |\n",
      "|    n_updates        | 66249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24745    |\n",
      "|    total_timesteps  | 266000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24769    |\n",
      "|    total_timesteps  | 266400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 66349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=266500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 266500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000585 |\n",
      "|    n_updates        | 66374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24815    |\n",
      "|    total_timesteps  | 266800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000765 |\n",
      "|    n_updates        | 66449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=267000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 267000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 66499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24855    |\n",
      "|    total_timesteps  | 267200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 66549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=267500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 267500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000528 |\n",
      "|    n_updates        | 66624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24897    |\n",
      "|    total_timesteps  | 267600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000575 |\n",
      "|    n_updates        | 66649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=268000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 268000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000894 |\n",
      "|    n_updates        | 66749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24940    |\n",
      "|    total_timesteps  | 268000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.681    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 24964    |\n",
      "|    total_timesteps  | 268400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000352 |\n",
      "|    n_updates        | 66849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=268500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.681    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 268500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000924 |\n",
      "|    n_updates        | 66874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.681    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25008    |\n",
      "|    total_timesteps  | 268800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000299 |\n",
      "|    n_updates        | 66949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=269000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.681    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 269000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00886  |\n",
      "|    n_updates        | 66999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.68     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25052    |\n",
      "|    total_timesteps  | 269200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 67049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=269500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.68     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 269500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000571 |\n",
      "|    n_updates        | 67124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.68     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25098    |\n",
      "|    total_timesteps  | 269600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000751 |\n",
      "|    n_updates        | 67149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 270000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000626 |\n",
      "|    n_updates        | 67249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25134    |\n",
      "|    total_timesteps  | 270000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.59    |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25167    |\n",
      "|    total_timesteps  | 270400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000579 |\n",
      "|    n_updates        | 67349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=270500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 270500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 67374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25208    |\n",
      "|    total_timesteps  | 270800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 67449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=271000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 271000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000675 |\n",
      "|    n_updates        | 67499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2712     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25247    |\n",
      "|    total_timesteps  | 271200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000884 |\n",
      "|    n_updates        | 67549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=271500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 271500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 67624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.677    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2716     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25293    |\n",
      "|    total_timesteps  | 271600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 67649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.677    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 272000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 67749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.677    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2720     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25335    |\n",
      "|    total_timesteps  | 272000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.677    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2724     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25359    |\n",
      "|    total_timesteps  | 272400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 67849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=272500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 272500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000844 |\n",
      "|    n_updates        | 67874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2728     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25401    |\n",
      "|    total_timesteps  | 272800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000758 |\n",
      "|    n_updates        | 67949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=273000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 273000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00285  |\n",
      "|    n_updates        | 67999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2732     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25442    |\n",
      "|    total_timesteps  | 273200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 68049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=273500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 273500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000566 |\n",
      "|    n_updates        | 68124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2736     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25484    |\n",
      "|    total_timesteps  | 273600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 68149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=274000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 274000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 68249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2740     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25529    |\n",
      "|    total_timesteps  | 274000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.674    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2744     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25552    |\n",
      "|    total_timesteps  | 274400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 68349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=274500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.674    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 274500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000986 |\n",
      "|    n_updates        | 68374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.674    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2748     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25598    |\n",
      "|    total_timesteps  | 274800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00059  |\n",
      "|    n_updates        | 68449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 275000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000529 |\n",
      "|    n_updates        | 68499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2752     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25634    |\n",
      "|    total_timesteps  | 275200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 68549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=275500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 275500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000778 |\n",
      "|    n_updates        | 68624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2756     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25679    |\n",
      "|    total_timesteps  | 275600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00428  |\n",
      "|    n_updates        | 68649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=276000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.672    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 276000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000373 |\n",
      "|    n_updates        | 68749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.672    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2760     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25723    |\n",
      "|    total_timesteps  | 276000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.672    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2764     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25747    |\n",
      "|    total_timesteps  | 276400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000492 |\n",
      "|    n_updates        | 68849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=276500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.672    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 276500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00064  |\n",
      "|    n_updates        | 68874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2768     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25796    |\n",
      "|    total_timesteps  | 276800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 68949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=277000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 277000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000405 |\n",
      "|    n_updates        | 68999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2772     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25832    |\n",
      "|    total_timesteps  | 277200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000797 |\n",
      "|    n_updates        | 69049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=277500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.67     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 277500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000416 |\n",
      "|    n_updates        | 69124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.67     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2776     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25880    |\n",
      "|    total_timesteps  | 277600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00075  |\n",
      "|    n_updates        | 69149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=278000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.67     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 278000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00061  |\n",
      "|    n_updates        | 69249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.67     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2780     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25921    |\n",
      "|    total_timesteps  | 278000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.669    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2784     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25946    |\n",
      "|    total_timesteps  | 278400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000292 |\n",
      "|    n_updates        | 69349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=278500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.669    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 278500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00704  |\n",
      "|    n_updates        | 69374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.669    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2788     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 25991    |\n",
      "|    total_timesteps  | 278800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000456 |\n",
      "|    n_updates        | 69449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=279000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.669    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 279000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000758 |\n",
      "|    n_updates        | 69499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2792     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26031    |\n",
      "|    total_timesteps  | 279200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 69549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=279500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 279500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000684 |\n",
      "|    n_updates        | 69624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2796     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26071    |\n",
      "|    total_timesteps  | 279600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 69649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 280000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000922 |\n",
      "|    n_updates        | 69749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2800     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26117    |\n",
      "|    total_timesteps  | 280000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2804     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26141    |\n",
      "|    total_timesteps  | 280400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 69849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=280500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 280500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 69874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2808     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26183    |\n",
      "|    total_timesteps  | 280800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 69949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=281000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 281000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000674 |\n",
      "|    n_updates        | 69999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2812     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26229    |\n",
      "|    total_timesteps  | 281200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000967 |\n",
      "|    n_updates        | 70049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=281500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 281500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000633 |\n",
      "|    n_updates        | 70124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2816     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26272    |\n",
      "|    total_timesteps  | 281600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000609 |\n",
      "|    n_updates        | 70149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=282000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.665    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 282000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000728 |\n",
      "|    n_updates        | 70249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.665    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2820     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26309    |\n",
      "|    total_timesteps  | 282000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.665    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2824     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26340    |\n",
      "|    total_timesteps  | 282400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 70349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=282500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.665    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 282500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 70374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2828     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26382    |\n",
      "|    total_timesteps  | 282800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000609 |\n",
      "|    n_updates        | 70449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=283000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 283000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000776 |\n",
      "|    n_updates        | 70499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2832     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26422    |\n",
      "|    total_timesteps  | 283200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 70549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=283500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 283500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000511 |\n",
      "|    n_updates        | 70624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2836     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26464    |\n",
      "|    total_timesteps  | 283600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000952 |\n",
      "|    n_updates        | 70649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=284000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 284000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 70749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2840     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26505    |\n",
      "|    total_timesteps  | 284000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2844     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26531    |\n",
      "|    total_timesteps  | 284400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000672 |\n",
      "|    n_updates        | 70849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=284500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 284500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 70874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2848     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26574    |\n",
      "|    total_timesteps  | 284800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 70949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 285000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000353 |\n",
      "|    n_updates        | 70999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.661    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2852     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26612    |\n",
      "|    total_timesteps  | 285200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000422 |\n",
      "|    n_updates        | 71049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=285500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.661    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 285500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0462   |\n",
      "|    n_updates        | 71124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.661    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2856     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26656    |\n",
      "|    total_timesteps  | 285600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000817 |\n",
      "|    n_updates        | 71149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=286000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.66     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 286000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000361 |\n",
      "|    n_updates        | 71249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.66     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2860     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26703    |\n",
      "|    total_timesteps  | 286000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.66     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2864     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26727    |\n",
      "|    total_timesteps  | 286400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000636 |\n",
      "|    n_updates        | 71349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=286500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.66     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 286500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00616  |\n",
      "|    n_updates        | 71374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2868     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26774    |\n",
      "|    total_timesteps  | 286800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00045  |\n",
      "|    n_updates        | 71449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=287000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 287000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000656 |\n",
      "|    n_updates        | 71499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2872     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26811    |\n",
      "|    total_timesteps  | 287200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000664 |\n",
      "|    n_updates        | 71549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=287500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 287500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000801 |\n",
      "|    n_updates        | 71624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2876     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26854    |\n",
      "|    total_timesteps  | 287600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000247 |\n",
      "|    n_updates        | 71649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 288000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 71749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2880     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26896    |\n",
      "|    total_timesteps  | 288000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2884     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26921    |\n",
      "|    total_timesteps  | 288400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 71849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=288500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.657    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 288500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 71874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.657    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2888     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 26967    |\n",
      "|    total_timesteps  | 288800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000309 |\n",
      "|    n_updates        | 71949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=289000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.657    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 289000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000735 |\n",
      "|    n_updates        | 71999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.657    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2892     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27013    |\n",
      "|    total_timesteps  | 289200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000497 |\n",
      "|    n_updates        | 72049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=289500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 289500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00685  |\n",
      "|    n_updates        | 72124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2896     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27055    |\n",
      "|    total_timesteps  | 289600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000337 |\n",
      "|    n_updates        | 72149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 290000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 72249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2900     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27092    |\n",
      "|    total_timesteps  | 290000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.655    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2904     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27124    |\n",
      "|    total_timesteps  | 290400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 72349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=290500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.655    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 290500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000509 |\n",
      "|    n_updates        | 72374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.655    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2908     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27168    |\n",
      "|    total_timesteps  | 290800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000539 |\n",
      "|    n_updates        | 72449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=291000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 291000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000892 |\n",
      "|    n_updates        | 72499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2912     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27209    |\n",
      "|    total_timesteps  | 291200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 72549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=291500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 291500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000919 |\n",
      "|    n_updates        | 72624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2916     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27249    |\n",
      "|    total_timesteps  | 291600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 72649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=292000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.653    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 292000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00548  |\n",
      "|    n_updates        | 72749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.653    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2920     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27288    |\n",
      "|    total_timesteps  | 292000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.653    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2924     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27316    |\n",
      "|    total_timesteps  | 292400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 72849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=292500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.653    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 292500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 72874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.652    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2928     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27358    |\n",
      "|    total_timesteps  | 292800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000875 |\n",
      "|    n_updates        | 72949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=293000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.652    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 293000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00082  |\n",
      "|    n_updates        | 72999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.652    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2932     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27405    |\n",
      "|    total_timesteps  | 293200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000494 |\n",
      "|    n_updates        | 73049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=293500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 293500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 73124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2936     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27441    |\n",
      "|    total_timesteps  | 293600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00391  |\n",
      "|    n_updates        | 73149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=294000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 294000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000823 |\n",
      "|    n_updates        | 73249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2940     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27486    |\n",
      "|    total_timesteps  | 294000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2944     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27510    |\n",
      "|    total_timesteps  | 294400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000644 |\n",
      "|    n_updates        | 73349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=294500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 294500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 73374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2948     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27554    |\n",
      "|    total_timesteps  | 294800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000447 |\n",
      "|    n_updates        | 73449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 295000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000809 |\n",
      "|    n_updates        | 73499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2952     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27597    |\n",
      "|    total_timesteps  | 295200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 73549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=295500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 295500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000474 |\n",
      "|    n_updates        | 73624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.59    |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2956     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27634    |\n",
      "|    total_timesteps  | 295600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 73649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=296000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 296000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000665 |\n",
      "|    n_updates        | 73749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.59    |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2960     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27679    |\n",
      "|    total_timesteps  | 296000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.648    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2964     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27712    |\n",
      "|    total_timesteps  | 296400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00879  |\n",
      "|    n_updates        | 73849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=296500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.648    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 296500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00828  |\n",
      "|    n_updates        | 73874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.57    |\n",
      "|    exploration_rate | 0.648    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2968     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27749    |\n",
      "|    total_timesteps  | 296800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000563 |\n",
      "|    n_updates        | 73949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=297000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 297000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 73999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.54    |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2972     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27794    |\n",
      "|    total_timesteps  | 297200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000968 |\n",
      "|    n_updates        | 74049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=297500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 297500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000598 |\n",
      "|    n_updates        | 74124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.53    |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2976     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27841    |\n",
      "|    total_timesteps  | 297600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 74149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=298000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 298000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000472 |\n",
      "|    n_updates        | 74249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2980     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27880    |\n",
      "|    total_timesteps  | 298000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2984     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27906    |\n",
      "|    total_timesteps  | 298400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000724 |\n",
      "|    n_updates        | 74349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=298500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 298500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000276 |\n",
      "|    n_updates        | 74374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.645    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2988     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27951    |\n",
      "|    total_timesteps  | 298800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000618 |\n",
      "|    n_updates        | 74449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=299000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.645    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 299000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000649 |\n",
      "|    n_updates        | 74499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.645    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2992     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 27990    |\n",
      "|    total_timesteps  | 299200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000248 |\n",
      "|    n_updates        | 74549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=299500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 299500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 74624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2996     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28033    |\n",
      "|    total_timesteps  | 299600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 74649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000606 |\n",
      "|    n_updates        | 74749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.48    |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3000     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28076    |\n",
      "|    total_timesteps  | 300000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.643    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3004     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28104    |\n",
      "|    total_timesteps  | 300400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 74849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=300500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.643    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 74874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.48    |\n",
      "|    exploration_rate | 0.643    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3008     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28145    |\n",
      "|    total_timesteps  | 300800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000409 |\n",
      "|    n_updates        | 74949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=301000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.643    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 301000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0069   |\n",
      "|    n_updates        | 74999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.642    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3012     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28191    |\n",
      "|    total_timesteps  | 301200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 75049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=301500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.642    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 301500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000802 |\n",
      "|    n_updates        | 75124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.49    |\n",
      "|    exploration_rate | 0.642    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3016     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28228    |\n",
      "|    total_timesteps  | 301600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 75149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=302000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 302000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000508 |\n",
      "|    n_updates        | 75249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3020     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28276    |\n",
      "|    total_timesteps  | 302000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3024     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28300    |\n",
      "|    total_timesteps  | 302400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 75349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=302500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 302500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000661 |\n",
      "|    n_updates        | 75374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3028     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28346    |\n",
      "|    total_timesteps  | 302800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 75449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=303000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 303000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000764 |\n",
      "|    n_updates        | 75499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3032     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28387    |\n",
      "|    total_timesteps  | 303200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000646 |\n",
      "|    n_updates        | 75549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=303500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 303500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000572 |\n",
      "|    n_updates        | 75624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3036     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28426    |\n",
      "|    total_timesteps  | 303600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000401 |\n",
      "|    n_updates        | 75649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 304000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000637 |\n",
      "|    n_updates        | 75749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3040     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28470    |\n",
      "|    total_timesteps  | 304000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3044     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28494    |\n",
      "|    total_timesteps  | 304400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000635 |\n",
      "|    n_updates        | 75849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=304500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.638    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 304500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 75874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.638    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3048     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28540    |\n",
      "|    total_timesteps  | 304800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000557 |\n",
      "|    n_updates        | 75949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=305000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.638    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 305000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000673 |\n",
      "|    n_updates        | 75999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.638    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3052     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28589    |\n",
      "|    total_timesteps  | 305200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00027  |\n",
      "|    n_updates        | 76049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=305500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 305500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000841 |\n",
      "|    n_updates        | 76124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3056     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28626    |\n",
      "|    total_timesteps  | 305600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00929  |\n",
      "|    n_updates        | 76149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=306000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 306000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000475 |\n",
      "|    n_updates        | 76249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3060     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28666    |\n",
      "|    total_timesteps  | 306000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.636    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3064     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28697    |\n",
      "|    total_timesteps  | 306400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000623 |\n",
      "|    n_updates        | 76349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=306500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.636    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 306500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000675 |\n",
      "|    n_updates        | 76374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.636    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3068     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28733    |\n",
      "|    total_timesteps  | 306800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000424 |\n",
      "|    n_updates        | 76449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=307000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 307000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00997  |\n",
      "|    n_updates        | 76499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3072     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28778    |\n",
      "|    total_timesteps  | 307200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00913  |\n",
      "|    n_updates        | 76549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=307500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 307500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000402 |\n",
      "|    n_updates        | 76624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3076     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28822    |\n",
      "|    total_timesteps  | 307600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000706 |\n",
      "|    n_updates        | 76649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=308000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 308000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000646 |\n",
      "|    n_updates        | 76749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3080     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28861    |\n",
      "|    total_timesteps  | 308000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3084     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28891    |\n",
      "|    total_timesteps  | 308400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000724 |\n",
      "|    n_updates        | 76849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=308500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 308500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000748 |\n",
      "|    n_updates        | 76874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.633    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3088     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28932    |\n",
      "|    total_timesteps  | 308800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 76949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=309000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.633    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 309000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 76999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.633    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3092     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 28974    |\n",
      "|    total_timesteps  | 309200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 77049    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=309500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 309500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 77124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3096     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29014    |\n",
      "|    total_timesteps  | 309600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000662 |\n",
      "|    n_updates        | 77149    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 310000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000656 |\n",
      "|    n_updates        | 77249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3100     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29058    |\n",
      "|    total_timesteps  | 310000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3104     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29082    |\n",
      "|    total_timesteps  | 310400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 77349    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=310500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 310500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000833 |\n",
      "|    n_updates        | 77374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3108     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29123    |\n",
      "|    total_timesteps  | 310800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 77449    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=311000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 311000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 77499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.63     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3112     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29163    |\n",
      "|    total_timesteps  | 311200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 77549    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=311500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.63     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 311500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000934 |\n",
      "|    n_updates        | 77624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.63     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3116     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29204    |\n",
      "|    total_timesteps  | 311600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00659  |\n",
      "|    n_updates        | 77649    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=312000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.63     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 312000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000523 |\n",
      "|    n_updates        | 77749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.629    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3120     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29252    |\n",
      "|    total_timesteps  | 312000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.629    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3124     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29276    |\n",
      "|    total_timesteps  | 312400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000761 |\n",
      "|    n_updates        | 77849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=312500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.629    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 312500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000905 |\n",
      "|    n_updates        | 77874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.629    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3128     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29323    |\n",
      "|    total_timesteps  | 312800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000766 |\n",
      "|    n_updates        | 77949    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=313000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 313000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000834 |\n",
      "|    n_updates        | 77999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3132     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29366    |\n",
      "|    total_timesteps  | 313182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000638 |\n",
      "|    n_updates        | 78045    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=313500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 313500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000766 |\n",
      "|    n_updates        | 78124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3136     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29403    |\n",
      "|    total_timesteps  | 313582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 78145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.627    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3140     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29434    |\n",
      "|    total_timesteps  | 313982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 78245    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=314000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.627    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 314000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000943 |\n",
      "|    n_updates        | 78249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.627    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3144     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29476    |\n",
      "|    total_timesteps  | 314382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000728 |\n",
      "|    n_updates        | 78345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=314500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.627    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 314500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 78374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.626    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3148     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29523    |\n",
      "|    total_timesteps  | 314782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000814 |\n",
      "|    n_updates        | 78445    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.626    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 315000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000425 |\n",
      "|    n_updates        | 78499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.626    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3152     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29560    |\n",
      "|    total_timesteps  | 315182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 78545    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=315500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 315500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 78624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3156     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29603    |\n",
      "|    total_timesteps  | 315582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000208 |\n",
      "|    n_updates        | 78645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3160     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29628    |\n",
      "|    total_timesteps  | 315982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000854 |\n",
      "|    n_updates        | 78745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=316000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 316000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000488 |\n",
      "|    n_updates        | 78749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3164     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29671    |\n",
      "|    total_timesteps  | 316382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000557 |\n",
      "|    n_updates        | 78845    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=316500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 316500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 78874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3168     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29715    |\n",
      "|    total_timesteps  | 316782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 78945    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=317000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 317000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000497 |\n",
      "|    n_updates        | 78999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.623    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3172     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29759    |\n",
      "|    total_timesteps  | 317182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 79045    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=317500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.623    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 317500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00069  |\n",
      "|    n_updates        | 79124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.623    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3176     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29801    |\n",
      "|    total_timesteps  | 317582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000899 |\n",
      "|    n_updates        | 79145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3180     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29825    |\n",
      "|    total_timesteps  | 317982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 79245    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=318000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 318000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 79249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3184     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29870    |\n",
      "|    total_timesteps  | 318382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00838  |\n",
      "|    n_updates        | 79345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=318500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 318500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000364 |\n",
      "|    n_updates        | 79374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.621    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3188     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29913    |\n",
      "|    total_timesteps  | 318782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00189  |\n",
      "|    n_updates        | 79445    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=319000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.621    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 319000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000439 |\n",
      "|    n_updates        | 79499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.621    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3192     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29952    |\n",
      "|    total_timesteps  | 319182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000555 |\n",
      "|    n_updates        | 79545    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=319500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.621    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 319500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000471 |\n",
      "|    n_updates        | 79624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3196     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 29993    |\n",
      "|    total_timesteps  | 319582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000842 |\n",
      "|    n_updates        | 79645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3200     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30019    |\n",
      "|    total_timesteps  | 319982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000414 |\n",
      "|    n_updates        | 79745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 320000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00817  |\n",
      "|    n_updates        | 79749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3204     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30061    |\n",
      "|    total_timesteps  | 320382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000831 |\n",
      "|    n_updates        | 79845    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=320500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 320500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0062   |\n",
      "|    n_updates        | 79874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3208     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30107    |\n",
      "|    total_timesteps  | 320782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 79945    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=321000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 321000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000998 |\n",
      "|    n_updates        | 79999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3212     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30143    |\n",
      "|    total_timesteps  | 321182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00612  |\n",
      "|    n_updates        | 80045    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=321500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.618    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 321500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000834 |\n",
      "|    n_updates        | 80124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.618    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3216     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30187    |\n",
      "|    total_timesteps  | 321582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000547 |\n",
      "|    n_updates        | 80145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.618    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3220     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30212    |\n",
      "|    total_timesteps  | 321982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000477 |\n",
      "|    n_updates        | 80245    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=322000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.618    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 322000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000799 |\n",
      "|    n_updates        | 80249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.617    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3224     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30259    |\n",
      "|    total_timesteps  | 322382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000875 |\n",
      "|    n_updates        | 80345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=322500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.617    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 322500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000895 |\n",
      "|    n_updates        | 80374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.617    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3228     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30299    |\n",
      "|    total_timesteps  | 322782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000691 |\n",
      "|    n_updates        | 80445    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=323000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 323000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00956  |\n",
      "|    n_updates        | 80499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3232     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30339    |\n",
      "|    total_timesteps  | 323182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 80545    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=323500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 323500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000841 |\n",
      "|    n_updates        | 80624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3236     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30382    |\n",
      "|    total_timesteps  | 323582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 80645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3240     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30408    |\n",
      "|    total_timesteps  | 323982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 80745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=324000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 324000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 80749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3244     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30450    |\n",
      "|    total_timesteps  | 324382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 80845    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=324500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 324500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000563 |\n",
      "|    n_updates        | 80874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3248     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30490    |\n",
      "|    total_timesteps  | 324782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000808 |\n",
      "|    n_updates        | 80945    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 325000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0093   |\n",
      "|    n_updates        | 80999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3252     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30530    |\n",
      "|    total_timesteps  | 325182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00506  |\n",
      "|    n_updates        | 81045    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=325500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.613    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 325500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000613 |\n",
      "|    n_updates        | 81124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.613    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3256     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30577    |\n",
      "|    total_timesteps  | 325582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 81145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.613    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3260     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30601    |\n",
      "|    total_timesteps  | 325982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 81245    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=326000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.613    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 326000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 81249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.612    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3264     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30648    |\n",
      "|    total_timesteps  | 326382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000848 |\n",
      "|    n_updates        | 81345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=326500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.612    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 326500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 81374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.612    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3268     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30686    |\n",
      "|    total_timesteps  | 326782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 81445    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=327000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.612    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 327000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000426 |\n",
      "|    n_updates        | 81499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3272     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30727    |\n",
      "|    total_timesteps  | 327182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000469 |\n",
      "|    n_updates        | 81545    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=327500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 327500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 81624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3276     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30768    |\n",
      "|    total_timesteps  | 327582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 81645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3280     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30795    |\n",
      "|    total_timesteps  | 327982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000531 |\n",
      "|    n_updates        | 81745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=328000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 328000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 81749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.61     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3284     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30837    |\n",
      "|    total_timesteps  | 328382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000989 |\n",
      "|    n_updates        | 81845    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=328500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.61     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 328500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000817 |\n",
      "|    n_updates        | 81874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.61     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3288     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30882    |\n",
      "|    total_timesteps  | 328782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000351 |\n",
      "|    n_updates        | 81945    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=329000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 329000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 81999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3292     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30919    |\n",
      "|    total_timesteps  | 329182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000416 |\n",
      "|    n_updates        | 82045    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=329500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 329500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 82124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3296     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30964    |\n",
      "|    total_timesteps  | 329582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000807 |\n",
      "|    n_updates        | 82145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3300     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 30990    |\n",
      "|    total_timesteps  | 329982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000516 |\n",
      "|    n_updates        | 82245    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 330000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000421 |\n",
      "|    n_updates        | 82249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3304     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31035    |\n",
      "|    total_timesteps  | 330382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 82345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=330500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 330500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 82374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.607    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3308     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31077    |\n",
      "|    total_timesteps  | 330782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000695 |\n",
      "|    n_updates        | 82445    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=331000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.607    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 331000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 82499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.607    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3312     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31123    |\n",
      "|    total_timesteps  | 331182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 82545    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=331500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 331500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000724 |\n",
      "|    n_updates        | 82624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3316     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31160    |\n",
      "|    total_timesteps  | 331582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 82645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3320     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31194    |\n",
      "|    total_timesteps  | 331982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000545 |\n",
      "|    n_updates        | 82745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=332000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 332000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 82749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.605    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3324     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31230    |\n",
      "|    total_timesteps  | 332382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000587 |\n",
      "|    n_updates        | 82845    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=332500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.605    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 332500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000527 |\n",
      "|    n_updates        | 82874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.605    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3328     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31278    |\n",
      "|    total_timesteps  | 332782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000645 |\n",
      "|    n_updates        | 82945    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=333000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.605    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 333000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000568 |\n",
      "|    n_updates        | 82999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3332     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31325    |\n",
      "|    total_timesteps  | 333182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 83045    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=333500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 333500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000668 |\n",
      "|    n_updates        | 83124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3336     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31361    |\n",
      "|    total_timesteps  | 333582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000449 |\n",
      "|    n_updates        | 83145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3340     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31390    |\n",
      "|    total_timesteps  | 333982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000434 |\n",
      "|    n_updates        | 83245    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=334000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 334000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000761 |\n",
      "|    n_updates        | 83249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3344     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31431    |\n",
      "|    total_timesteps  | 334382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 83345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=334500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 334500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000597 |\n",
      "|    n_updates        | 83374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.602    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3348     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31476    |\n",
      "|    total_timesteps  | 334782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000516 |\n",
      "|    n_updates        | 83445    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.602    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 335000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000629 |\n",
      "|    n_updates        | 83499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.602    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3352     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31524    |\n",
      "|    total_timesteps  | 335182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 83545    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=335500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.602    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 335500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000446 |\n",
      "|    n_updates        | 83624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3356     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31563    |\n",
      "|    total_timesteps  | 335582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00087  |\n",
      "|    n_updates        | 83645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3360     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31587    |\n",
      "|    total_timesteps  | 335982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000408 |\n",
      "|    n_updates        | 83745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 336000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000677 |\n",
      "|    n_updates        | 83749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3364     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31633    |\n",
      "|    total_timesteps  | 336382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000999 |\n",
      "|    n_updates        | 83845    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=336500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.6      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 336500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 83874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.6      |\n",
      "| time/               |          |\n",
      "|    episodes         | 3368     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31675    |\n",
      "|    total_timesteps  | 336782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000888 |\n",
      "|    n_updates        | 83945    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=337000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.6      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 337000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 83999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.6      |\n",
      "| time/               |          |\n",
      "|    episodes         | 3372     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31714    |\n",
      "|    total_timesteps  | 337182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 84045    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=337500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.599    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 337500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000654 |\n",
      "|    n_updates        | 84124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.599    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3376     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31758    |\n",
      "|    total_timesteps  | 337582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000355 |\n",
      "|    n_updates        | 84145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.599    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3380     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31786    |\n",
      "|    total_timesteps  | 337982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 84245    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=338000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.599    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 338000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 84249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3384     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31828    |\n",
      "|    total_timesteps  | 338382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 84345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=338500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 338500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000451 |\n",
      "|    n_updates        | 84374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3388     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31875    |\n",
      "|    total_timesteps  | 338782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000985 |\n",
      "|    n_updates        | 84445    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=339000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 339000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00087  |\n",
      "|    n_updates        | 84499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3392     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31916    |\n",
      "|    total_timesteps  | 339182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 84545    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=339500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 339500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 84624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3396     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31954    |\n",
      "|    total_timesteps  | 339582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 84645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3400     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 31986    |\n",
      "|    total_timesteps  | 339982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 84745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 340000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 84749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3404     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32023    |\n",
      "|    total_timesteps  | 340382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 84845    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=340500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 340500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 84874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3408     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32069    |\n",
      "|    total_timesteps  | 340782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 84945    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=341000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.595    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 341000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 84999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3412     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32110    |\n",
      "|    total_timesteps  | 341182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 85045    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=341500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 341500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000884 |\n",
      "|    n_updates        | 85124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3416     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32151    |\n",
      "|    total_timesteps  | 341582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 85145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3420     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32180    |\n",
      "|    total_timesteps  | 341982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000838 |\n",
      "|    n_updates        | 85245    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=342000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 342000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 85249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3424     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32218    |\n",
      "|    total_timesteps  | 342382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000596 |\n",
      "|    n_updates        | 85345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=342500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 342500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 85374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3428     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32264    |\n",
      "|    total_timesteps  | 342782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000596 |\n",
      "|    n_updates        | 85445    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=343000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 343000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000543 |\n",
      "|    n_updates        | 85499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3432     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32309    |\n",
      "|    total_timesteps  | 343182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00871  |\n",
      "|    n_updates        | 85545    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=343500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 343500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 85624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3436     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32349    |\n",
      "|    total_timesteps  | 343582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000289 |\n",
      "|    n_updates        | 85645    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3440     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32375    |\n",
      "|    total_timesteps  | 343982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000659 |\n",
      "|    n_updates        | 85745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=344000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 344000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000407 |\n",
      "|    n_updates        | 85749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.591    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3444     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32417    |\n",
      "|    total_timesteps  | 344344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000397 |\n",
      "|    n_updates        | 85835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=344500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.591    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 344500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000938 |\n",
      "|    n_updates        | 85874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.591    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3448     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32459    |\n",
      "|    total_timesteps  | 344744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000429 |\n",
      "|    n_updates        | 85935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 345000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 85999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3452     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32501    |\n",
      "|    total_timesteps  | 345144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000676 |\n",
      "|    n_updates        | 86035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=345500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 345500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000394 |\n",
      "|    n_updates        | 86124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32541    |\n",
      "|    total_timesteps  | 345544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00622  |\n",
      "|    n_updates        | 86135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.589    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32566    |\n",
      "|    total_timesteps  | 345944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 86235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=346000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.589    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 346000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000634 |\n",
      "|    n_updates        | 86249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.589    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3464     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32609    |\n",
      "|    total_timesteps  | 346344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 86335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=346500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.589    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 346500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 86374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.588    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3468     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32650    |\n",
      "|    total_timesteps  | 346744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000552 |\n",
      "|    n_updates        | 86435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=347000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.588    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 347000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 86499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.588    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3472     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32696    |\n",
      "|    total_timesteps  | 347144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 86535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=347500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.587    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 347500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000782 |\n",
      "|    n_updates        | 86624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.587    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32734    |\n",
      "|    total_timesteps  | 347544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000345 |\n",
      "|    n_updates        | 86635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.587    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32761    |\n",
      "|    total_timesteps  | 347944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 86735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=348000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.587    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 348000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 86749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3484     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32803    |\n",
      "|    total_timesteps  | 348344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00666  |\n",
      "|    n_updates        | 86835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=348500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 348500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000747 |\n",
      "|    n_updates        | 86874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32844    |\n",
      "|    total_timesteps  | 348744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000391 |\n",
      "|    n_updates        | 86935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=349000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 349000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000954 |\n",
      "|    n_updates        | 86999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.585    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32886    |\n",
      "|    total_timesteps  | 349144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000887 |\n",
      "|    n_updates        | 87035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=349500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.585    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 349500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000424 |\n",
      "|    n_updates        | 87124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.585    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32931    |\n",
      "|    total_timesteps  | 349544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00812  |\n",
      "|    n_updates        | 87135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 32955    |\n",
      "|    total_timesteps  | 349944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000504 |\n",
      "|    n_updates        | 87235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 350000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00053  |\n",
      "|    n_updates        | 87249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33000    |\n",
      "|    total_timesteps  | 350344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 87335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=350500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 350500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 87374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3508     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33043    |\n",
      "|    total_timesteps  | 350744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 87435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=351000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 351000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 87499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33088    |\n",
      "|    total_timesteps  | 351144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 87535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=351500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 351500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 87624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33125    |\n",
      "|    total_timesteps  | 351544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 87635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33157    |\n",
      "|    total_timesteps  | 351944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.001    |\n",
      "|    n_updates        | 87735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 352000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 87749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33199    |\n",
      "|    total_timesteps  | 352344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000809 |\n",
      "|    n_updates        | 87835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=352500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 352500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000586 |\n",
      "|    n_updates        | 87874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33239    |\n",
      "|    total_timesteps  | 352744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000866 |\n",
      "|    n_updates        | 87935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=353000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 353000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 87999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33279    |\n",
      "|    total_timesteps  | 353144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000652 |\n",
      "|    n_updates        | 88035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=353500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 353500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000482 |\n",
      "|    n_updates        | 88124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33322    |\n",
      "|    total_timesteps  | 353544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00062  |\n",
      "|    n_updates        | 88135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33353    |\n",
      "|    total_timesteps  | 353944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000982 |\n",
      "|    n_updates        | 88235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=354000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 354000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 88249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.29    |\n",
      "|    exploration_rate | 0.579    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33396    |\n",
      "|    total_timesteps  | 354344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 88335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=354500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.579    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 354500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00463  |\n",
      "|    n_updates        | 88374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.579    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33435    |\n",
      "|    total_timesteps  | 354744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000754 |\n",
      "|    n_updates        | 88435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 355000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000445 |\n",
      "|    n_updates        | 88499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33477    |\n",
      "|    total_timesteps  | 355144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000474 |\n",
      "|    n_updates        | 88535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=355500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 355500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000705 |\n",
      "|    n_updates        | 88624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33523    |\n",
      "|    total_timesteps  | 355544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 88635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.577    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33547    |\n",
      "|    total_timesteps  | 355944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 88735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=356000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.577    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 356000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000498 |\n",
      "|    n_updates        | 88749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.577    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33592    |\n",
      "|    total_timesteps  | 356344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000718 |\n",
      "|    n_updates        | 88835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=356500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.577    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 356500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000477 |\n",
      "|    n_updates        | 88874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.576    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33637    |\n",
      "|    total_timesteps  | 356744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 88935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=357000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.576    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 357000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000886 |\n",
      "|    n_updates        | 88999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.576    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33674    |\n",
      "|    total_timesteps  | 357144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000541 |\n",
      "|    n_updates        | 89035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=357500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.575    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 357500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000902 |\n",
      "|    n_updates        | 89124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.575    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33721    |\n",
      "|    total_timesteps  | 357544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000788 |\n",
      "|    n_updates        | 89135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.575    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33745    |\n",
      "|    total_timesteps  | 357944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000397 |\n",
      "|    n_updates        | 89235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=358000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.575    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 358000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000821 |\n",
      "|    n_updates        | 89249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33789    |\n",
      "|    total_timesteps  | 358344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00641  |\n",
      "|    n_updates        | 89335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=358500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 358500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 89374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33826    |\n",
      "|    total_timesteps  | 358744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000421 |\n",
      "|    n_updates        | 89435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=359000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 359000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000598 |\n",
      "|    n_updates        | 89499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33873    |\n",
      "|    total_timesteps  | 359144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000268 |\n",
      "|    n_updates        | 89535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=359500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 359500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 89624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33918    |\n",
      "|    total_timesteps  | 359544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 89635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33942    |\n",
      "|    total_timesteps  | 359944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000632 |\n",
      "|    n_updates        | 89735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 360000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 89749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.01    |\n",
      "|    exploration_rate | 0.572    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 33984    |\n",
      "|    total_timesteps  | 360344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 89835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=360500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.572    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 360500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 89874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.572    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34030    |\n",
      "|    total_timesteps  | 360744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000934 |\n",
      "|    n_updates        | 89935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=361000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 361000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000672 |\n",
      "|    n_updates        | 89999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34067    |\n",
      "|    total_timesteps  | 361144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 90035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=361500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 361500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 90124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34112    |\n",
      "|    total_timesteps  | 361544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000597 |\n",
      "|    n_updates        | 90135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.57     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34138    |\n",
      "|    total_timesteps  | 361944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000878 |\n",
      "|    n_updates        | 90235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=362000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.57     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 362000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 90249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.57     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34182    |\n",
      "|    total_timesteps  | 362344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 90335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=362500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.57     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 362500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000836 |\n",
      "|    n_updates        | 90374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34228    |\n",
      "|    total_timesteps  | 362744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 90435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=363000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 363000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 90499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34265    |\n",
      "|    total_timesteps  | 363144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000726 |\n",
      "|    n_updates        | 90535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=363500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 363500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00048  |\n",
      "|    n_updates        | 90624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34308    |\n",
      "|    total_timesteps  | 363544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0069   |\n",
      "|    n_updates        | 90635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34340    |\n",
      "|    total_timesteps  | 363944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 90735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=364000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 364000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 90749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34378    |\n",
      "|    total_timesteps  | 364344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000539 |\n",
      "|    n_updates        | 90835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=364500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 364500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000619 |\n",
      "|    n_updates        | 90874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34423    |\n",
      "|    total_timesteps  | 364744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000626 |\n",
      "|    n_updates        | 90935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 365000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 90999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.566    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34465    |\n",
      "|    total_timesteps  | 365144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 91035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=365500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.566    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 365500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000782 |\n",
      "|    n_updates        | 91124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.566    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34503    |\n",
      "|    total_timesteps  | 365544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000844 |\n",
      "|    n_updates        | 91135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34536    |\n",
      "|    total_timesteps  | 365944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000624 |\n",
      "|    n_updates        | 91235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=366000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 366000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00073  |\n",
      "|    n_updates        | 91249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34578    |\n",
      "|    total_timesteps  | 366344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000755 |\n",
      "|    n_updates        | 91335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=366500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 366500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0029   |\n",
      "|    n_updates        | 91374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34615    |\n",
      "|    total_timesteps  | 366744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000936 |\n",
      "|    n_updates        | 91435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=367000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 367000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 91499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34663    |\n",
      "|    total_timesteps  | 367144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000711 |\n",
      "|    n_updates        | 91535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=367500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 367500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 91624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34702    |\n",
      "|    total_timesteps  | 367544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000547 |\n",
      "|    n_updates        | 91635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34731    |\n",
      "|    total_timesteps  | 367944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 91735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 368000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000627 |\n",
      "|    n_updates        | 91749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34776    |\n",
      "|    total_timesteps  | 368344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 91835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=368500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.562    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 368500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00097  |\n",
      "|    n_updates        | 91874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.562    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34813    |\n",
      "|    total_timesteps  | 368744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000681 |\n",
      "|    n_updates        | 91935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=369000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.562    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 369000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 91999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.562    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34858    |\n",
      "|    total_timesteps  | 369144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 92035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=369500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 369500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 92124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34903    |\n",
      "|    total_timesteps  | 369544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00067  |\n",
      "|    n_updates        | 92135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34927    |\n",
      "|    total_timesteps  | 369944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00072  |\n",
      "|    n_updates        | 92235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 370000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 92249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 34971    |\n",
      "|    total_timesteps  | 370344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000826 |\n",
      "|    n_updates        | 92335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=370500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 370500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000812 |\n",
      "|    n_updates        | 92374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35009    |\n",
      "|    total_timesteps  | 370744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 92435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=371000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 371000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 92499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3712     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35055    |\n",
      "|    total_timesteps  | 371144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 92535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=371500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 371500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 92624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3716     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35095    |\n",
      "|    total_timesteps  | 371544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 92635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.558    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3720     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35121    |\n",
      "|    total_timesteps  | 371944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 92735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=372000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.558    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 372000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00071  |\n",
      "|    n_updates        | 92749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.558    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3724     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35165    |\n",
      "|    total_timesteps  | 372344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 92835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=372500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.558    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 372500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000865 |\n",
      "|    n_updates        | 92874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.557    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3728     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35210    |\n",
      "|    total_timesteps  | 372744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000597 |\n",
      "|    n_updates        | 92935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=373000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.557    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 373000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00079  |\n",
      "|    n_updates        | 92999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.557    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3732     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35251    |\n",
      "|    total_timesteps  | 373144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 93035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=373500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.556    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 373500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 93124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.556    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3736     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35290    |\n",
      "|    total_timesteps  | 373544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00094  |\n",
      "|    n_updates        | 93135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.556    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3740     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35322    |\n",
      "|    total_timesteps  | 373944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 93235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=374000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.556    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 374000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000752 |\n",
      "|    n_updates        | 93249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3744     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35360    |\n",
      "|    total_timesteps  | 374344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000582 |\n",
      "|    n_updates        | 93335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=374500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 374500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 93374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3748     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35405    |\n",
      "|    total_timesteps  | 374744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 93435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 375000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 93499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3752     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35449    |\n",
      "|    total_timesteps  | 375144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000779 |\n",
      "|    n_updates        | 93535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=375500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 375500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 93624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3756     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35494    |\n",
      "|    total_timesteps  | 375544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00076  |\n",
      "|    n_updates        | 93635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3760     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35519    |\n",
      "|    total_timesteps  | 375944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 93735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=376000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 376000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000789 |\n",
      "|    n_updates        | 93749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3764     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35564    |\n",
      "|    total_timesteps  | 376344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 93835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=376500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 376500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000385 |\n",
      "|    n_updates        | 93874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3768     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35610    |\n",
      "|    total_timesteps  | 376744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000742 |\n",
      "|    n_updates        | 93935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=377000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.552    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 377000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 93999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.552    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3772     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35646    |\n",
      "|    total_timesteps  | 377144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 94035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=377500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.552    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 377500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00035  |\n",
      "|    n_updates        | 94124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.552    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3776     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35696    |\n",
      "|    total_timesteps  | 377544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000858 |\n",
      "|    n_updates        | 94135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3780     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35720    |\n",
      "|    total_timesteps  | 377944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000442 |\n",
      "|    n_updates        | 94235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=378000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 378000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 94249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3784     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35766    |\n",
      "|    total_timesteps  | 378344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000726 |\n",
      "|    n_updates        | 94335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=378500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 378500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000492 |\n",
      "|    n_updates        | 94374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.55     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3788     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35803    |\n",
      "|    total_timesteps  | 378744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 94435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=379000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.55     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 379000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000829 |\n",
      "|    n_updates        | 94499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.55     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3792     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35846    |\n",
      "|    total_timesteps  | 379144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 94535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=379500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.549    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 379500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000797 |\n",
      "|    n_updates        | 94624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.549    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3796     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35896    |\n",
      "|    total_timesteps  | 379544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000731 |\n",
      "|    n_updates        | 94635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.549    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3800     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35920    |\n",
      "|    total_timesteps  | 379944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 94735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.549    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 380000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 94749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3804     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 35957    |\n",
      "|    total_timesteps  | 380344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 94835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=380500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 380500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000994 |\n",
      "|    n_updates        | 94874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3808     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36005    |\n",
      "|    total_timesteps  | 380744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 94935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=381000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 381000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000773 |\n",
      "|    n_updates        | 94999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.29    |\n",
      "|    exploration_rate | 0.547    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3812     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36051    |\n",
      "|    total_timesteps  | 381144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000795 |\n",
      "|    n_updates        | 95035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=381500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.547    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 381500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000845 |\n",
      "|    n_updates        | 95124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.547    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3816     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36089    |\n",
      "|    total_timesteps  | 381544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 95135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3820     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36118    |\n",
      "|    total_timesteps  | 381944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.001    |\n",
      "|    n_updates        | 95235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=382000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 382000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00775  |\n",
      "|    n_updates        | 95249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3824     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36157    |\n",
      "|    total_timesteps  | 382344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 95335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=382500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 382500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000811 |\n",
      "|    n_updates        | 95374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3828     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36203    |\n",
      "|    total_timesteps  | 382744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000527 |\n",
      "|    n_updates        | 95435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=383000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 383000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000617 |\n",
      "|    n_updates        | 95499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3832     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36241    |\n",
      "|    total_timesteps  | 383144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000469 |\n",
      "|    n_updates        | 95535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=383500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 383500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 95624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3836     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36289    |\n",
      "|    total_timesteps  | 383544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 95635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3840     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36313    |\n",
      "|    total_timesteps  | 383944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000563 |\n",
      "|    n_updates        | 95735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 384000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00422  |\n",
      "|    n_updates        | 95749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3844     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36355    |\n",
      "|    total_timesteps  | 384344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 95835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=384500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 384500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00595  |\n",
      "|    n_updates        | 95874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3848     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36400    |\n",
      "|    total_timesteps  | 384744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 95935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 385000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 95999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3852     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36437    |\n",
      "|    total_timesteps  | 385144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 96035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=385500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 385500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00051  |\n",
      "|    n_updates        | 96124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3856     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36482    |\n",
      "|    total_timesteps  | 385544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00093  |\n",
      "|    n_updates        | 96135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3860     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36515    |\n",
      "|    total_timesteps  | 385944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 96235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=386000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 386000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000395 |\n",
      "|    n_updates        | 96249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3864     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36554    |\n",
      "|    total_timesteps  | 386344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 96335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=386500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 386500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000491 |\n",
      "|    n_updates        | 96374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3868     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36598    |\n",
      "|    total_timesteps  | 386744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000611 |\n",
      "|    n_updates        | 96435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=387000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 387000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00762  |\n",
      "|    n_updates        | 96499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3872     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36645    |\n",
      "|    total_timesteps  | 387144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 96535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=387500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 387500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 96624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3876     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36681    |\n",
      "|    total_timesteps  | 387544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0005   |\n",
      "|    n_updates        | 96635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.539    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3880     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36717    |\n",
      "|    total_timesteps  | 387944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000443 |\n",
      "|    n_updates        | 96735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=388000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.539    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 388000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000976 |\n",
      "|    n_updates        | 96749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.539    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3884     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36756    |\n",
      "|    total_timesteps  | 388344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000984 |\n",
      "|    n_updates        | 96835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=388500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.539    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 388500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000835 |\n",
      "|    n_updates        | 96874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3888     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36807    |\n",
      "|    total_timesteps  | 388744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000716 |\n",
      "|    n_updates        | 96935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=389000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 389000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 96999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3892     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36859    |\n",
      "|    total_timesteps  | 389144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000568 |\n",
      "|    n_updates        | 97035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=389500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.537    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 389500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 97124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.537    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3896     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36906    |\n",
      "|    total_timesteps  | 389544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000497 |\n",
      "|    n_updates        | 97135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.537    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3900     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36934    |\n",
      "|    total_timesteps  | 389944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000957 |\n",
      "|    n_updates        | 97235    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.537    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 390000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 97249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3904     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 36980    |\n",
      "|    total_timesteps  | 390344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 97335    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=390500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 390500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000427 |\n",
      "|    n_updates        | 97374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3908     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37030    |\n",
      "|    total_timesteps  | 390744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 97435    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=391000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 391000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 97499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3912     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37081    |\n",
      "|    total_timesteps  | 391144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 97535    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=391500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 391500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000544 |\n",
      "|    n_updates        | 97624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3916     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37128    |\n",
      "|    total_timesteps  | 391544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.008    |\n",
      "|    n_updates        | 97635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3920     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37156    |\n",
      "|    total_timesteps  | 391944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 97735    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=392000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 392000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 97749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.534    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3924     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37207    |\n",
      "|    total_timesteps  | 392344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 97835    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=392500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.534    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 392500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000776 |\n",
      "|    n_updates        | 97874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.534    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3928     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37256    |\n",
      "|    total_timesteps  | 392744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 97935    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=393000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 393000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 97999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3932     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37307    |\n",
      "|    total_timesteps  | 393144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000797 |\n",
      "|    n_updates        | 98035    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=393500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 393500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000935 |\n",
      "|    n_updates        | 98124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.97    |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3936     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37354    |\n",
      "|    total_timesteps  | 393544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000626 |\n",
      "|    n_updates        | 98135    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.86    |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3940     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37376    |\n",
      "|    total_timesteps  | 393903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000935 |\n",
      "|    n_updates        | 98225    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=394000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 394000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 98249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.87    |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3944     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37424    |\n",
      "|    total_timesteps  | 394303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00041  |\n",
      "|    n_updates        | 98325    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=394500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 394500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 98374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.88    |\n",
      "|    exploration_rate | 0.531    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3948     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37476    |\n",
      "|    total_timesteps  | 394703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00095  |\n",
      "|    n_updates        | 98425    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.531    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 395000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00059  |\n",
      "|    n_updates        | 98499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.84    |\n",
      "|    exploration_rate | 0.531    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3952     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37528    |\n",
      "|    total_timesteps  | 395103   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000557 |\n",
      "|    n_updates        | 98525    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=395500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 395500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000547 |\n",
      "|    n_updates        | 98624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.81    |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3956     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37578    |\n",
      "|    total_timesteps  | 395503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 98625    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.81    |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3960     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37603    |\n",
      "|    total_timesteps  | 395903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000644 |\n",
      "|    n_updates        | 98725    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=396000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 396000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000827 |\n",
      "|    n_updates        | 98749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3964     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37649    |\n",
      "|    total_timesteps  | 396303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000782 |\n",
      "|    n_updates        | 98825    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=396500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 396500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000885 |\n",
      "|    n_updates        | 98874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3968     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37700    |\n",
      "|    total_timesteps  | 396703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000714 |\n",
      "|    n_updates        | 98925    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=397000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 397000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00828  |\n",
      "|    n_updates        | 98999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3972     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37748    |\n",
      "|    total_timesteps  | 397103   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 99025    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=397500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 397500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 99124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3976     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37801    |\n",
      "|    total_timesteps  | 397503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000826 |\n",
      "|    n_updates        | 99125    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.79    |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3980     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37827    |\n",
      "|    total_timesteps  | 397903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 99225    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=398000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 398000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000733 |\n",
      "|    n_updates        | 99249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.76    |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3984     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37875    |\n",
      "|    total_timesteps  | 398303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000969 |\n",
      "|    n_updates        | 99325    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=398500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 398500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000332 |\n",
      "|    n_updates        | 99374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.64    |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3988     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37922    |\n",
      "|    total_timesteps  | 398683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00857  |\n",
      "|    n_updates        | 99420    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=399000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.526    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 399000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 99499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.66    |\n",
      "|    exploration_rate | 0.526    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3992     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 37972    |\n",
      "|    total_timesteps  | 399083   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00059  |\n",
      "|    n_updates        | 99520    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.69    |\n",
      "|    exploration_rate | 0.526    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3996     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38007    |\n",
      "|    total_timesteps  | 399483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000505 |\n",
      "|    n_updates        | 99620    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=399500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.526    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 399500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000325 |\n",
      "|    n_updates        | 99624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.69    |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4000     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38048    |\n",
      "|    total_timesteps  | 399883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 99720    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000852 |\n",
      "|    n_updates        | 99749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.67    |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4004     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38095    |\n",
      "|    total_timesteps  | 400283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 99820    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=400500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 99874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.67    |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4008     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38144    |\n",
      "|    total_timesteps  | 400683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 99920    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=401000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 401000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 99999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.7     |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4012     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38192    |\n",
      "|    total_timesteps  | 401083   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00762  |\n",
      "|    n_updates        | 100020   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.73    |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4016     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38230    |\n",
      "|    total_timesteps  | 401483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 100120   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=401500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 401500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 100124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.74    |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4020     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38280    |\n",
      "|    total_timesteps  | 401883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 100220   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=402000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 402000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000936 |\n",
      "|    n_updates        | 100249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.76    |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4024     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38328    |\n",
      "|    total_timesteps  | 402283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 100320   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=402500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 402500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 100374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.79    |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4028     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38371    |\n",
      "|    total_timesteps  | 402683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 100420   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=403000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 403000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 100499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4032     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38416    |\n",
      "|    total_timesteps  | 403083   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 100520   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.84    |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4036     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38454    |\n",
      "|    total_timesteps  | 403483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000736 |\n",
      "|    n_updates        | 100620   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=403500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 403500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 100624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4040     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38505    |\n",
      "|    total_timesteps  | 403883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00756  |\n",
      "|    n_updates        | 100720   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=404000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 404000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 100749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4044     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38555    |\n",
      "|    total_timesteps  | 404283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000628 |\n",
      "|    n_updates        | 100820   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=404500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 404500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 100874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.93    |\n",
      "|    exploration_rate | 0.519    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4048     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38605    |\n",
      "|    total_timesteps  | 404683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000458 |\n",
      "|    n_updates        | 100920   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.519    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 405000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000419 |\n",
      "|    n_updates        | 100999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.519    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4052     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38655    |\n",
      "|    total_timesteps  | 405083   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 101020   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4056     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38685    |\n",
      "|    total_timesteps  | 405483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 101120   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=405500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 405500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 101124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8       |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4060     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38731    |\n",
      "|    total_timesteps  | 405883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 101220   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=406000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 406000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 101249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4064     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38786    |\n",
      "|    total_timesteps  | 406283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 101320   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=406500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 406500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 101374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.97    |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4068     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38839    |\n",
      "|    total_timesteps  | 406683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000429 |\n",
      "|    n_updates        | 101420   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=407000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 407000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 101499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4072     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38890    |\n",
      "|    total_timesteps  | 407083   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000544 |\n",
      "|    n_updates        | 101520   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4076     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38916    |\n",
      "|    total_timesteps  | 407483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 101620   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=407500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 407500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 101624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -8       |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4080     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 38965    |\n",
      "|    total_timesteps  | 407883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 101720   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=408000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 408000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000404 |\n",
      "|    n_updates        | 101749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4084     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39019    |\n",
      "|    total_timesteps  | 408283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000534 |\n",
      "|    n_updates        | 101820   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=408500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 408500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 101874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4088     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39070    |\n",
      "|    total_timesteps  | 408683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000436 |\n",
      "|    n_updates        | 101920   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=409000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 409000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000565 |\n",
      "|    n_updates        | 101999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4092     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39126    |\n",
      "|    total_timesteps  | 409055   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000503 |\n",
      "|    n_updates        | 102013   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.9     |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4096     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39150    |\n",
      "|    total_timesteps  | 409455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 102113   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=409500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 409500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 102124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.75    |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4100     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39187    |\n",
      "|    total_timesteps  | 409827   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000477 |\n",
      "|    n_updates        | 102206   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 410000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 102249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.75    |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4104     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39233    |\n",
      "|    total_timesteps  | 410227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 102306   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=410500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 410500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 102374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.78    |\n",
      "|    exploration_rate | 0.512    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4108     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39280    |\n",
      "|    total_timesteps  | 410627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 102406   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=411000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.512    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 411000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000651 |\n",
      "|    n_updates        | 102499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.78    |\n",
      "|    exploration_rate | 0.512    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4112     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39318    |\n",
      "|    total_timesteps  | 411027   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 102506   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.73    |\n",
      "|    exploration_rate | 0.511    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4116     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39351    |\n",
      "|    total_timesteps  | 411427   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000719 |\n",
      "|    n_updates        | 102606   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=411500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.511    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 411500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 102624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.74    |\n",
      "|    exploration_rate | 0.511    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4120     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39398    |\n",
      "|    total_timesteps  | 411827   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 102706   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=412000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.511    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 412000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00798  |\n",
      "|    n_updates        | 102749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.72    |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4124     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39435    |\n",
      "|    total_timesteps  | 412227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 102806   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=412500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 412500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00872  |\n",
      "|    n_updates        | 102874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.73    |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4128     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39480    |\n",
      "|    total_timesteps  | 412627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00519  |\n",
      "|    n_updates        | 102906   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=413000, episode_reward=10.90 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 31       |\n",
      "|    mean_reward      | 10.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 413000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000604 |\n",
      "|    n_updates        | 102999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.71    |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4132     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39518    |\n",
      "|    total_timesteps  | 413027   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000856 |\n",
      "|    n_updates        | 103006   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.71    |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4136     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39543    |\n",
      "|    total_timesteps  | 413427   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000439 |\n",
      "|    n_updates        | 103106   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=413500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 413500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00061  |\n",
      "|    n_updates        | 103124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.73    |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4140     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39588    |\n",
      "|    total_timesteps  | 413827   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00621  |\n",
      "|    n_updates        | 103206   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=414000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.508    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 414000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.292    |\n",
      "|    n_updates        | 103249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.72    |\n",
      "|    exploration_rate | 0.508    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4144     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39626    |\n",
      "|    total_timesteps  | 414227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 103306   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=414500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.508    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 414500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000661 |\n",
      "|    n_updates        | 103374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.73    |\n",
      "|    exploration_rate | 0.508    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4148     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39671    |\n",
      "|    total_timesteps  | 414627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 103406   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=10.90 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 31       |\n",
      "|    mean_reward      | 10.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.507    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 415000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0407   |\n",
      "|    n_updates        | 103499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.6     |\n",
      "|    exploration_rate | 0.507    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4152     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39705    |\n",
      "|    total_timesteps  | 415009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 103502   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.45    |\n",
      "|    exploration_rate | 0.507    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4156     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39730    |\n",
      "|    total_timesteps  | 415387   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000708 |\n",
      "|    n_updates        | 103596   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=415500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.507    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 415500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000996 |\n",
      "|    n_updates        | 103624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.43    |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4160     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39772    |\n",
      "|    total_timesteps  | 415787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000659 |\n",
      "|    n_updates        | 103696   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 416000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000776 |\n",
      "|    n_updates        | 103749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4164     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39815    |\n",
      "|    total_timesteps  | 416187   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 103796   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=416500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.505    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 416500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 103874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.45    |\n",
      "|    exploration_rate | 0.505    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4168     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39857    |\n",
      "|    total_timesteps  | 416587   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000686 |\n",
      "|    n_updates        | 103896   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.505    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4172     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39883    |\n",
      "|    total_timesteps  | 416987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000693 |\n",
      "|    n_updates        | 103996   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=417000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.505    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 417000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000944 |\n",
      "|    n_updates        | 103999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.45    |\n",
      "|    exploration_rate | 0.504    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4176     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39927    |\n",
      "|    total_timesteps  | 417387   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 104096   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=417500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.504    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 417500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 104124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.504    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4180     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 39974    |\n",
      "|    total_timesteps  | 417787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000829 |\n",
      "|    n_updates        | 104196   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=418000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.504    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 418000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0296   |\n",
      "|    n_updates        | 104249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.46    |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4184     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40017    |\n",
      "|    total_timesteps  | 418187   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 104296   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=418500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 418500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000941 |\n",
      "|    n_updates        | 104374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.52    |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4188     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40055    |\n",
      "|    total_timesteps  | 418587   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 104396   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.68    |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4192     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40087    |\n",
      "|    total_timesteps  | 418987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 104496   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=419000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 419000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000984 |\n",
      "|    n_updates        | 104499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.69    |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4196     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40133    |\n",
      "|    total_timesteps  | 419387   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000629 |\n",
      "|    n_updates        | 104596   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=419500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 419500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000878 |\n",
      "|    n_updates        | 104624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4200     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40172    |\n",
      "|    total_timesteps  | 419787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 104696   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 420000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 104749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.83    |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4204     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40222    |\n",
      "|    total_timesteps  | 420187   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 104796   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=420500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 420500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 104874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4208     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40260    |\n",
      "|    total_timesteps  | 420587   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 104896   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.67    |\n",
      "|    exploration_rate | 0.5      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4212     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40294    |\n",
      "|    total_timesteps  | 420962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 104990   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=421000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.5      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 421000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 104999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.68    |\n",
      "|    exploration_rate | 0.5      |\n",
      "| time/               |          |\n",
      "|    episodes         | 4216     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40332    |\n",
      "|    total_timesteps  | 421362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 105090   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=421500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 421500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 105124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.64    |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4220     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40375    |\n",
      "|    total_timesteps  | 421762   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000851 |\n",
      "|    n_updates        | 105190   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=422000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 422000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 105249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.64    |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4224     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40418    |\n",
      "|    total_timesteps  | 422162   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 105290   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=422500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 422500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000889 |\n",
      "|    n_updates        | 105374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.58    |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4228     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40460    |\n",
      "|    total_timesteps  | 422562   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 105390   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.59    |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4232     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40485    |\n",
      "|    total_timesteps  | 422962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 105490   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=423000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 423000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 105499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4236     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40531    |\n",
      "|    total_timesteps  | 423334   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000847 |\n",
      "|    n_updates        | 105583   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=423500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 423500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000847 |\n",
      "|    n_updates        | 105624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.42    |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4240     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40574    |\n",
      "|    total_timesteps  | 423734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 105683   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=424000, episode_reward=10.90 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 31       |\n",
      "|    mean_reward      | 10.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 424000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 105749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.41    |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4244     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40603    |\n",
      "|    total_timesteps  | 424134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000679 |\n",
      "|    n_updates        | 105783   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=424500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 424500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000797 |\n",
      "|    n_updates        | 105874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.41    |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4248     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40653    |\n",
      "|    total_timesteps  | 424534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 105883   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.5     |\n",
      "|    ep_rew_mean      | -7.21    |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4252     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40674    |\n",
      "|    total_timesteps  | 424855   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 105963   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 425000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000471 |\n",
      "|    n_updates        | 105999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.36    |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4256     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40718    |\n",
      "|    total_timesteps  | 425255   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 106063   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=425500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 425500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 106124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.38    |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4260     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40766    |\n",
      "|    total_timesteps  | 425655   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000614 |\n",
      "|    n_updates        | 106163   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=426000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 426000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000354 |\n",
      "|    n_updates        | 106249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.22    |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4264     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40800    |\n",
      "|    total_timesteps  | 426011   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000624 |\n",
      "|    n_updates        | 106252   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.2     |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4268     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40829    |\n",
      "|    total_timesteps  | 426411   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000982 |\n",
      "|    n_updates        | 106352   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=426500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 426500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 106374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.19    |\n",
      "|    exploration_rate | 0.493    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4272     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40873    |\n",
      "|    total_timesteps  | 426811   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 106452   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=427000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.493    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 427000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000766 |\n",
      "|    n_updates        | 106499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.18    |\n",
      "|    exploration_rate | 0.493    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4276     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40915    |\n",
      "|    total_timesteps  | 427211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000427 |\n",
      "|    n_updates        | 106552   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=427500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.492    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 427500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000527 |\n",
      "|    n_updates        | 106624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.16    |\n",
      "|    exploration_rate | 0.492    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4280     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 40958    |\n",
      "|    total_timesteps  | 427611   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000639 |\n",
      "|    n_updates        | 106652   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=428000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.492    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 428000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000531 |\n",
      "|    n_updates        | 106749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.18    |\n",
      "|    exploration_rate | 0.492    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4284     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41003    |\n",
      "|    total_timesteps  | 428011   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 106752   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.14    |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4288     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41030    |\n",
      "|    total_timesteps  | 428411   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000906 |\n",
      "|    n_updates        | 106852   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=428500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 428500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000996 |\n",
      "|    n_updates        | 106874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.12    |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4292     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41075    |\n",
      "|    total_timesteps  | 428811   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000542 |\n",
      "|    n_updates        | 106952   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=429000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 429000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 106999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.98    |\n",
      "|    exploration_rate | 0.49     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4296     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41121    |\n",
      "|    total_timesteps  | 429190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 107047   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=429500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.49     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 429500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000476 |\n",
      "|    n_updates        | 107124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.83    |\n",
      "|    exploration_rate | 0.49     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4300     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41157    |\n",
      "|    total_timesteps  | 429551   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 107137   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.82    |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4304     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41189    |\n",
      "|    total_timesteps  | 429951   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 107237   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 430000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000524 |\n",
      "|    n_updates        | 107249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.8     |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4308     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41232    |\n",
      "|    total_timesteps  | 430351   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 107337   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=430500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 430500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00349  |\n",
      "|    n_updates        | 107374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.5     |\n",
      "|    ep_rew_mean      | -6.68    |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4312     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41277    |\n",
      "|    total_timesteps  | 430715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000949 |\n",
      "|    n_updates        | 107428   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=431000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.488    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 431000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 107499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.54    |\n",
      "|    exploration_rate | 0.488    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4316     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41316    |\n",
      "|    total_timesteps  | 431087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 107521   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.57    |\n",
      "|    exploration_rate | 0.488    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4320     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41342    |\n",
      "|    total_timesteps  | 431487   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00767  |\n",
      "|    n_updates        | 107621   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=431500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.488    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 431500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000531 |\n",
      "|    n_updates        | 107624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.54    |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4324     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41386    |\n",
      "|    total_timesteps  | 431887   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 107721   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=10.90 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 31       |\n",
      "|    mean_reward      | 10.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 432000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000627 |\n",
      "|    n_updates        | 107749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.57    |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4328     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41424    |\n",
      "|    total_timesteps  | 432287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 107821   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=432500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 432500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000704 |\n",
      "|    n_updates        | 107874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.54    |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4332     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41462    |\n",
      "|    total_timesteps  | 432687   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00075  |\n",
      "|    n_updates        | 107921   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=433000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 433000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000795 |\n",
      "|    n_updates        | 107999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.5     |\n",
      "|    ep_rew_mean      | -6.7     |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4336     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41509    |\n",
      "|    total_timesteps  | 433087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 108021   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.5     |\n",
      "|    ep_rew_mean      | -6.7     |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4340     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41541    |\n",
      "|    total_timesteps  | 433487   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000554 |\n",
      "|    n_updates        | 108121   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=433500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 433500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 108124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | -6.58    |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4344     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41579    |\n",
      "|    total_timesteps  | 433877   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 108219   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=434000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 434000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 108249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | -6.58    |\n",
      "|    exploration_rate | 0.484    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4348     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41621    |\n",
      "|    total_timesteps  | 434277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00049  |\n",
      "|    n_updates        | 108319   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=434500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.484    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 434500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000709 |\n",
      "|    n_updates        | 108374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -6.92    |\n",
      "|    exploration_rate | 0.484    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4352     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41667    |\n",
      "|    total_timesteps  | 434677   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00051  |\n",
      "|    n_updates        | 108419   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=435000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 435000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00811  |\n",
      "|    n_updates        | 108499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -6.79    |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4356     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41715    |\n",
      "|    total_timesteps  | 435072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 108517   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -6.77    |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4360     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41740    |\n",
      "|    total_timesteps  | 435472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00881  |\n",
      "|    n_updates        | 108617   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=435500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 435500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 108624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -6.92    |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4364     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41788    |\n",
      "|    total_timesteps  | 435872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000805 |\n",
      "|    n_updates        | 108717   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=436000, episode_reward=10.90 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 31       |\n",
      "|    mean_reward      | 10.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 436000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000363 |\n",
      "|    n_updates        | 108749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -6.65    |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4368     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41815    |\n",
      "|    total_timesteps  | 436229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00568  |\n",
      "|    n_updates        | 108807   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=436500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 436500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 108874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -6.49    |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4372     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41851    |\n",
      "|    total_timesteps  | 436598   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 108899   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -6.47    |\n",
      "|    exploration_rate | 0.481    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4376     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41885    |\n",
      "|    total_timesteps  | 436998   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000842 |\n",
      "|    n_updates        | 108999   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=437000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.481    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 437000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -6.47    |\n",
      "|    exploration_rate | 0.481    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4380     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41925    |\n",
      "|    total_timesteps  | 437398   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000596 |\n",
      "|    n_updates        | 109099   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=437500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 437500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 109124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -6.44    |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4384     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 41966    |\n",
      "|    total_timesteps  | 437798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000623 |\n",
      "|    n_updates        | 109199   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=438000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 438000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000688 |\n",
      "|    n_updates        | 109249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -6.45    |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4388     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42015    |\n",
      "|    total_timesteps  | 438198   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 109299   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=438500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 438500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000571 |\n",
      "|    n_updates        | 109374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | -6.25    |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4392     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42051    |\n",
      "|    total_timesteps  | 438554   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000357 |\n",
      "|    n_updates        | 109388   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.3     |\n",
      "|    ep_rew_mean      | -6.23    |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4396     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42077    |\n",
      "|    total_timesteps  | 438921   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00741  |\n",
      "|    n_updates        | 109480   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=439000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 439000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000596 |\n",
      "|    n_updates        | 109499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.22    |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4400     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42117    |\n",
      "|    total_timesteps  | 439276   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000758 |\n",
      "|    n_updates        | 109568   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=439500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 439500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 109624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.24    |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4404     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42164    |\n",
      "|    total_timesteps  | 439676   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000474 |\n",
      "|    n_updates        | 109668   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 440000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 109749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.25    |\n",
      "|    exploration_rate | 0.477    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4408     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42210    |\n",
      "|    total_timesteps  | 440076   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 109768   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.52    |\n",
      "|    exploration_rate | 0.477    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4412     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42234    |\n",
      "|    total_timesteps  | 440476   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 109868   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=440500, episode_reward=10.70 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 33       |\n",
      "|    mean_reward      | 10.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.477    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 440500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000657 |\n",
      "|    n_updates        | 109874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -6.69    |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4416     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42267    |\n",
      "|    total_timesteps  | 440876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00068  |\n",
      "|    n_updates        | 109968   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=441000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 441000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 109999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | -6.55    |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4420     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42309    |\n",
      "|    total_timesteps  | 441255   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 110063   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=441500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 441500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 110124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | -6.57    |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4424     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42355    |\n",
      "|    total_timesteps  | 441655   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 110163   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=442000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 442000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000792 |\n",
      "|    n_updates        | 110249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | -6.53    |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4428     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42400    |\n",
      "|    total_timesteps  | 442055   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 110263   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | -6.56    |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4432     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42437    |\n",
      "|    total_timesteps  | 442455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 110363   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=442500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 442500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000957 |\n",
      "|    n_updates        | 110374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | -6.54    |\n",
      "|    exploration_rate | 0.474    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4436     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42488    |\n",
      "|    total_timesteps  | 442855   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000616 |\n",
      "|    n_updates        | 110463   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=443000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.474    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 443000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 110499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | -6.54    |\n",
      "|    exploration_rate | 0.474    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4440     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42528    |\n",
      "|    total_timesteps  | 443255   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 110563   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=443500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 443500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000412 |\n",
      "|    n_updates        | 110624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | -6.66    |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4444     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42579    |\n",
      "|    total_timesteps  | 443655   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 110663   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=444000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 444000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000864 |\n",
      "|    n_updates        | 110749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.53    |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4448     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42633    |\n",
      "|    total_timesteps  | 444037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 110759   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.51    |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4452     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42661    |\n",
      "|    total_timesteps  | 444437   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 110859   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=444500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 444500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 110874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.5     |\n",
      "|    ep_rew_mean      | -6.5     |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42716    |\n",
      "|    total_timesteps  | 444825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 110956   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 445000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 110999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.5     |\n",
      "|    ep_rew_mean      | -6.49    |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42771    |\n",
      "|    total_timesteps  | 445225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000871 |\n",
      "|    n_updates        | 111056   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=445500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 445500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 111124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.5     |\n",
      "|    ep_rew_mean      | -6.46    |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4464     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42835    |\n",
      "|    total_timesteps  | 445625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0273   |\n",
      "|    n_updates        | 111156   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=446000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.47     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 446000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000896 |\n",
      "|    n_updates        | 111249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.75    |\n",
      "|    exploration_rate | 0.47     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4468     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42907    |\n",
      "|    total_timesteps  | 446025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 111256   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.3     |\n",
      "|    ep_rew_mean      | -6.91    |\n",
      "|    exploration_rate | 0.47     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4472     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 42963    |\n",
      "|    total_timesteps  | 446425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 111356   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=446500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.47     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 446500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000519 |\n",
      "|    n_updates        | 111374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -6.78    |\n",
      "|    exploration_rate | 0.469    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43026    |\n",
      "|    total_timesteps  | 446786   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000716 |\n",
      "|    n_updates        | 111446   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=447000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.469    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 447000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000772 |\n",
      "|    n_updates        | 111499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.9     |\n",
      "|    ep_rew_mean      | -6.76    |\n",
      "|    exploration_rate | 0.469    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43071    |\n",
      "|    total_timesteps  | 447186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000764 |\n",
      "|    n_updates        | 111546   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=447500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.469    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 447500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 111624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | -6.6     |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4484     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43109    |\n",
      "|    total_timesteps  | 447580   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 111644   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | -6.57    |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43134    |\n",
      "|    total_timesteps  | 447980   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000782 |\n",
      "|    n_updates        | 111744   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 448000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000755 |\n",
      "|    n_updates        | 111749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.3     |\n",
      "|    ep_rew_mean      | -6.77    |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43179    |\n",
      "|    total_timesteps  | 448380   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00081  |\n",
      "|    n_updates        | 111844   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=448500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 448500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0263   |\n",
      "|    n_updates        | 111874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -6.94    |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43216    |\n",
      "|    total_timesteps  | 448780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 111944   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=449000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 449000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00319  |\n",
      "|    n_updates        | 111999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.09    |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43259    |\n",
      "|    total_timesteps  | 449180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 112044   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=449500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 449500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 112124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.09    |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43301    |\n",
      "|    total_timesteps  | 449580   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 112144   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.1     |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4508     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43335    |\n",
      "|    total_timesteps  | 449980   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00075  |\n",
      "|    n_updates        | 112244   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 450000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000961 |\n",
      "|    n_updates        | 112249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.09    |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43373    |\n",
      "|    total_timesteps  | 450380   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 112344   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=450500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 450500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 112374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.08    |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43417    |\n",
      "|    total_timesteps  | 450780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 112444   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=451000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.464    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 451000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 112499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.21    |\n",
      "|    exploration_rate | 0.464    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43461    |\n",
      "|    total_timesteps  | 451180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 112544   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=451500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.464    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 451500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 112624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.21    |\n",
      "|    exploration_rate | 0.464    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43508    |\n",
      "|    total_timesteps  | 451580   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 112644   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.11    |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43531    |\n",
      "|    total_timesteps  | 451950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 112737   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=452000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 452000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00656  |\n",
      "|    n_updates        | 112749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.09    |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43578    |\n",
      "|    total_timesteps  | 452350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 112837   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=452500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 452500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 112874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.11    |\n",
      "|    exploration_rate | 0.462    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43620    |\n",
      "|    total_timesteps  | 452750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 112937   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=453000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.462    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 453000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 112999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.16    |\n",
      "|    exploration_rate | 0.462    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43661    |\n",
      "|    total_timesteps  | 453150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 113037   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=453500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 453500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00791  |\n",
      "|    n_updates        | 113124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.17    |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43709    |\n",
      "|    total_timesteps  | 453550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000825 |\n",
      "|    n_updates        | 113137   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.27    |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43734    |\n",
      "|    total_timesteps  | 453950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00965  |\n",
      "|    n_updates        | 113237   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=454000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 454000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 113249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.29    |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43783    |\n",
      "|    total_timesteps  | 454350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 113337   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=454500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 454500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00561  |\n",
      "|    n_updates        | 113374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.45    |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43826    |\n",
      "|    total_timesteps  | 454750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 113437   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 455000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 113499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.46    |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43871    |\n",
      "|    total_timesteps  | 455150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000704 |\n",
      "|    n_updates        | 113537   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=455500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 455500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0331   |\n",
      "|    n_updates        | 113624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.46    |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43908    |\n",
      "|    total_timesteps  | 455550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000873 |\n",
      "|    n_updates        | 113637   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.45    |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43942    |\n",
      "|    total_timesteps  | 455950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000738 |\n",
      "|    n_updates        | 113737   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=456000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 456000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000894 |\n",
      "|    n_updates        | 113749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.46    |\n",
      "|    exploration_rate | 0.458    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 43981    |\n",
      "|    total_timesteps  | 456350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 113837   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=456500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.458    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 456500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000806 |\n",
      "|    n_updates        | 113874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.62    |\n",
      "|    exploration_rate | 0.458    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44024    |\n",
      "|    total_timesteps  | 456750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 113937   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=457000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 457000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 113999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.64    |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44073    |\n",
      "|    total_timesteps  | 457150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 114037   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=457500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 457500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 114124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.79    |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44119    |\n",
      "|    total_timesteps  | 457550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 114137   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44143    |\n",
      "|    total_timesteps  | 457950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00418  |\n",
      "|    n_updates        | 114237   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=458000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 458000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000951 |\n",
      "|    n_updates        | 114249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.84    |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44187    |\n",
      "|    total_timesteps  | 458350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 114337   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=458500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 458500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 114374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.455    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44231    |\n",
      "|    total_timesteps  | 458750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 114437   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=459000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.455    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 459000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 114499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.81    |\n",
      "|    exploration_rate | 0.455    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44278    |\n",
      "|    total_timesteps  | 459150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00618  |\n",
      "|    n_updates        | 114537   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=459500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 459500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 114624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.84    |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44324    |\n",
      "|    total_timesteps  | 459550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 114637   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44348    |\n",
      "|    total_timesteps  | 459950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000299 |\n",
      "|    n_updates        | 114737   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 460000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000478 |\n",
      "|    n_updates        | 114749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.79    |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44391    |\n",
      "|    total_timesteps  | 460350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 114837   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=460500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 460500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 114874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.79    |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44436    |\n",
      "|    total_timesteps  | 460750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 114937   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=461000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 461000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 114999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44480    |\n",
      "|    total_timesteps  | 461150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 115037   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=461500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 461500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 115124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44523    |\n",
      "|    total_timesteps  | 461550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 115137   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44547    |\n",
      "|    total_timesteps  | 461950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 115237   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=462000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 462000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 115249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.94    |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44590    |\n",
      "|    total_timesteps  | 462350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 115337   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=462500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 462500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 115374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.97    |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44635    |\n",
      "|    total_timesteps  | 462750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 115437   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=463000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 463000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 115499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.93    |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44683    |\n",
      "|    total_timesteps  | 463150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 115537   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=463500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 463500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 115624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.91    |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44731    |\n",
      "|    total_timesteps  | 463550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 115637   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.91    |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44756    |\n",
      "|    total_timesteps  | 463950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 115737   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 464000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 115749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.9     |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44805    |\n",
      "|    total_timesteps  | 464350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000951 |\n",
      "|    n_updates        | 115837   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=464500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.448    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 464500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 115874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.89    |\n",
      "|    exploration_rate | 0.448    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44843    |\n",
      "|    total_timesteps  | 464750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 115937   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.448    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 465000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00423  |\n",
      "|    n_updates        | 115999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.88    |\n",
      "|    exploration_rate | 0.448    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44890    |\n",
      "|    total_timesteps  | 465150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00659  |\n",
      "|    n_updates        | 116037   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=465500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 465500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 116124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.9     |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44936    |\n",
      "|    total_timesteps  | 465550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 116137   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 44964    |\n",
      "|    total_timesteps  | 465950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 116237   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=466000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 466000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 116249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.89    |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45013    |\n",
      "|    total_timesteps  | 466350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 116337   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=466500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 466500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0055   |\n",
      "|    n_updates        | 116374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.91    |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45057    |\n",
      "|    total_timesteps  | 466750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 116437   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=467000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.445    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 467000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 116499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.445    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45103    |\n",
      "|    total_timesteps  | 467150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000791 |\n",
      "|    n_updates        | 116537   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=467500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.445    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 467500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 116624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.445    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45142    |\n",
      "|    total_timesteps  | 467550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 116637   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45172    |\n",
      "|    total_timesteps  | 467950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000834 |\n",
      "|    n_updates        | 116737   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=468000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 468000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000573 |\n",
      "|    n_updates        | 116749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.93    |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45216    |\n",
      "|    total_timesteps  | 468350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0096   |\n",
      "|    n_updates        | 116837   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=468500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 468500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 116874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.443    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45262    |\n",
      "|    total_timesteps  | 468750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 116937   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=469000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.443    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 469000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 116999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.443    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45300    |\n",
      "|    total_timesteps  | 469150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0029   |\n",
      "|    n_updates        | 117037   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=469500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 469500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 117124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.97    |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45342    |\n",
      "|    total_timesteps  | 469550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 117137   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45375    |\n",
      "|    total_timesteps  | 469950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 117237   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 470000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000509 |\n",
      "|    n_updates        | 117249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4712     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45412    |\n",
      "|    total_timesteps  | 470350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 117337   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=470500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 470500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 117374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4716     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45459    |\n",
      "|    total_timesteps  | 470750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 117437   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=471000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 471000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 117499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4720     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45505    |\n",
      "|    total_timesteps  | 471150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 117537   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=471500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 471500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 117624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4724     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45547    |\n",
      "|    total_timesteps  | 471550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00508  |\n",
      "|    n_updates        | 117637   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4728     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45571    |\n",
      "|    total_timesteps  | 471950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 117737   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=472000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 472000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 117749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.439    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4732     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45614    |\n",
      "|    total_timesteps  | 472334   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 117833   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=472500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.439    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 472500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00289  |\n",
      "|    n_updates        | 117874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.8     |\n",
      "|    ep_rew_mean      | -7.9     |\n",
      "|    exploration_rate | 0.439    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4736     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45658    |\n",
      "|    total_timesteps  | 472734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 117933   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=473000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 473000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 117999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -7.76    |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4740     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45699    |\n",
      "|    total_timesteps  | 473099   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 118024   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -7.77    |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4744     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45723    |\n",
      "|    total_timesteps  | 473499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 118124   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=473500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 100      |\n",
      "|    mean_reward     | -10      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 473500   |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4748     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45769    |\n",
      "|    total_timesteps  | 473899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 118224   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=474000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 474000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 118249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4752     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45815    |\n",
      "|    total_timesteps  | 474299   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 118324   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=474500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 474500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 118374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -7.81    |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4756     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45855    |\n",
      "|    total_timesteps  | 474699   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.039    |\n",
      "|    n_updates        | 118424   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 475000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000902 |\n",
      "|    n_updates        | 118499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.63    |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4760     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45894    |\n",
      "|    total_timesteps  | 475051   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 118512   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.66    |\n",
      "|    exploration_rate | 0.435    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4764     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45924    |\n",
      "|    total_timesteps  | 475451   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 118612   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=475500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.435    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 475500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 118624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.67    |\n",
      "|    exploration_rate | 0.435    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4768     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 45966    |\n",
      "|    total_timesteps  | 475851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 118712   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=476000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.435    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 476000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 118749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.7     |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4772     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46008    |\n",
      "|    total_timesteps  | 476251   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 118812   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=476500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 476500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 118874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.68    |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4776     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46056    |\n",
      "|    total_timesteps  | 476651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 118912   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=477000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 477000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00365  |\n",
      "|    n_updates        | 118999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.65    |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4780     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46094    |\n",
      "|    total_timesteps  | 477051   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 119012   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.65    |\n",
      "|    exploration_rate | 0.433    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4784     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46131    |\n",
      "|    total_timesteps  | 477451   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 119112   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=477500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.433    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 477500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00362  |\n",
      "|    n_updates        | 119124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.66    |\n",
      "|    exploration_rate | 0.433    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4788     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46168    |\n",
      "|    total_timesteps  | 477851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00478  |\n",
      "|    n_updates        | 119212   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=478000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 478000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 119249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -7.5     |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4792     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46210    |\n",
      "|    total_timesteps  | 478232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 119307   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=478500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 478500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 119374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4796     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46252    |\n",
      "|    total_timesteps  | 478632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00435  |\n",
      "|    n_updates        | 119407   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=479000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 479000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000735 |\n",
      "|    n_updates        | 119499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -7.5     |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4800     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46294    |\n",
      "|    total_timesteps  | 479032   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 119507   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -7.5     |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4804     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46319    |\n",
      "|    total_timesteps  | 479432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 119607   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=479500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 479500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 119624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.34    |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4808     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46358    |\n",
      "|    total_timesteps  | 479791   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 119697   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 480000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 119749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.2     |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4812     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46404    |\n",
      "|    total_timesteps  | 480189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 119797   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=480500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 480500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 119874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.1     |\n",
      "|    ep_rew_mean      | -7.03    |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4816     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46446    |\n",
      "|    total_timesteps  | 480560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00566  |\n",
      "|    n_updates        | 119889   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.1     |\n",
      "|    ep_rew_mean      | -7.03    |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4820     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46471    |\n",
      "|    total_timesteps  | 480960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00359  |\n",
      "|    n_updates        | 119989   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=481000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 481000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 119999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.1     |\n",
      "|    ep_rew_mean      | -7.03    |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4824     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46514    |\n",
      "|    total_timesteps  | 481360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 120089   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=481500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 481500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000968 |\n",
      "|    n_updates        | 120124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | -6.74    |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4828     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46552    |\n",
      "|    total_timesteps  | 481694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 120173   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=482000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 482000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0266   |\n",
      "|    n_updates        | 120249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.88    |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4832     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46598    |\n",
      "|    total_timesteps  | 482094   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 120273   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.88    |\n",
      "|    exploration_rate | 0.427    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4836     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46622    |\n",
      "|    total_timesteps  | 482494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 120373   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=482500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.427    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 482500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 120374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -7.04    |\n",
      "|    exploration_rate | 0.427    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4840     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46669    |\n",
      "|    total_timesteps  | 482894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 120473   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=483000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 483000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 120499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -7.04    |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4844     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46712    |\n",
      "|    total_timesteps  | 483294   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 120573   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=483500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 483500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 120624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -7       |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4848     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46754    |\n",
      "|    total_timesteps  | 483694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 120673   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=484000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 484000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0266   |\n",
      "|    n_updates        | 120749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -7.04    |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4852     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46793    |\n",
      "|    total_timesteps  | 484094   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 120773   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -7.03    |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4856     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46820    |\n",
      "|    total_timesteps  | 484494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 120873   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=484500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 484500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 120874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.19    |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4860     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46860    |\n",
      "|    total_timesteps  | 484894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0556   |\n",
      "|    n_updates        | 120973   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=485000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 485000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 120999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -7.01    |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4864     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46901    |\n",
      "|    total_timesteps  | 485254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 121063   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=485500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 485500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00438  |\n",
      "|    n_updates        | 121124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.98    |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4868     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46944    |\n",
      "|    total_timesteps  | 485654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 121163   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=486000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 486000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00339  |\n",
      "|    n_updates        | 121249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.96    |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4872     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 46989    |\n",
      "|    total_timesteps  | 486054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000929 |\n",
      "|    n_updates        | 121263   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.95    |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4876     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47013    |\n",
      "|    total_timesteps  | 486454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000691 |\n",
      "|    n_updates        | 121363   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=486500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 486500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 121374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.97    |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4880     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47058    |\n",
      "|    total_timesteps  | 486854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 121463   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=487000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 487000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 121499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.95    |\n",
      "|    exploration_rate | 0.421    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4884     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47096    |\n",
      "|    total_timesteps  | 487254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 121563   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=487500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.421    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 487500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 121624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.96    |\n",
      "|    exploration_rate | 0.421    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4888     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47140    |\n",
      "|    total_timesteps  | 487654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000992 |\n",
      "|    n_updates        | 121663   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=488000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.421    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 488000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 121749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.14    |\n",
      "|    exploration_rate | 0.42     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4892     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47185    |\n",
      "|    total_timesteps  | 488054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00294  |\n",
      "|    n_updates        | 121763   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.16    |\n",
      "|    exploration_rate | 0.42     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4896     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47209    |\n",
      "|    total_timesteps  | 488454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 121863   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=488500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.42     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 488500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 121874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.11    |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4900     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47252    |\n",
      "|    total_timesteps  | 488854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00077  |\n",
      "|    n_updates        | 121963   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=489000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 489000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00413  |\n",
      "|    n_updates        | 121999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -7.1     |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4904     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47292    |\n",
      "|    total_timesteps  | 489254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 122063   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=489500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 489500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 122124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -7.23    |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4908     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47333    |\n",
      "|    total_timesteps  | 489654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 122163   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 490000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 122249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.33    |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4912     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47376    |\n",
      "|    total_timesteps  | 490054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 122263   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.9     |\n",
      "|    ep_rew_mean      | -7.49    |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4916     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47416    |\n",
      "|    total_timesteps  | 490454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 122363   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=490500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 490500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 122374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.9     |\n",
      "|    ep_rew_mean      | -7.49    |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4920     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47474    |\n",
      "|    total_timesteps  | 490854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 122463   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=491000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 491000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 122499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.9     |\n",
      "|    ep_rew_mean      | -7.5     |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4924     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47530    |\n",
      "|    total_timesteps  | 491254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 122563   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=491500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.416    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 491500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 122624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.81    |\n",
      "|    exploration_rate | 0.416    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4928     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47568    |\n",
      "|    total_timesteps  | 491654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 122663   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=492000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.416    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 492000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00892  |\n",
      "|    n_updates        | 122749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.416    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4932     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47617    |\n",
      "|    total_timesteps  | 492054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 122763   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4936     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47645    |\n",
      "|    total_timesteps  | 492454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 122863   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=492500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 492500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 122874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4940     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47685    |\n",
      "|    total_timesteps  | 492854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 122963   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=493000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 493000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.029    |\n",
      "|    n_updates        | 122999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -7.78    |\n",
      "|    exploration_rate | 0.414    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4944     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47731    |\n",
      "|    total_timesteps  | 493254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00587  |\n",
      "|    n_updates        | 123063   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=493500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.414    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 493500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 123124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.64    |\n",
      "|    exploration_rate | 0.414    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4948     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47772    |\n",
      "|    total_timesteps  | 493625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 123156   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=494000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 494000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 123249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.63    |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4952     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47819    |\n",
      "|    total_timesteps  | 494025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00328  |\n",
      "|    n_updates        | 123256   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.62    |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4956     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47844    |\n",
      "|    total_timesteps  | 494425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 123356   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=494500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 494500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 123374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.47    |\n",
      "|    exploration_rate | 0.412    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4960     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47886    |\n",
      "|    total_timesteps  | 494790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 123447   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.412    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 495000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00956  |\n",
      "|    n_updates        | 123499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.6     |\n",
      "|    exploration_rate | 0.412    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4964     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47927    |\n",
      "|    total_timesteps  | 495190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 123547   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=495500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.412    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 495500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 123624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.63    |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4968     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47969    |\n",
      "|    total_timesteps  | 495590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000722 |\n",
      "|    n_updates        | 123647   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.65    |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4972     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 47994    |\n",
      "|    total_timesteps  | 495990   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 123747   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 496000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 123749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.66    |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4976     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48038    |\n",
      "|    total_timesteps  | 496390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 123847   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=496500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 496500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 123874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.63    |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4980     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48083    |\n",
      "|    total_timesteps  | 496790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 123947   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=497000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 497000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 123999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.62    |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4984     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48121    |\n",
      "|    total_timesteps  | 497190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00443  |\n",
      "|    n_updates        | 124047   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=497500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.409    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 497500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 124124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.6     |\n",
      "|    exploration_rate | 0.409    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4988     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48164    |\n",
      "|    total_timesteps  | 497590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 124147   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.56    |\n",
      "|    exploration_rate | 0.409    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4992     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48192    |\n",
      "|    total_timesteps  | 497990   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000754 |\n",
      "|    n_updates        | 124247   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=498000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.409    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 498000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000545 |\n",
      "|    n_updates        | 124249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.56    |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4996     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48229    |\n",
      "|    total_timesteps  | 498390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 124347   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=498500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 498500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 124374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.54    |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5000     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48276    |\n",
      "|    total_timesteps  | 498790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 124447   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=499000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 499000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 124499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.41    |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5004     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48319    |\n",
      "|    total_timesteps  | 499178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 124544   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=499500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 499500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00404  |\n",
      "|    n_updates        | 124624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.43    |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5008     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48355    |\n",
      "|    total_timesteps  | 499578   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 124644   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.47    |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5012     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48383    |\n",
      "|    total_timesteps  | 499978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 124744   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00555  |\n",
      "|    n_updates        | 124749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.45    |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5016     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48424    |\n",
      "|    total_timesteps  | 500378   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00781  |\n",
      "|    n_updates        | 124844   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=500500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 124874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.45    |\n",
      "|    exploration_rate | 0.405    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5020     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48463    |\n",
      "|    total_timesteps  | 500778   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0359   |\n",
      "|    n_updates        | 124944   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=501000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.405    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 501000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 124999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.2     |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.405    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5024     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48507    |\n",
      "|    total_timesteps  | 501178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 125044   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=501500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 501500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 125124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.9     |\n",
      "|    ep_rew_mean      | -7.28    |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5028     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48542    |\n",
      "|    total_timesteps  | 501540   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00785  |\n",
      "|    n_updates        | 125134   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.9     |\n",
      "|    ep_rew_mean      | -7.26    |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5032     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48569    |\n",
      "|    total_timesteps  | 501940   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 125234   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=502000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 502000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 125249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -7.12    |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5036     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48608    |\n",
      "|    total_timesteps  | 502335   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 125333   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=502500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 502500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00781  |\n",
      "|    n_updates        | 125374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -6.84    |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5040     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48646    |\n",
      "|    total_timesteps  | 502711   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00559  |\n",
      "|    n_updates        | 125427   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=503000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 503000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 125499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.3     |\n",
      "|    ep_rew_mean      | -6.7     |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5044     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48687    |\n",
      "|    total_timesteps  | 503082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 125520   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -6.85    |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5048     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48711    |\n",
      "|    total_timesteps  | 503482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00443  |\n",
      "|    n_updates        | 125620   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=503500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 503500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 125624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -6.83    |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5052     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48752    |\n",
      "|    total_timesteps  | 503882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 125720   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=504000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 504000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 125749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | -6.55    |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5056     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48790    |\n",
      "|    total_timesteps  | 504242   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 125810   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=504500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 504500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 125874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.5     |\n",
      "|    ep_rew_mean      | -6.72    |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5060     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48829    |\n",
      "|    total_timesteps  | 504642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 125910   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.46    |\n",
      "|    exploration_rate | 0.4      |\n",
      "| time/               |          |\n",
      "|    episodes         | 5064     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48850    |\n",
      "|    total_timesteps  | 504988   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 125996   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.4      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 505000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 125999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.44    |\n",
      "|    exploration_rate | 0.4      |\n",
      "| time/               |          |\n",
      "|    episodes         | 5068     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48893    |\n",
      "|    total_timesteps  | 505388   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 126096   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=505500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.4      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 505500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 126124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.4     |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5072     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48938    |\n",
      "|    total_timesteps  | 505788   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 126196   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=506000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 506000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 126249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.4     |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5076     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 48975    |\n",
      "|    total_timesteps  | 506188   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00637  |\n",
      "|    n_updates        | 126296   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=506500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 506500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 126374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | -6.27    |\n",
      "|    exploration_rate | 0.398    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5080     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49015    |\n",
      "|    total_timesteps  | 506571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 126392   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | -6.16    |\n",
      "|    exploration_rate | 0.398    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5084     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49039    |\n",
      "|    total_timesteps  | 506968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 126491   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=507000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.398    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 507000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00495  |\n",
      "|    n_updates        | 126499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | -6.16    |\n",
      "|    exploration_rate | 0.398    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5088     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49080    |\n",
      "|    total_timesteps  | 507368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00651  |\n",
      "|    n_updates        | 126591   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=507500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 507500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 126624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.3     |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5092     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49115    |\n",
      "|    total_timesteps  | 507721   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 126680   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=508000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 508000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 126749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.9     |\n",
      "|    ep_rew_mean      | -5.85    |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5096     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49151    |\n",
      "|    total_timesteps  | 508084   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000992 |\n",
      "|    n_updates        | 126770   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.9     |\n",
      "|    ep_rew_mean      | -5.41    |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5100     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49173    |\n",
      "|    total_timesteps  | 508381   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 126845   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=508500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 508500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 126874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96       |\n",
      "|    ep_rew_mean      | -5.55    |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5104     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49209    |\n",
      "|    total_timesteps  | 508781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 126945   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=509000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 509000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 126999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96       |\n",
      "|    ep_rew_mean      | -5.55    |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5108     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49250    |\n",
      "|    total_timesteps  | 509181   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 127045   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=509500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 509500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 127124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96       |\n",
      "|    ep_rew_mean      | -5.52    |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5112     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49288    |\n",
      "|    total_timesteps  | 509581   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 127145   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.6     |\n",
      "|    ep_rew_mean      | -5.24    |\n",
      "|    exploration_rate | 0.394    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5116     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49314    |\n",
      "|    total_timesteps  | 509941   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00506  |\n",
      "|    n_updates        | 127235   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.394    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 510000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00933  |\n",
      "|    n_updates        | 127249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.6     |\n",
      "|    ep_rew_mean      | -5.22    |\n",
      "|    exploration_rate | 0.394    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5120     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49351    |\n",
      "|    total_timesteps  | 510341   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 127335   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=510500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.394    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 510500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 127374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.2     |\n",
      "|    ep_rew_mean      | -5.06    |\n",
      "|    exploration_rate | 0.394    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5124     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49388    |\n",
      "|    total_timesteps  | 510695   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0321   |\n",
      "|    n_updates        | 127423   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=511000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 511000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 127499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.3     |\n",
      "|    ep_rew_mean      | -5.07    |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5128     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49424    |\n",
      "|    total_timesteps  | 511069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 127517   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.3     |\n",
      "|    ep_rew_mean      | -5.11    |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5132     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49449    |\n",
      "|    total_timesteps  | 511469   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 127617   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=511500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 511500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00322  |\n",
      "|    n_updates        | 127624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.3     |\n",
      "|    ep_rew_mean      | -5.24    |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5136     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49487    |\n",
      "|    total_timesteps  | 511869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 127717   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=512000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 512000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 127749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.2     |\n",
      "|    ep_rew_mean      | -5.04    |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5140     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49516    |\n",
      "|    total_timesteps  | 512136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 127783   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.6     |\n",
      "|    ep_rew_mean      | -4.73    |\n",
      "|    exploration_rate | 0.391    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5144     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49537    |\n",
      "|    total_timesteps  | 512438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 127859   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=512500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.391    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 512500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 127874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.9     |\n",
      "|    ep_rew_mean      | -4.42    |\n",
      "|    exploration_rate | 0.391    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5148     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49572    |\n",
      "|    total_timesteps  | 512770   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 127942   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=513000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.391    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 513000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0072   |\n",
      "|    n_updates        | 127999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.9     |\n",
      "|    ep_rew_mean      | -4.44    |\n",
      "|    exploration_rate | 0.391    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5152     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49610    |\n",
      "|    total_timesteps  | 513170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0285   |\n",
      "|    n_updates        | 128042   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=513500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 513500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0262   |\n",
      "|    n_updates        | 128124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.3     |\n",
      "|    ep_rew_mean      | -4.74    |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5156     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49652    |\n",
      "|    total_timesteps  | 513570   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 128142   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.3     |\n",
      "|    ep_rew_mean      | -4.77    |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5160     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49676    |\n",
      "|    total_timesteps  | 513970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 128242   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=514000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 514000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 128249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.8     |\n",
      "|    ep_rew_mean      | -5.07    |\n",
      "|    exploration_rate | 0.389    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5164     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49717    |\n",
      "|    total_timesteps  | 514370   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 128342   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=514500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.389    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 514500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00332  |\n",
      "|    n_updates        | 128374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.2     |\n",
      "|    ep_rew_mean      | -4.79    |\n",
      "|    exploration_rate | 0.389    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5168     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49750    |\n",
      "|    total_timesteps  | 514710   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00365  |\n",
      "|    n_updates        | 128427   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 515000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 128499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.7     |\n",
      "|    ep_rew_mean      | -4.66    |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5172     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49788    |\n",
      "|    total_timesteps  | 515057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 128514   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.7     |\n",
      "|    ep_rew_mean      | -4.67    |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5176     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49813    |\n",
      "|    total_timesteps  | 515457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00331  |\n",
      "|    n_updates        | 128614   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=515500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 515500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00365  |\n",
      "|    n_updates        | 128624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.9     |\n",
      "|    ep_rew_mean      | -4.81    |\n",
      "|    exploration_rate | 0.387    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5180     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49854    |\n",
      "|    total_timesteps  | 515857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 128714   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=516000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.387    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 516000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 128749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.9     |\n",
      "|    ep_rew_mean      | -4.95    |\n",
      "|    exploration_rate | 0.387    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5184     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49891    |\n",
      "|    total_timesteps  | 516257   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 128814   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=516500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.387    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 516500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 128874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.9     |\n",
      "|    ep_rew_mean      | -4.97    |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5188     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49931    |\n",
      "|    total_timesteps  | 516657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 128914   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=517000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 517000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 128999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.1     |\n",
      "|    ep_rew_mean      | -4.99    |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5192     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49967    |\n",
      "|    total_timesteps  | 517028   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00375  |\n",
      "|    n_updates        | 129006   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.1     |\n",
      "|    ep_rew_mean      | -4.85    |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5196     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 49990    |\n",
      "|    total_timesteps  | 517398   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 129099   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=517500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.385    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 517500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 129124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.2     |\n",
      "|    ep_rew_mean      | -5.3     |\n",
      "|    exploration_rate | 0.385    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5200     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50029    |\n",
      "|    total_timesteps  | 517798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 129199   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=518000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.385    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 518000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 129249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.7     |\n",
      "|    ep_rew_mean      | -5       |\n",
      "|    exploration_rate | 0.385    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5204     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50065    |\n",
      "|    total_timesteps  | 518147   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 129286   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=518500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 518500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 129374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.3     |\n",
      "|    ep_rew_mean      | -4.73    |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5208     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50100    |\n",
      "|    total_timesteps  | 518513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 129378   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.2     |\n",
      "|    ep_rew_mean      | -4.6     |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5212     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50125    |\n",
      "|    total_timesteps  | 518899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 129474   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=519000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 519000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 129499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.4     |\n",
      "|    ep_rew_mean      | -4.75    |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5216     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50162    |\n",
      "|    total_timesteps  | 519280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 129569   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=519500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 519500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 129624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.9     |\n",
      "|    ep_rew_mean      | -4.59    |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5220     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50198    |\n",
      "|    total_timesteps  | 519634   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00716  |\n",
      "|    n_updates        | 129658   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93       |\n",
      "|    ep_rew_mean      | -4.61    |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5224     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50220    |\n",
      "|    total_timesteps  | 519990   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 129747   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 520000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 129749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93       |\n",
      "|    ep_rew_mean      | -4.63    |\n",
      "|    exploration_rate | 0.382    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5228     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50258    |\n",
      "|    total_timesteps  | 520368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 129841   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=520500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.382    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 520500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 129874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93       |\n",
      "|    ep_rew_mean      | -4.65    |\n",
      "|    exploration_rate | 0.382    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5232     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50296    |\n",
      "|    total_timesteps  | 520768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 129941   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=521000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 521000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00549  |\n",
      "|    n_updates        | 129999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93       |\n",
      "|    ep_rew_mean      | -4.66    |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5236     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50334    |\n",
      "|    total_timesteps  | 521168   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 130041   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=521500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 521500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 130124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.3     |\n",
      "|    ep_rew_mean      | -5.12    |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5240     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50371    |\n",
      "|    total_timesteps  | 521568   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000946 |\n",
      "|    n_updates        | 130141   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.3     |\n",
      "|    ep_rew_mean      | -5.6     |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5244     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50397    |\n",
      "|    total_timesteps  | 521968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00307  |\n",
      "|    n_updates        | 130241   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=522000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 522000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 130249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96       |\n",
      "|    ep_rew_mean      | -5.93    |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5248     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50435    |\n",
      "|    total_timesteps  | 522368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00673  |\n",
      "|    n_updates        | 130341   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=522500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 522500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 130374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96       |\n",
      "|    ep_rew_mean      | -5.92    |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5252     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50474    |\n",
      "|    total_timesteps  | 522768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.319    |\n",
      "|    n_updates        | 130441   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=523000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 523000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 130499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.7     |\n",
      "|    ep_rew_mean      | -5.62    |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5256     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50511    |\n",
      "|    total_timesteps  | 523135   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 130533   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.2     |\n",
      "|    ep_rew_mean      | -5.45    |\n",
      "|    exploration_rate | 0.378    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5260     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50533    |\n",
      "|    total_timesteps  | 523485   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 130621   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=523500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.378    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 523500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 130624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.7     |\n",
      "|    ep_rew_mean      | -5.26    |\n",
      "|    exploration_rate | 0.378    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5264     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50572    |\n",
      "|    total_timesteps  | 523837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 130709   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=524000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.378    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 524000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 130749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.3     |\n",
      "|    ep_rew_mean      | -5.52    |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5268     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50610    |\n",
      "|    total_timesteps  | 524237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 130809   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=524500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 524500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 130874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.8     |\n",
      "|    ep_rew_mean      | -5.67    |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5272     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50651    |\n",
      "|    total_timesteps  | 524637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 130909   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 525000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 130999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.8     |\n",
      "|    ep_rew_mean      | -5.64    |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5276     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50691    |\n",
      "|    total_timesteps  | 525037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 131009   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.8     |\n",
      "|    ep_rew_mean      | -5.64    |\n",
      "|    exploration_rate | 0.376    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5280     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50716    |\n",
      "|    total_timesteps  | 525437   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00716  |\n",
      "|    n_updates        | 131109   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=525500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.376    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 525500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000967 |\n",
      "|    n_updates        | 131124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.8     |\n",
      "|    ep_rew_mean      | -5.6     |\n",
      "|    exploration_rate | 0.376    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5284     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50757    |\n",
      "|    total_timesteps  | 525837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 131209   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=526000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 526000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 131249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.8     |\n",
      "|    ep_rew_mean      | -5.59    |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5288     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50794    |\n",
      "|    total_timesteps  | 526237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 131309   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=526500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 526500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 131374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.1     |\n",
      "|    ep_rew_mean      | -5.73    |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5292     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50839    |\n",
      "|    total_timesteps  | 526637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 131409   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=527000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 527000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 131499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.4     |\n",
      "|    ep_rew_mean      | -6       |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5296     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50882    |\n",
      "|    total_timesteps  | 527037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 131509   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.4     |\n",
      "|    ep_rew_mean      | -5.99    |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5300     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50909    |\n",
      "|    total_timesteps  | 527437   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 131609   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=527500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 527500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 131624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.9     |\n",
      "|    ep_rew_mean      | -6.26    |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5304     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50948    |\n",
      "|    total_timesteps  | 527837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 131709   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=528000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 528000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 131749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.49    |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5308     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 50989    |\n",
      "|    total_timesteps  | 528237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 131809   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=528500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 528500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 131874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | -6.62    |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5312     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51026    |\n",
      "|    total_timesteps  | 528637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 131909   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=529000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 529000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00345  |\n",
      "|    n_updates        | 131999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.73    |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5316     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51070    |\n",
      "|    total_timesteps  | 529037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 132009   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.87    |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5320     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51095    |\n",
      "|    total_timesteps  | 529437   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 132109   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=529500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 529500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 132124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.5     |\n",
      "|    ep_rew_mean      | -7.03    |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5324     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51141    |\n",
      "|    total_timesteps  | 529837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0401   |\n",
      "|    n_updates        | 132209   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 530000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 132249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.12    |\n",
      "|    exploration_rate | 0.37     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5328     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51178    |\n",
      "|    total_timesteps  | 530237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00459  |\n",
      "|    n_updates        | 132309   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=530500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.37     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 530500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00863  |\n",
      "|    n_updates        | 132374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.09    |\n",
      "|    exploration_rate | 0.37     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5332     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51224    |\n",
      "|    total_timesteps  | 530637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 132409   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=531000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 531000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 132499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.07    |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5336     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51264    |\n",
      "|    total_timesteps  | 531037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0883   |\n",
      "|    n_updates        | 132509   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.5     |\n",
      "|    ep_rew_mean      | -6.92    |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5340     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51290    |\n",
      "|    total_timesteps  | 531413   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 132603   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=531500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 531500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 132624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.5     |\n",
      "|    ep_rew_mean      | -6.91    |\n",
      "|    exploration_rate | 0.368    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5344     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51329    |\n",
      "|    total_timesteps  | 531813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 132703   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=532000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.368    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 532000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 132749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.5     |\n",
      "|    ep_rew_mean      | -6.87    |\n",
      "|    exploration_rate | 0.368    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5348     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51368    |\n",
      "|    total_timesteps  | 532213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00748  |\n",
      "|    n_updates        | 132803   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=532500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.368    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 532500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00885  |\n",
      "|    n_updates        | 132874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.1     |\n",
      "|    ep_rew_mean      | -6.73    |\n",
      "|    exploration_rate | 0.368    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5352     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51408    |\n",
      "|    total_timesteps  | 532574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0034   |\n",
      "|    n_updates        | 132893   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -6.99    |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5356     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51432    |\n",
      "|    total_timesteps  | 532974   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00628  |\n",
      "|    n_updates        | 132993   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=533000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 533000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 132999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.9     |\n",
      "|    ep_rew_mean      | -7.01    |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5360     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51474    |\n",
      "|    total_timesteps  | 533372   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 133092   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=533500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 533500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00909  |\n",
      "|    n_updates        | 133124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.04    |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5364     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51510    |\n",
      "|    total_timesteps  | 533743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00423  |\n",
      "|    n_updates        | 133185   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=534000, episode_reward=10.70 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 33       |\n",
      "|    mean_reward      | 10.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 534000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 133249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.05    |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5368     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51546    |\n",
      "|    total_timesteps  | 534143   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00378  |\n",
      "|    n_updates        | 133285   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=534500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 534500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 133374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.06    |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5372     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51588    |\n",
      "|    total_timesteps  | 534543   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 133385   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.06    |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5376     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51613    |\n",
      "|    total_timesteps  | 534943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 133485   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 535000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 133499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.6     |\n",
      "|    ep_rew_mean      | -6.9     |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5380     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51650    |\n",
      "|    total_timesteps  | 535301   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 133575   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=535500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 535500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 133624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.3     |\n",
      "|    ep_rew_mean      | -6.75    |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5384     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51686    |\n",
      "|    total_timesteps  | 535668   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 133666   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=536000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 536000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 133749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.3     |\n",
      "|    ep_rew_mean      | -6.74    |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5388     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51727    |\n",
      "|    total_timesteps  | 536068   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 133766   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.62    |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5392     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51753    |\n",
      "|    total_timesteps  | 536438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 133859   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=536500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 536500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 133874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.64    |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5396     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51793    |\n",
      "|    total_timesteps  | 536838   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 133959   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=537000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 537000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 133999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.67    |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5400     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51833    |\n",
      "|    total_timesteps  | 537238   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 134059   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=537500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 537500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 134124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | -6.41    |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5404     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51871    |\n",
      "|    total_timesteps  | 537619   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00561  |\n",
      "|    n_updates        | 134154   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -6.11    |\n",
      "|    exploration_rate | 0.361    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5408     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51894    |\n",
      "|    total_timesteps  | 537933   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 134233   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=538000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.361    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 538000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 134249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -6.14    |\n",
      "|    exploration_rate | 0.361    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5412     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51931    |\n",
      "|    total_timesteps  | 538333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00285  |\n",
      "|    n_updates        | 134333   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=538500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.361    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 538500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 134374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -6.15    |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5416     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 51975    |\n",
      "|    total_timesteps  | 538733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 134433   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=539000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 539000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 134499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -6.16    |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5420     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52012    |\n",
      "|    total_timesteps  | 539133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00408  |\n",
      "|    n_updates        | 134533   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=539500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 539500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 134624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -6.15    |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5424     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52057    |\n",
      "|    total_timesteps  | 539533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 134633   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -6.18    |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5428     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52082    |\n",
      "|    total_timesteps  | 539933   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 134733   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 540000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 134749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -6.17    |\n",
      "|    exploration_rate | 0.358    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5432     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52129    |\n",
      "|    total_timesteps  | 540333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0505   |\n",
      "|    n_updates        | 134833   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=540500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.358    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 540500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00829  |\n",
      "|    n_updates        | 134874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | -6.16    |\n",
      "|    exploration_rate | 0.358    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5436     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52173    |\n",
      "|    total_timesteps  | 540733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00698  |\n",
      "|    n_updates        | 134933   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=541000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.358    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 541000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00693  |\n",
      "|    n_updates        | 134999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.37    |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5440     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52211    |\n",
      "|    total_timesteps  | 541133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00389  |\n",
      "|    n_updates        | 135033   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=541500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 541500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 135124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.35    |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5444     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52251    |\n",
      "|    total_timesteps  | 541533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00506  |\n",
      "|    n_updates        | 135133   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.2     |\n",
      "|    ep_rew_mean      | -6.42    |\n",
      "|    exploration_rate | 0.356    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5448     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52276    |\n",
      "|    total_timesteps  | 541933   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00865  |\n",
      "|    n_updates        | 135233   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=542000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.356    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 542000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 135249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.55    |\n",
      "|    exploration_rate | 0.356    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5452     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52319    |\n",
      "|    total_timesteps  | 542333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 135333   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=542500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.356    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 542500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 135374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.56    |\n",
      "|    exploration_rate | 0.356    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52362    |\n",
      "|    total_timesteps  | 542733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 135433   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=543000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 543000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00356  |\n",
      "|    n_updates        | 135499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.67    |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52400    |\n",
      "|    total_timesteps  | 543133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00487  |\n",
      "|    n_updates        | 135533   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=543500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 543500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 135624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.69    |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5464     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52441    |\n",
      "|    total_timesteps  | 543505   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00363  |\n",
      "|    n_updates        | 135626   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.7     |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5468     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52468    |\n",
      "|    total_timesteps  | 543905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 135726   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=544000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 544000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 135749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.71    |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5472     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52513    |\n",
      "|    total_timesteps  | 544305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00389  |\n",
      "|    n_updates        | 135826   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=544500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 544500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 135874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.6     |\n",
      "|    ep_rew_mean      | -6.74    |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52549    |\n",
      "|    total_timesteps  | 544705   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0326   |\n",
      "|    n_updates        | 135926   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 545000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 135999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | -6.91    |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52593    |\n",
      "|    total_timesteps  | 545105   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00717  |\n",
      "|    n_updates        | 136026   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=545500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 545500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 136124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.12    |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5484     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52635    |\n",
      "|    total_timesteps  | 545505   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0041   |\n",
      "|    n_updates        | 136126   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.04    |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52659    |\n",
      "|    total_timesteps  | 545904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 136225   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=546000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 546000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 136249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.18    |\n",
      "|    exploration_rate | 0.351    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52703    |\n",
      "|    total_timesteps  | 546304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0292   |\n",
      "|    n_updates        | 136325   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=546500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.351    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 546500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00581  |\n",
      "|    n_updates        | 136374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.2     |\n",
      "|    exploration_rate | 0.351    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52749    |\n",
      "|    total_timesteps  | 546704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 136425   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=547000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 547000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 136499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.7     |\n",
      "|    ep_rew_mean      | -7.21    |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52785    |\n",
      "|    total_timesteps  | 547104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 136525   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=547500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 547500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 136624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -7.49    |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52832    |\n",
      "|    total_timesteps  | 547504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 136625   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.81    |\n",
      "|    exploration_rate | 0.349    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5508     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52856    |\n",
      "|    total_timesteps  | 547904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 136725   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=548000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.349    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 548000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 136749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.349    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52902    |\n",
      "|    total_timesteps  | 548304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.034    |\n",
      "|    n_updates        | 136825   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=548500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.349    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 548500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00492  |\n",
      "|    n_updates        | 136874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.84    |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52943    |\n",
      "|    total_timesteps  | 548704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 136925   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=549000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 549000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 136999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.86    |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 52981    |\n",
      "|    total_timesteps  | 549104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 137025   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=549500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 549500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00345  |\n",
      "|    n_updates        | 137124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -7.85    |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53021    |\n",
      "|    total_timesteps  | 549504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00554  |\n",
      "|    n_updates        | 137125   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -7.68    |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53043    |\n",
      "|    total_timesteps  | 549867   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 137216   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 550000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00413  |\n",
      "|    n_updates        | 137249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.57    |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53082    |\n",
      "|    total_timesteps  | 550245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 137311   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=550500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 550500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 137374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.59    |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53126    |\n",
      "|    total_timesteps  | 550645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 137411   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=551000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 551000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 137499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.54    |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53163    |\n",
      "|    total_timesteps  | 551045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00526  |\n",
      "|    n_updates        | 137511   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.58    |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53194    |\n",
      "|    total_timesteps  | 551445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 137611   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=551500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 551500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 137624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.55    |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53238    |\n",
      "|    total_timesteps  | 551845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 137711   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=552000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 552000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0274   |\n",
      "|    n_updates        | 137749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.55    |\n",
      "|    exploration_rate | 0.344    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53275    |\n",
      "|    total_timesteps  | 552245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 137811   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=552500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.344    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 552500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 137874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.56    |\n",
      "|    exploration_rate | 0.344    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53322    |\n",
      "|    total_timesteps  | 552645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 137911   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=553000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.343    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 553000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0482   |\n",
      "|    n_updates        | 137999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.1     |\n",
      "|    ep_rew_mean      | -7.6     |\n",
      "|    exploration_rate | 0.343    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53367    |\n",
      "|    total_timesteps  | 553045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00505  |\n",
      "|    n_updates        | 138011   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.73    |\n",
      "|    exploration_rate | 0.343    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53391    |\n",
      "|    total_timesteps  | 553445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00313  |\n",
      "|    n_updates        | 138111   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=553500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.343    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 553500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00379  |\n",
      "|    n_updates        | 138124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.75    |\n",
      "|    exploration_rate | 0.342    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53433    |\n",
      "|    total_timesteps  | 553845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 138211   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=554000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.342    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 554000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 138249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.74    |\n",
      "|    exploration_rate | 0.342    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53471    |\n",
      "|    total_timesteps  | 554245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 138311   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=554500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.342    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 554500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 138374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.7     |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53512    |\n",
      "|    total_timesteps  | 554645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 138411   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 555000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 138499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.69    |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53552    |\n",
      "|    total_timesteps  | 555045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 138511   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.53    |\n",
      "|    exploration_rate | 0.34     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53577    |\n",
      "|    total_timesteps  | 555401   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 138600   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=555500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.34     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 555500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 138624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.63    |\n",
      "|    exploration_rate | 0.34     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53622    |\n",
      "|    total_timesteps  | 555801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 138700   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=556000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.34     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 556000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 138749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.65    |\n",
      "|    exploration_rate | 0.34     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53662    |\n",
      "|    total_timesteps  | 556201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 138800   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=556500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 556500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00445  |\n",
      "|    n_updates        | 138874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.62    |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53700    |\n",
      "|    total_timesteps  | 556601   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 138900   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=557000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 557000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000826 |\n",
      "|    n_updates        | 138999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.62    |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53743    |\n",
      "|    total_timesteps  | 557001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 139000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.43    |\n",
      "|    exploration_rate | 0.338    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53771    |\n",
      "|    total_timesteps  | 557346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 139086   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=557500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.338    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 557500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 139124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.43    |\n",
      "|    exploration_rate | 0.338    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53808    |\n",
      "|    total_timesteps  | 557746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 139186   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=558000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 558000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 139249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53853    |\n",
      "|    total_timesteps  | 558146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 139286   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=558500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 558500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 139374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.42    |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53898    |\n",
      "|    total_timesteps  | 558546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 139386   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.42    |\n",
      "|    exploration_rate | 0.336    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53922    |\n",
      "|    total_timesteps  | 558946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 139486   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=559000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.336    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 559000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.088    |\n",
      "|    n_updates        | 139499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.4     |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.336    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 53966    |\n",
      "|    total_timesteps  | 559346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0357   |\n",
      "|    n_updates        | 139586   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=559500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.336    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 559500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 139624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | -7.62    |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54002    |\n",
      "|    total_timesteps  | 559746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 139686   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 560000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0987   |\n",
      "|    n_updates        | 139749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.73    |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54048    |\n",
      "|    total_timesteps  | 560146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00829  |\n",
      "|    n_updates        | 139786   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=560500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.334    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 560500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 139874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.76    |\n",
      "|    exploration_rate | 0.334    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54093    |\n",
      "|    total_timesteps  | 560546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 139886   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.79    |\n",
      "|    exploration_rate | 0.334    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54117    |\n",
      "|    total_timesteps  | 560946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00444  |\n",
      "|    n_updates        | 139986   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=561000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.334    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 561000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0773   |\n",
      "|    n_updates        | 139999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.8     |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54166    |\n",
      "|    total_timesteps  | 561346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 140086   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=561500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 561500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0543   |\n",
      "|    n_updates        | 140124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.78    |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54203    |\n",
      "|    total_timesteps  | 561746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 140186   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=562000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 562000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 140249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.83    |\n",
      "|    exploration_rate | 0.332    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54249    |\n",
      "|    total_timesteps  | 562146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0309   |\n",
      "|    n_updates        | 140286   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=562500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.332    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 562500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00267  |\n",
      "|    n_updates        | 140374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.84    |\n",
      "|    exploration_rate | 0.332    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54293    |\n",
      "|    total_timesteps  | 562546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 140386   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.82    |\n",
      "|    exploration_rate | 0.332    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54318    |\n",
      "|    total_timesteps  | 562946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 140486   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=563000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 563000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00223  |\n",
      "|    n_updates        | 140499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.84    |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54364    |\n",
      "|    total_timesteps  | 563346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0609   |\n",
      "|    n_updates        | 140586   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=563500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 563500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 140624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.85    |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54406    |\n",
      "|    total_timesteps  | 563746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00765  |\n",
      "|    n_updates        | 140686   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=564000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 564000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 140749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.85    |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54446    |\n",
      "|    total_timesteps  | 564146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 140786   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=564500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 564500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 140874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.9     |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54487    |\n",
      "|    total_timesteps  | 564546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00563  |\n",
      "|    n_updates        | 140886   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99       |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.329    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54518    |\n",
      "|    total_timesteps  | 564946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00447  |\n",
      "|    n_updates        | 140986   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.329    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 565000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 140999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.329    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54555    |\n",
      "|    total_timesteps  | 565346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 141086   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=565500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 565500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00644  |\n",
      "|    n_updates        | 141124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54597    |\n",
      "|    total_timesteps  | 565746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00454  |\n",
      "|    n_updates        | 141186   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=566000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 566000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 141249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54641    |\n",
      "|    total_timesteps  | 566146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 141286   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=566500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 566500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 141374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54679    |\n",
      "|    total_timesteps  | 566546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00524  |\n",
      "|    n_updates        | 141386   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54708    |\n",
      "|    total_timesteps  | 566946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 141486   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=567000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 567000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00339  |\n",
      "|    n_updates        | 141499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.326    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54756    |\n",
      "|    total_timesteps  | 567346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 141586   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=567500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.326    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 567500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00425  |\n",
      "|    n_updates        | 141624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.326    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54792    |\n",
      "|    total_timesteps  | 567746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 141686   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=568000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.326    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 568000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 141749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5712     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54843    |\n",
      "|    total_timesteps  | 568146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00443  |\n",
      "|    n_updates        | 141786   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=568500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 568500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 141874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5716     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54882    |\n",
      "|    total_timesteps  | 568546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 141886   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.324    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5720     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54913    |\n",
      "|    total_timesteps  | 568946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 141986   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=569000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.324    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 569000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 141999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.324    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5724     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54956    |\n",
      "|    total_timesteps  | 569346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00327  |\n",
      "|    n_updates        | 142086   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=569500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.324    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 569500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 142124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.323    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5728     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 54994    |\n",
      "|    total_timesteps  | 569746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00289  |\n",
      "|    n_updates        | 142186   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.323    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 570000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000922 |\n",
      "|    n_updates        | 142249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.323    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5732     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55045    |\n",
      "|    total_timesteps  | 570146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 142286   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=570500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.323    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 570500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00672  |\n",
      "|    n_updates        | 142374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.322    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5736     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55089    |\n",
      "|    total_timesteps  | 570546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00489  |\n",
      "|    n_updates        | 142386   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.322    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5740     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55114    |\n",
      "|    total_timesteps  | 570946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0334   |\n",
      "|    n_updates        | 142486   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=571000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.322    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 571000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0274   |\n",
      "|    n_updates        | 142499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.322    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5744     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55157    |\n",
      "|    total_timesteps  | 571346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 142586   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=571500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 571500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 142624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.39    |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5748     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55194    |\n",
      "|    total_timesteps  | 571746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00574  |\n",
      "|    n_updates        | 142686   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=572000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 572000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00985  |\n",
      "|    n_updates        | 142749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5752     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55239    |\n",
      "|    total_timesteps  | 572146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 142786   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=572500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 572500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 142874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.39    |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5756     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55289    |\n",
      "|    total_timesteps  | 572546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 142886   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5760     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55314    |\n",
      "|    total_timesteps  | 572946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 142986   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=573000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 573000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 142999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5764     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55359    |\n",
      "|    total_timesteps  | 573346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0715   |\n",
      "|    n_updates        | 143086   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=573500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 573500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 143124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5768     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55406    |\n",
      "|    total_timesteps  | 573746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 143186   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=574000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.318    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 574000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00719  |\n",
      "|    n_updates        | 143249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.318    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5772     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55443    |\n",
      "|    total_timesteps  | 574146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 143286   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=574500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.318    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 574500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 143374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.318    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5776     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55492    |\n",
      "|    total_timesteps  | 574546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 143386   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5780     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55517    |\n",
      "|    total_timesteps  | 574946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 143486   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 575000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 143499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5784     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55561    |\n",
      "|    total_timesteps  | 575346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00382  |\n",
      "|    n_updates        | 143586   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=575500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 575500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 143624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5788     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55606    |\n",
      "|    total_timesteps  | 575746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 143686   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=576000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 576000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 143749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5792     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55649    |\n",
      "|    total_timesteps  | 576146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0668   |\n",
      "|    n_updates        | 143786   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=576500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.315    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 576500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 143874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.315    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5796     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55686    |\n",
      "|    total_timesteps  | 576512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 143877   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.315    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5800     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55717    |\n",
      "|    total_timesteps  | 576912   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.432    |\n",
      "|    n_updates        | 143977   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=577000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.315    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 577000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 143999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.314    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5804     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55756    |\n",
      "|    total_timesteps  | 577312   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00663  |\n",
      "|    n_updates        | 144077   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=577500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.314    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 577500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 144124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.314    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5808     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55799    |\n",
      "|    total_timesteps  | 577712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 144177   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=578000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.314    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 578000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00621  |\n",
      "|    n_updates        | 144249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.91    |\n",
      "|    exploration_rate | 0.314    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5812     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55842    |\n",
      "|    total_timesteps  | 578088   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00486  |\n",
      "|    n_updates        | 144271   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5816     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55866    |\n",
      "|    total_timesteps  | 578488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 144371   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=578500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 578500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 144374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5820     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55913    |\n",
      "|    total_timesteps  | 578888   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 144471   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=579000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 579000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 144499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.91    |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5824     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55959    |\n",
      "|    total_timesteps  | 579288   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00386  |\n",
      "|    n_updates        | 144571   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=579500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 579500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 144624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.88    |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5828     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 55997    |\n",
      "|    total_timesteps  | 579688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 144671   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 580000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 144749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.76    |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5832     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56044    |\n",
      "|    total_timesteps  | 580082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0447   |\n",
      "|    n_updates        | 144770   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.79    |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5836     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56071    |\n",
      "|    total_timesteps  | 580482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 144870   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=580500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 580500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.042    |\n",
      "|    n_updates        | 144874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.79    |\n",
      "|    exploration_rate | 0.31     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5840     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56111    |\n",
      "|    total_timesteps  | 580882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00515  |\n",
      "|    n_updates        | 144970   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=581000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.31     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 581000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00448  |\n",
      "|    n_updates        | 144999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.83    |\n",
      "|    exploration_rate | 0.31     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5844     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56153    |\n",
      "|    total_timesteps  | 581282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00599  |\n",
      "|    n_updates        | 145070   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=581500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.309    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 581500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 145124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.85    |\n",
      "|    exploration_rate | 0.309    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5848     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56199    |\n",
      "|    total_timesteps  | 581682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 145170   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=582000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.309    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 582000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 145249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.88    |\n",
      "|    exploration_rate | 0.309    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5852     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56245    |\n",
      "|    total_timesteps  | 582082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00509  |\n",
      "|    n_updates        | 145270   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.87    |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5856     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56270    |\n",
      "|    total_timesteps  | 582482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 145370   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=582500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 582500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00543  |\n",
      "|    n_updates        | 145374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.85    |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5860     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56313    |\n",
      "|    total_timesteps  | 582882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 145470   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=583000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 583000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00974  |\n",
      "|    n_updates        | 145499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.91    |\n",
      "|    exploration_rate | 0.307    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5864     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56359    |\n",
      "|    total_timesteps  | 583282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.162    |\n",
      "|    n_updates        | 145570   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=583500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.307    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 583500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 145624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.94    |\n",
      "|    exploration_rate | 0.307    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5868     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56406    |\n",
      "|    total_timesteps  | 583682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.034    |\n",
      "|    n_updates        | 145670   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=584000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.307    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 584000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00457  |\n",
      "|    n_updates        | 145749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.306    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5872     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56448    |\n",
      "|    total_timesteps  | 584082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00579  |\n",
      "|    n_updates        | 145770   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.306    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5876     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56475    |\n",
      "|    total_timesteps  | 584482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 145870   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=584500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.306    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 584500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.029    |\n",
      "|    n_updates        | 145874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.97    |\n",
      "|    exploration_rate | 0.305    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5880     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56524    |\n",
      "|    total_timesteps  | 584882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 145970   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.305    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 585000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00878  |\n",
      "|    n_updates        | 145999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.94    |\n",
      "|    exploration_rate | 0.305    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5884     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56566    |\n",
      "|    total_timesteps  | 585282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 146070   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=585500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.305    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 585500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 146124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.305    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5888     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56611    |\n",
      "|    total_timesteps  | 585682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 146170   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=586000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.304    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 586000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 146249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.4     |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.304    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5892     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56652    |\n",
      "|    total_timesteps  | 586082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00259  |\n",
      "|    n_updates        | 146270   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.304    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5896     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56680    |\n",
      "|    total_timesteps  | 586482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 146370   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=586500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.304    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 586500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00378  |\n",
      "|    n_updates        | 146374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.303    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5900     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56720    |\n",
      "|    total_timesteps  | 586882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00259  |\n",
      "|    n_updates        | 146470   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=587000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.303    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 587000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00767  |\n",
      "|    n_updates        | 146499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.303    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5904     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56767    |\n",
      "|    total_timesteps  | 587282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0242   |\n",
      "|    n_updates        | 146570   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=587500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.302    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 587500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 146624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.302    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5908     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56813    |\n",
      "|    total_timesteps  | 587682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00566  |\n",
      "|    n_updates        | 146670   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=588000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.302    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 588000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 146749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.9     |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.302    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5912     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56855    |\n",
      "|    total_timesteps  | 588082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 146770   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.9     |\n",
      "|    ep_rew_mean      | -8.46    |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5916     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56882    |\n",
      "|    total_timesteps  | 588482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 146870   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=588500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 588500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 146874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.9     |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5920     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56922    |\n",
      "|    total_timesteps  | 588882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0064   |\n",
      "|    n_updates        | 146970   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=589000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 589000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 146999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.9     |\n",
      "|    ep_rew_mean      | -8.48    |\n",
      "|    exploration_rate | 0.3      |\n",
      "| time/               |          |\n",
      "|    episodes         | 5924     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56967    |\n",
      "|    total_timesteps  | 589282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00627  |\n",
      "|    n_updates        | 147070   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=589500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.3      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 589500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 147124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.9     |\n",
      "|    ep_rew_mean      | -8.49    |\n",
      "|    exploration_rate | 0.3      |\n",
      "| time/               |          |\n",
      "|    episodes         | 5928     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57013    |\n",
      "|    total_timesteps  | 589682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.309    |\n",
      "|    n_updates        | 147170   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 590000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 147249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5932     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57051    |\n",
      "|    total_timesteps  | 590082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 147270   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5936     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57084    |\n",
      "|    total_timesteps  | 590482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00868  |\n",
      "|    n_updates        | 147370   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=590500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 590500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 147374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.298    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5940     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57130    |\n",
      "|    total_timesteps  | 590882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0069   |\n",
      "|    n_updates        | 147470   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=591000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.298    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 591000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 147499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.298    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5944     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57172    |\n",
      "|    total_timesteps  | 591282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00438  |\n",
      "|    n_updates        | 147570   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=591500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.298    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 591500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0787   |\n",
      "|    n_updates        | 147624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5948     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57208    |\n",
      "|    total_timesteps  | 591682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00848  |\n",
      "|    n_updates        | 147670   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=592000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 592000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 147749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5952     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57250    |\n",
      "|    total_timesteps  | 592082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 147770   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.296    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5956     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57283    |\n",
      "|    total_timesteps  | 592482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 147870   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=592500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.296    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 592500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 147874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.296    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5960     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57321    |\n",
      "|    total_timesteps  | 592882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0355   |\n",
      "|    n_updates        | 147970   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=593000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.296    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 593000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 147999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.295    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5964     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57366    |\n",
      "|    total_timesteps  | 593282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00352  |\n",
      "|    n_updates        | 148070   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=593500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.295    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 593500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 148124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.295    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5968     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57410    |\n",
      "|    total_timesteps  | 593682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00511  |\n",
      "|    n_updates        | 148170   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=594000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.295    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 594000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 148249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.295    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5972     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57456    |\n",
      "|    total_timesteps  | 594082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 148270   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.294    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5976     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57480    |\n",
      "|    total_timesteps  | 594482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 148370   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=594500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.294    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 594500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0458   |\n",
      "|    n_updates        | 148374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.294    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5980     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57528    |\n",
      "|    total_timesteps  | 594882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0087   |\n",
      "|    n_updates        | 148470   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 595000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 148499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5984     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57572    |\n",
      "|    total_timesteps  | 595282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 148570   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=595500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 595500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 148624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5988     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57617    |\n",
      "|    total_timesteps  | 595682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00658  |\n",
      "|    n_updates        | 148670   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=596000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 596000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 148749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5992     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57655    |\n",
      "|    total_timesteps  | 596082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00347  |\n",
      "|    n_updates        | 148770   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 5996     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57688    |\n",
      "|    total_timesteps  | 596482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00723  |\n",
      "|    n_updates        | 148870   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=596500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 596500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 148874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.291    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6000     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57734    |\n",
      "|    total_timesteps  | 596882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00562  |\n",
      "|    n_updates        | 148970   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=597000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.291    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 597000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 148999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.291    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6004     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57771    |\n",
      "|    total_timesteps  | 597282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00319  |\n",
      "|    n_updates        | 149070   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=597500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 597500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0044   |\n",
      "|    n_updates        | 149124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6008     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57819    |\n",
      "|    total_timesteps  | 597682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0032   |\n",
      "|    n_updates        | 149170   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=598000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 598000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 149249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6012     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57865    |\n",
      "|    total_timesteps  | 598082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 149270   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.52    |\n",
      "|    exploration_rate | 0.289    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6016     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57888    |\n",
      "|    total_timesteps  | 598445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 149361   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=598500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.289    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 598500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 149374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.289    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6020     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57936    |\n",
      "|    total_timesteps  | 598845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00831  |\n",
      "|    n_updates        | 149461   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=599000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.289    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 599000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 149499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6024     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 57984    |\n",
      "|    total_timesteps  | 599245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 149561   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=599500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 599500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00858  |\n",
      "|    n_updates        | 149624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.58    |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6028     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58029    |\n",
      "|    total_timesteps  | 599645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 149661   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 600000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00332  |\n",
      "|    n_updates        | 149749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.287    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6032     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58066    |\n",
      "|    total_timesteps  | 600045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 149761   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.57    |\n",
      "|    exploration_rate | 0.287    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6036     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58099    |\n",
      "|    total_timesteps  | 600445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 149861   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=600500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.287    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 600500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00483  |\n",
      "|    n_updates        | 149874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.54    |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6040     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58146    |\n",
      "|    total_timesteps  | 600845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00645  |\n",
      "|    n_updates        | 149961   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=601000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 601000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.099    |\n",
      "|    n_updates        | 149999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.5     |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6044     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58187    |\n",
      "|    total_timesteps  | 601245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0535   |\n",
      "|    n_updates        | 150061   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=601500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 601500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 150124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.49    |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6048     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58227    |\n",
      "|    total_timesteps  | 601645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 150161   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=602000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.285    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 602000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 150249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.49    |\n",
      "|    exploration_rate | 0.285    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6052     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58271    |\n",
      "|    total_timesteps  | 602045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 150261   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.49    |\n",
      "|    exploration_rate | 0.285    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6056     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58295    |\n",
      "|    total_timesteps  | 602445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 150361   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=602500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.285    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 602500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 150374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.284    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6060     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58341    |\n",
      "|    total_timesteps  | 602845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00268  |\n",
      "|    n_updates        | 150461   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=603000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.284    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 603000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00517  |\n",
      "|    n_updates        | 150499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.43    |\n",
      "|    exploration_rate | 0.284    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6064     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58387    |\n",
      "|    total_timesteps  | 603245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 150561   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=603500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 603500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 150624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.39    |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6068     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58433    |\n",
      "|    total_timesteps  | 603645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.32     |\n",
      "|    n_updates        | 150661   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=604000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 604000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 150749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6072     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58477    |\n",
      "|    total_timesteps  | 604045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 150761   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.282    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6076     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58501    |\n",
      "|    total_timesteps  | 604445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 150861   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=604500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.282    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 604500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00756  |\n",
      "|    n_updates        | 150874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.43    |\n",
      "|    exploration_rate | 0.282    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6080     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58548    |\n",
      "|    total_timesteps  | 604845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 150961   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.282    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 605000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 150999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.42    |\n",
      "|    exploration_rate | 0.281    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6084     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58594    |\n",
      "|    total_timesteps  | 605245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 151061   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=605500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.281    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 605500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 151124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.281    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6088     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58639    |\n",
      "|    total_timesteps  | 605645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0352   |\n",
      "|    n_updates        | 151161   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=606000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 606000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 151249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.42    |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6092     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58676    |\n",
      "|    total_timesteps  | 606045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00808  |\n",
      "|    n_updates        | 151261   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.29    |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6096     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58710    |\n",
      "|    total_timesteps  | 606437   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 151359   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=606500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 606500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 151374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.29    |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6100     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58755    |\n",
      "|    total_timesteps  | 606837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00572  |\n",
      "|    n_updates        | 151459   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=607000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 607000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00494  |\n",
      "|    n_updates        | 151499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6104     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58797    |\n",
      "|    total_timesteps  | 607237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 151559   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=607500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 607500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 151624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.5     |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6108     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58838    |\n",
      "|    total_timesteps  | 607637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 151659   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=608000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 608000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00556  |\n",
      "|    n_updates        | 151749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.3     |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6112     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58883    |\n",
      "|    total_timesteps  | 608008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0317   |\n",
      "|    n_updates        | 151751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6116     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58914    |\n",
      "|    total_timesteps  | 608408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00421  |\n",
      "|    n_updates        | 151851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=608500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.277    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 608500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 151874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.277    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6120     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58957    |\n",
      "|    total_timesteps  | 608808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 151951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=609000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.277    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 609000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 151999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.277    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6124     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 58995    |\n",
      "|    total_timesteps  | 609208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00371  |\n",
      "|    n_updates        | 152051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=609500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 609500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0715   |\n",
      "|    n_updates        | 152124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6128     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59034    |\n",
      "|    total_timesteps  | 609608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00738  |\n",
      "|    n_updates        | 152151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 610000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00759  |\n",
      "|    n_updates        | 152249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6132     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59080    |\n",
      "|    total_timesteps  | 610008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.025    |\n",
      "|    n_updates        | 152251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.275    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6136     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59106    |\n",
      "|    total_timesteps  | 610408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0308   |\n",
      "|    n_updates        | 152351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=610500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.275    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 610500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 152374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.275    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6140     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59155    |\n",
      "|    total_timesteps  | 610808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 152451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=611000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 611000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 152499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6144     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59200    |\n",
      "|    total_timesteps  | 611208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 152551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=611500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 611500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 152624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6148     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59237    |\n",
      "|    total_timesteps  | 611608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00646  |\n",
      "|    n_updates        | 152651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=612000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 612000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 152749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6152     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59281    |\n",
      "|    total_timesteps  | 612008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 152751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6156     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59312    |\n",
      "|    total_timesteps  | 612408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 152851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=612500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 612500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 152874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.272    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6160     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59349    |\n",
      "|    total_timesteps  | 612808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00821  |\n",
      "|    n_updates        | 152951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=613000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.272    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 613000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0611   |\n",
      "|    n_updates        | 152999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.272    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6164     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59395    |\n",
      "|    total_timesteps  | 613208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 153051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=613500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.271    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 613500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 153124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.271    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6168     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59436    |\n",
      "|    total_timesteps  | 613608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 153151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=614000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.271    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 614000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 153249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.39    |\n",
      "|    exploration_rate | 0.271    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6172     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59479    |\n",
      "|    total_timesteps  | 614008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 153251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.27     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6176     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59505    |\n",
      "|    total_timesteps  | 614408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00479  |\n",
      "|    n_updates        | 153351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=614500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.27     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 614500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00574  |\n",
      "|    n_updates        | 153374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.27     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6180     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59544    |\n",
      "|    total_timesteps  | 614808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00534  |\n",
      "|    n_updates        | 153451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=615000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.27     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 615000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00348  |\n",
      "|    n_updates        | 153499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.269    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6184     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59590    |\n",
      "|    total_timesteps  | 615208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 153551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=615500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.269    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 615500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 153624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.43    |\n",
      "|    exploration_rate | 0.269    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6188     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59642    |\n",
      "|    total_timesteps  | 615608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0869   |\n",
      "|    n_updates        | 153651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=616000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.269    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 616000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 153749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.6     |\n",
      "|    ep_rew_mean      | -8.42    |\n",
      "|    exploration_rate | 0.268    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6192     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59680    |\n",
      "|    total_timesteps  | 616008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0795   |\n",
      "|    n_updates        | 153751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.268    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6196     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59708    |\n",
      "|    total_timesteps  | 616408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00931  |\n",
      "|    n_updates        | 153851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=616500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.268    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 616500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00536  |\n",
      "|    n_updates        | 153874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.54    |\n",
      "|    exploration_rate | 0.268    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6200     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59753    |\n",
      "|    total_timesteps  | 616808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 153951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=617000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 617000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 153999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.51    |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6204     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59789    |\n",
      "|    total_timesteps  | 617208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 154051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=617500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 617500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 154124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | -8.51    |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6208     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59835    |\n",
      "|    total_timesteps  | 617608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 154151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=618000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 618000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 154249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6212     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59878    |\n",
      "|    total_timesteps  | 618008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 154251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6216     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59903    |\n",
      "|    total_timesteps  | 618408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 154351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=618500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 618500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 154374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.265    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6220     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59949    |\n",
      "|    total_timesteps  | 618808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0279   |\n",
      "|    n_updates        | 154451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=619000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.265    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 619000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 154499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.265    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6224     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 59993    |\n",
      "|    total_timesteps  | 619208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 154551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=619500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.264    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 619500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00482  |\n",
      "|    n_updates        | 154624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.264    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6228     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60030    |\n",
      "|    total_timesteps  | 619608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 154651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.264    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 620000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00369  |\n",
      "|    n_updates        | 154749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.264    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6232     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60076    |\n",
      "|    total_timesteps  | 620008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 154751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6236     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60109    |\n",
      "|    total_timesteps  | 620408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 154851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=620500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 620500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0301   |\n",
      "|    n_updates        | 154874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6240     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60149    |\n",
      "|    total_timesteps  | 620808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0821   |\n",
      "|    n_updates        | 154951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=621000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 621000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 154999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.262    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6244     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60198    |\n",
      "|    total_timesteps  | 621208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 155051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=621500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.262    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 621500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 155124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.262    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6248     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60235    |\n",
      "|    total_timesteps  | 621608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 155151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=622000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.261    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 622000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00593  |\n",
      "|    n_updates        | 155249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.261    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6252     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60282    |\n",
      "|    total_timesteps  | 622008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 155251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.261    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6256     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60318    |\n",
      "|    total_timesteps  | 622408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00284  |\n",
      "|    n_updates        | 155351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=622500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.261    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 622500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0375   |\n",
      "|    n_updates        | 155374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.78    |\n",
      "|    exploration_rate | 0.26     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6260     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60354    |\n",
      "|    total_timesteps  | 622808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 155451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=623000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.26     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 623000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0068   |\n",
      "|    n_updates        | 155499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.26     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6264     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60401    |\n",
      "|    total_timesteps  | 623208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 155551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=623500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.26     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 623500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 155624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6268     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60446    |\n",
      "|    total_timesteps  | 623608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.053    |\n",
      "|    n_updates        | 155651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=624000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 624000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 155749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6272     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60483    |\n",
      "|    total_timesteps  | 624008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 155751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6276     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60516    |\n",
      "|    total_timesteps  | 624408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 155851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=624500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.258    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 624500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0287   |\n",
      "|    n_updates        | 155874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.258    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6280     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60560    |\n",
      "|    total_timesteps  | 624808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00593  |\n",
      "|    n_updates        | 155951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.258    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 625000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.061    |\n",
      "|    n_updates        | 155999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.258    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6284     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60599    |\n",
      "|    total_timesteps  | 625208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00438  |\n",
      "|    n_updates        | 156051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=625500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.257    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 625500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 156124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.82    |\n",
      "|    exploration_rate | 0.257    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6288     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60643    |\n",
      "|    total_timesteps  | 625608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 156151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=626000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.257    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 626000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 156249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.257    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6292     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60688    |\n",
      "|    total_timesteps  | 626008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00455  |\n",
      "|    n_updates        | 156251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.256    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6296     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60712    |\n",
      "|    total_timesteps  | 626408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 156351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=626500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.256    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 626500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 156374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.256    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6300     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60759    |\n",
      "|    total_timesteps  | 626808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 156451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=627000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 627000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 156499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6304     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60807    |\n",
      "|    total_timesteps  | 627208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00505  |\n",
      "|    n_updates        | 156551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=627500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 627500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00969  |\n",
      "|    n_updates        | 156624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6308     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60849    |\n",
      "|    total_timesteps  | 627608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00649  |\n",
      "|    n_updates        | 156651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=628000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.254    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 628000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 156749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.254    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6312     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60889    |\n",
      "|    total_timesteps  | 628008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 156751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.254    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6316     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60925    |\n",
      "|    total_timesteps  | 628408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 156851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=628500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.254    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 628500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 156874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.253    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6320     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 60963    |\n",
      "|    total_timesteps  | 628808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 156951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=629000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.253    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 629000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0305   |\n",
      "|    n_updates        | 156999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.253    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6324     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61008    |\n",
      "|    total_timesteps  | 629208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 157051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=629500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.252    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 629500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 157124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.252    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6328     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61052    |\n",
      "|    total_timesteps  | 629608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 157151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.252    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 630000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 157249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.252    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6332     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61098    |\n",
      "|    total_timesteps  | 630008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0348   |\n",
      "|    n_updates        | 157251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6336     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61124    |\n",
      "|    total_timesteps  | 630408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 157351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=630500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 630500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 157374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6340     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61166    |\n",
      "|    total_timesteps  | 630808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00847  |\n",
      "|    n_updates        | 157451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=631000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 631000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 157499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.25     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6344     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61210    |\n",
      "|    total_timesteps  | 631208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00836  |\n",
      "|    n_updates        | 157551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=631500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.25     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 631500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0331   |\n",
      "|    n_updates        | 157624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.25     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6348     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61255    |\n",
      "|    total_timesteps  | 631608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00464  |\n",
      "|    n_updates        | 157651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=632000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.25     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 632000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 157749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.249    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6352     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61302    |\n",
      "|    total_timesteps  | 632008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00621  |\n",
      "|    n_updates        | 157751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.249    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6356     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61326    |\n",
      "|    total_timesteps  | 632408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.025    |\n",
      "|    n_updates        | 157851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=632500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.249    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 632500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 157874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.249    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6360     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61373    |\n",
      "|    total_timesteps  | 632808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 157951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=633000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.248    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 633000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 157999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.248    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6364     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61423    |\n",
      "|    total_timesteps  | 633208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0781   |\n",
      "|    n_updates        | 158051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=633500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.248    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 633500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0702   |\n",
      "|    n_updates        | 158124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.248    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6368     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61470    |\n",
      "|    total_timesteps  | 633608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 158151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=634000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 634000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00876  |\n",
      "|    n_updates        | 158249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6372     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61506    |\n",
      "|    total_timesteps  | 634008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0904   |\n",
      "|    n_updates        | 158251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6376     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61545    |\n",
      "|    total_timesteps  | 634408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 158351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=634500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 634500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00496  |\n",
      "|    n_updates        | 158374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6380     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61583    |\n",
      "|    total_timesteps  | 634808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0448   |\n",
      "|    n_updates        | 158451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 635000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 158499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6384     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61628    |\n",
      "|    total_timesteps  | 635208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 158551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=635500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.245    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 635500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00712  |\n",
      "|    n_updates        | 158624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.245    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6388     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61676    |\n",
      "|    total_timesteps  | 635608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 158651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=636000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.245    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 636000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00564  |\n",
      "|    n_updates        | 158749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.245    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6392     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61721    |\n",
      "|    total_timesteps  | 636008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 158751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.244    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6396     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61748    |\n",
      "|    total_timesteps  | 636408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 158851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=636500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.244    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 636500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0735   |\n",
      "|    n_updates        | 158874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.244    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6400     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61795    |\n",
      "|    total_timesteps  | 636808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00446  |\n",
      "|    n_updates        | 158951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=637000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.244    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 637000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 158999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.243    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6404     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61833    |\n",
      "|    total_timesteps  | 637208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 159051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=637500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.243    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 637500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 159124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.243    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6408     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61877    |\n",
      "|    total_timesteps  | 637608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 159151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=638000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.242    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 638000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 159249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.242    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6412     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61919    |\n",
      "|    total_timesteps  | 638008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 159251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.242    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6416     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61950    |\n",
      "|    total_timesteps  | 638408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 159351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=638500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.242    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 638500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0279   |\n",
      "|    n_updates        | 159374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.241    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6420     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 61996    |\n",
      "|    total_timesteps  | 638808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00484  |\n",
      "|    n_updates        | 159451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=639000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.241    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 639000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0761   |\n",
      "|    n_updates        | 159499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.241    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6424     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62042    |\n",
      "|    total_timesteps  | 639208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00641  |\n",
      "|    n_updates        | 159551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=639500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.241    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 639500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 159624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6428     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62079    |\n",
      "|    total_timesteps  | 639608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00373  |\n",
      "|    n_updates        | 159651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 640000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0738   |\n",
      "|    n_updates        | 159749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6432     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62126    |\n",
      "|    total_timesteps  | 640008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.074    |\n",
      "|    n_updates        | 159751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6436     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62164    |\n",
      "|    total_timesteps  | 640408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0301   |\n",
      "|    n_updates        | 159851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=640500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.239    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 640500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00982  |\n",
      "|    n_updates        | 159874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.239    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6440     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62201    |\n",
      "|    total_timesteps  | 640808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0274   |\n",
      "|    n_updates        | 159951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=641000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.239    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 641000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0587   |\n",
      "|    n_updates        | 159999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.239    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6444     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62245    |\n",
      "|    total_timesteps  | 641208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 160051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=641500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 641500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0875   |\n",
      "|    n_updates        | 160124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6448     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62291    |\n",
      "|    total_timesteps  | 641608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00994  |\n",
      "|    n_updates        | 160151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=642000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 642000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 160249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6452     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62340    |\n",
      "|    total_timesteps  | 642008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 160251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.237    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62365    |\n",
      "|    total_timesteps  | 642408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 160351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=642500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.237    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 642500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 160374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.237    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62409    |\n",
      "|    total_timesteps  | 642808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 160451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=643000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 643000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 160499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6464     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62454    |\n",
      "|    total_timesteps  | 643208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00852  |\n",
      "|    n_updates        | 160551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=643500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 643500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00455  |\n",
      "|    n_updates        | 160624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6468     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62498    |\n",
      "|    total_timesteps  | 643608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 160651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=644000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.235    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 644000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0268   |\n",
      "|    n_updates        | 160749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.235    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6472     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62536    |\n",
      "|    total_timesteps  | 644008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00313  |\n",
      "|    n_updates        | 160751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.235    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62568    |\n",
      "|    total_timesteps  | 644408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00899  |\n",
      "|    n_updates        | 160851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=644500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.235    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 644500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 160874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.234    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62615    |\n",
      "|    total_timesteps  | 644808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0049   |\n",
      "|    n_updates        | 160951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.234    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 645000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 160999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.234    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6484     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62652    |\n",
      "|    total_timesteps  | 645208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00946  |\n",
      "|    n_updates        | 161051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=645500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.233    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 645500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00324  |\n",
      "|    n_updates        | 161124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.233    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62702    |\n",
      "|    total_timesteps  | 645608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00331  |\n",
      "|    n_updates        | 161151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=646000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.233    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 646000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0051   |\n",
      "|    n_updates        | 161249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.233    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62750    |\n",
      "|    total_timesteps  | 646008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00868  |\n",
      "|    n_updates        | 161251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.232    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62775    |\n",
      "|    total_timesteps  | 646408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 161351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=646500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.232    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 646500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 161374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.232    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62823    |\n",
      "|    total_timesteps  | 646808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 161451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=647000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.232    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 647000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00542  |\n",
      "|    n_updates        | 161499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.82    |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62870    |\n",
      "|    total_timesteps  | 647208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 161551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=647500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 647500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00992  |\n",
      "|    n_updates        | 161624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6508     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62918    |\n",
      "|    total_timesteps  | 647608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 161651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=648000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 648000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 161749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.23     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62955    |\n",
      "|    total_timesteps  | 648008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 161751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.23     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 62987    |\n",
      "|    total_timesteps  | 648408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 161851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=648500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.23     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 648500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 161874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.23     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63032    |\n",
      "|    total_timesteps  | 648808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 161951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=649000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.229    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 649000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 161999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.229    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63077    |\n",
      "|    total_timesteps  | 649208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 162051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=649500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.229    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 649500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 162124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.229    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63118    |\n",
      "|    total_timesteps  | 649608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00562  |\n",
      "|    n_updates        | 162151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 650000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 162249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63161    |\n",
      "|    total_timesteps  | 650008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 162251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63197    |\n",
      "|    total_timesteps  | 650408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 162351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=650500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 650500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 162374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.227    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63240    |\n",
      "|    total_timesteps  | 650808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 162451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=651000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.227    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 651000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00483  |\n",
      "|    n_updates        | 162499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.227    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63281    |\n",
      "|    total_timesteps  | 651208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0683   |\n",
      "|    n_updates        | 162551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=651500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.226    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 651500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 162624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.226    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63331    |\n",
      "|    total_timesteps  | 651608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 162651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=652000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.226    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 652000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 162749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.226    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63381    |\n",
      "|    total_timesteps  | 652008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00871  |\n",
      "|    n_updates        | 162751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63405    |\n",
      "|    total_timesteps  | 652408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00284  |\n",
      "|    n_updates        | 162851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=652500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 652500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0688   |\n",
      "|    n_updates        | 162874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63453    |\n",
      "|    total_timesteps  | 652808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 162951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=653000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 653000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 162999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.224    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63499    |\n",
      "|    total_timesteps  | 653208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 163051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=653500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.224    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 653500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 163124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.224    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63539    |\n",
      "|    total_timesteps  | 653608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 163151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=654000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.223    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 654000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.233    |\n",
      "|    n_updates        | 163249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.223    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63584    |\n",
      "|    total_timesteps  | 654008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 163251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.223    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63608    |\n",
      "|    total_timesteps  | 654408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 163351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=654500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.223    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 654500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0517   |\n",
      "|    n_updates        | 163374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.222    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63655    |\n",
      "|    total_timesteps  | 654808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 163451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.222    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 655000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00818  |\n",
      "|    n_updates        | 163499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.222    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63703    |\n",
      "|    total_timesteps  | 655208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 163551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=655500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.222    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 655500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00812  |\n",
      "|    n_updates        | 163624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63749    |\n",
      "|    total_timesteps  | 655608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 163651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=656000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 656000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 163749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63792    |\n",
      "|    total_timesteps  | 656008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 163751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63817    |\n",
      "|    total_timesteps  | 656408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00992  |\n",
      "|    n_updates        | 163851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=656500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.22     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 656500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 163874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.22     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63864    |\n",
      "|    total_timesteps  | 656808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 163951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=657000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.22     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 657000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00562  |\n",
      "|    n_updates        | 163999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.82    |\n",
      "|    exploration_rate | 0.22     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63910    |\n",
      "|    total_timesteps  | 657208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 164051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=657500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.219    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 657500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00989  |\n",
      "|    n_updates        | 164124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.219    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 63959    |\n",
      "|    total_timesteps  | 657608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 164151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=658000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.219    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 658000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00467  |\n",
      "|    n_updates        | 164249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.219    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64003    |\n",
      "|    total_timesteps  | 658008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 164251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.218    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64030    |\n",
      "|    total_timesteps  | 658408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 164351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=658500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.218    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 658500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 164374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.218    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64076    |\n",
      "|    total_timesteps  | 658808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00626  |\n",
      "|    n_updates        | 164451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=659000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 659000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 164499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64123    |\n",
      "|    total_timesteps  | 659208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 164551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=659500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 659500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 164624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64171    |\n",
      "|    total_timesteps  | 659608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 164651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 660000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 164749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64225    |\n",
      "|    total_timesteps  | 660008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0892   |\n",
      "|    n_updates        | 164751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.82    |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64251    |\n",
      "|    total_timesteps  | 660408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0934   |\n",
      "|    n_updates        | 164851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=660500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 660500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 164874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.215    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64292    |\n",
      "|    total_timesteps  | 660808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 164951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=661000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.215    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 661000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 164999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.215    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64335    |\n",
      "|    total_timesteps  | 661208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 165051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=661500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.214    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 661500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 165124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.214    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64378    |\n",
      "|    total_timesteps  | 661608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00892  |\n",
      "|    n_updates        | 165151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=662000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.214    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 662000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00411  |\n",
      "|    n_updates        | 165249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.214    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64427    |\n",
      "|    total_timesteps  | 662008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0079   |\n",
      "|    n_updates        | 165251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64453    |\n",
      "|    total_timesteps  | 662408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0424   |\n",
      "|    n_updates        | 165351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=662500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 662500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0906   |\n",
      "|    n_updates        | 165374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64502    |\n",
      "|    total_timesteps  | 662808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0288   |\n",
      "|    n_updates        | 165451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=663000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 663000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0352   |\n",
      "|    n_updates        | 165499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.212    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64545    |\n",
      "|    total_timesteps  | 663208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 165551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=663500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.212    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 663500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00868  |\n",
      "|    n_updates        | 165624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.212    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64588    |\n",
      "|    total_timesteps  | 663608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00719  |\n",
      "|    n_updates        | 165651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=664000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.212    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 664000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 165749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.211    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64639    |\n",
      "|    total_timesteps  | 664008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 165751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.211    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64674    |\n",
      "|    total_timesteps  | 664408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00547  |\n",
      "|    n_updates        | 165851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=664500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.211    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 664500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00253  |\n",
      "|    n_updates        | 165874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.211    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64724    |\n",
      "|    total_timesteps  | 664808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 165951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=665000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 665000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00536  |\n",
      "|    n_updates        | 165999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64762    |\n",
      "|    total_timesteps  | 665208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 166051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=665500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 665500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 166124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64814    |\n",
      "|    total_timesteps  | 665608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00784  |\n",
      "|    n_updates        | 166151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=666000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.209    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 666000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 166249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.209    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64858    |\n",
      "|    total_timesteps  | 666008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0632   |\n",
      "|    n_updates        | 166251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.209    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64884    |\n",
      "|    total_timesteps  | 666408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0478   |\n",
      "|    n_updates        | 166351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=666500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.209    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 666500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 166374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64930    |\n",
      "|    total_timesteps  | 666808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 166451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=667000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 667000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 166499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 64975    |\n",
      "|    total_timesteps  | 667208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00421  |\n",
      "|    n_updates        | 166551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=667500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.207    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 667500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00884  |\n",
      "|    n_updates        | 166624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.207    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65022    |\n",
      "|    total_timesteps  | 667608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00865  |\n",
      "|    n_updates        | 166651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=668000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.207    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 668000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00898  |\n",
      "|    n_updates        | 166749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.207    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6712     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65059    |\n",
      "|    total_timesteps  | 668008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 166751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.206    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6716     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65091    |\n",
      "|    total_timesteps  | 668408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00516  |\n",
      "|    n_updates        | 166851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=668500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.206    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 668500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00872  |\n",
      "|    n_updates        | 166874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.206    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6720     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65131    |\n",
      "|    total_timesteps  | 668808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 166951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=669000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.206    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 669000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00397  |\n",
      "|    n_updates        | 166999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.205    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6724     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65176    |\n",
      "|    total_timesteps  | 669208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 167051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=669500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.205    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 669500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00527  |\n",
      "|    n_updates        | 167124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.205    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6728     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65223    |\n",
      "|    total_timesteps  | 669608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 167151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.204    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 670000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 167249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.204    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6732     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65270    |\n",
      "|    total_timesteps  | 670008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.169    |\n",
      "|    n_updates        | 167251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.204    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6736     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65295    |\n",
      "|    total_timesteps  | 670408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 167351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=670500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.204    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 670500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 167374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.203    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6740     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65344    |\n",
      "|    total_timesteps  | 670808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00745  |\n",
      "|    n_updates        | 167451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=671000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.203    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 671000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00682  |\n",
      "|    n_updates        | 167499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.203    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6744     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65393    |\n",
      "|    total_timesteps  | 671208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00434  |\n",
      "|    n_updates        | 167551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=671500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.203    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 671500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00925  |\n",
      "|    n_updates        | 167624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6748     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65430    |\n",
      "|    total_timesteps  | 671608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0408   |\n",
      "|    n_updates        | 167651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=672000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 672000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0579   |\n",
      "|    n_updates        | 167749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6752     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65479    |\n",
      "|    total_timesteps  | 672008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 167751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6756     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65514    |\n",
      "|    total_timesteps  | 672408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 167851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=672500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 672500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00541  |\n",
      "|    n_updates        | 167874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6760     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65552    |\n",
      "|    total_timesteps  | 672808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 167951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=673000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 673000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 167999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6764     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65597    |\n",
      "|    total_timesteps  | 673208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 168051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=673500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.2      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 673500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 168124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.2      |\n",
      "| time/               |          |\n",
      "|    episodes         | 6768     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65641    |\n",
      "|    total_timesteps  | 673608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00766  |\n",
      "|    n_updates        | 168151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=674000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.2      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 674000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00449  |\n",
      "|    n_updates        | 168249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.2      |\n",
      "| time/               |          |\n",
      "|    episodes         | 6772     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65687    |\n",
      "|    total_timesteps  | 674008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00861  |\n",
      "|    n_updates        | 168251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.199    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6776     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65716    |\n",
      "|    total_timesteps  | 674408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0062   |\n",
      "|    n_updates        | 168351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=674500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.199    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 674500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 168374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.199    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6780     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65760    |\n",
      "|    total_timesteps  | 674808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 168451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.198    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 675000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00651  |\n",
      "|    n_updates        | 168499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.9     |\n",
      "|    exploration_rate | 0.198    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6784     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65809    |\n",
      "|    total_timesteps  | 675208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 168551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=675500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.198    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 675500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0073   |\n",
      "|    n_updates        | 168624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.198    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6788     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65854    |\n",
      "|    total_timesteps  | 675608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0546   |\n",
      "|    n_updates        | 168651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=676000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.197    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 676000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 168749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.197    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6792     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65903    |\n",
      "|    total_timesteps  | 676008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 168751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.197    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6796     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65927    |\n",
      "|    total_timesteps  | 676408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 168851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=676500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.197    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 676500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 168874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.196    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6800     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 65975    |\n",
      "|    total_timesteps  | 676808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 168951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=677000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.196    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 677000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 168999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.196    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6804     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66023    |\n",
      "|    total_timesteps  | 677208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00664  |\n",
      "|    n_updates        | 169051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=677500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.195    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 677500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00499  |\n",
      "|    n_updates        | 169124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.195    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6808     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66071    |\n",
      "|    total_timesteps  | 677608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00385  |\n",
      "|    n_updates        | 169151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=678000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.195    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 678000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00466  |\n",
      "|    n_updates        | 169249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.195    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6812     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66109    |\n",
      "|    total_timesteps  | 678008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 169251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6816     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66143    |\n",
      "|    total_timesteps  | 678408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 169351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=678500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 678500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 169374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6820     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66192    |\n",
      "|    total_timesteps  | 678808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 169451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=679000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 679000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 169499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6824     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66240    |\n",
      "|    total_timesteps  | 679208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00617  |\n",
      "|    n_updates        | 169551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=679500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 679500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00356  |\n",
      "|    n_updates        | 169624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6828     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66280    |\n",
      "|    total_timesteps  | 679608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 169651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 680000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 169749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6832     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66326    |\n",
      "|    total_timesteps  | 680008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0515   |\n",
      "|    n_updates        | 169751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6836     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66351    |\n",
      "|    total_timesteps  | 680408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 169851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=680500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 680500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 169874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6840     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66398    |\n",
      "|    total_timesteps  | 680808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 169951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=681000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.191    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 681000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00847  |\n",
      "|    n_updates        | 169999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.02    |\n",
      "|    exploration_rate | 0.191    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6844     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66450    |\n",
      "|    total_timesteps  | 681208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0658   |\n",
      "|    n_updates        | 170051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=681500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.191    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 681500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00642  |\n",
      "|    n_updates        | 170124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.191    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6848     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66498    |\n",
      "|    total_timesteps  | 681608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 170151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=682000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 682000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 170249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6852     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66546    |\n",
      "|    total_timesteps  | 682008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 170251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6856     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66571    |\n",
      "|    total_timesteps  | 682408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.099    |\n",
      "|    n_updates        | 170351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=682500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 682500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00512  |\n",
      "|    n_updates        | 170374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.189    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6860     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66620    |\n",
      "|    total_timesteps  | 682808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 170451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=683000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.189    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 683000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 170499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.189    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6864     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66663    |\n",
      "|    total_timesteps  | 683208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0414   |\n",
      "|    n_updates        | 170551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=683500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.188    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 683500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 170624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.188    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6868     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66704    |\n",
      "|    total_timesteps  | 683608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 170651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=684000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.188    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 684000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 170749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.188    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6872     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66754    |\n",
      "|    total_timesteps  | 684008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000947 |\n",
      "|    n_updates        | 170751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.15    |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6876     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66792    |\n",
      "|    total_timesteps  | 684408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 170851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=684500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 684500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 170874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6880     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66829    |\n",
      "|    total_timesteps  | 684808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 170951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 685000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 170999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.186    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6884     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66878    |\n",
      "|    total_timesteps  | 685208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 171051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=685500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.186    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 685500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 171124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.186    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6888     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66928    |\n",
      "|    total_timesteps  | 685608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0622   |\n",
      "|    n_updates        | 171151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=686000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 686000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00419  |\n",
      "|    n_updates        | 171249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.15    |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6892     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 66976    |\n",
      "|    total_timesteps  | 686008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00804  |\n",
      "|    n_updates        | 171251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.15    |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6896     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67000    |\n",
      "|    total_timesteps  | 686408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 171351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=686500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 686500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 171374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.17    |\n",
      "|    exploration_rate | 0.184    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6900     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67049    |\n",
      "|    total_timesteps  | 686808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 171451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=687000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.184    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 687000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 171499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.2     |\n",
      "|    exploration_rate | 0.184    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6904     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67098    |\n",
      "|    total_timesteps  | 687208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 171551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=687500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.184    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 687500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 171624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.2     |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6908     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67141    |\n",
      "|    total_timesteps  | 687608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00452  |\n",
      "|    n_updates        | 171651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=688000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 688000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 171749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.23    |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6912     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67188    |\n",
      "|    total_timesteps  | 688008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 171751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.25    |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6916     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67212    |\n",
      "|    total_timesteps  | 688408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 171851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=688500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.182    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 688500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 171874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.182    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6920     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67258    |\n",
      "|    total_timesteps  | 688808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 171951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=689000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.182    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 689000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 171999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.182    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6924     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67306    |\n",
      "|    total_timesteps  | 689208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 172051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=689500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 689500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 172124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6928     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67355    |\n",
      "|    total_timesteps  | 689608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 172151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 690000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0346   |\n",
      "|    n_updates        | 172249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6932     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67402    |\n",
      "|    total_timesteps  | 690008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.04     |\n",
      "|    n_updates        | 172251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.18     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6936     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67427    |\n",
      "|    total_timesteps  | 690408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00562  |\n",
      "|    n_updates        | 172351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=690500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.18     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 690500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00903  |\n",
      "|    n_updates        | 172374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.18     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6940     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67474    |\n",
      "|    total_timesteps  | 690808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 172451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=691000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 691000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00418  |\n",
      "|    n_updates        | 172499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.39    |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6944     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67522    |\n",
      "|    total_timesteps  | 691208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00464  |\n",
      "|    n_updates        | 172551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=691500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 691500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 172624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6948     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67569    |\n",
      "|    total_timesteps  | 691608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 172651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=692000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.178    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 692000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 172749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.178    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6952     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67607    |\n",
      "|    total_timesteps  | 692008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 172751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.178    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6956     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67643    |\n",
      "|    total_timesteps  | 692408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 172851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=692500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.178    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 692500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 172874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.37    |\n",
      "|    exploration_rate | 0.177    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6960     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67684    |\n",
      "|    total_timesteps  | 692808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 172951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=693000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.177    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 693000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.055    |\n",
      "|    n_updates        | 172999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.177    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6964     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67729    |\n",
      "|    total_timesteps  | 693208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 173051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=693500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.176    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 693500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 173124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.39    |\n",
      "|    exploration_rate | 0.176    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6968     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67776    |\n",
      "|    total_timesteps  | 693608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 173151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=694000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.176    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 694000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 173249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.41    |\n",
      "|    exploration_rate | 0.176    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6972     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67825    |\n",
      "|    total_timesteps  | 694008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0532   |\n",
      "|    n_updates        | 173251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.175    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6976     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67849    |\n",
      "|    total_timesteps  | 694408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 173351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=694500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.175    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 694500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 173374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.48    |\n",
      "|    exploration_rate | 0.175    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6980     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67900    |\n",
      "|    total_timesteps  | 694808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 173451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.175    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 695000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00331  |\n",
      "|    n_updates        | 173499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.5     |\n",
      "|    exploration_rate | 0.174    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6984     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67947    |\n",
      "|    total_timesteps  | 695208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 173551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=695500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.174    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 695500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00579  |\n",
      "|    n_updates        | 173624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.174    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6988     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 67998    |\n",
      "|    total_timesteps  | 695608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 173651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=696000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.174    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 696000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 173749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.53    |\n",
      "|    exploration_rate | 0.173    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6992     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68038    |\n",
      "|    total_timesteps  | 696008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00253  |\n",
      "|    n_updates        | 173751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.55    |\n",
      "|    exploration_rate | 0.173    |\n",
      "| time/               |          |\n",
      "|    episodes         | 6996     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68069    |\n",
      "|    total_timesteps  | 696408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 173851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=696500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.173    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 696500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 173874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.53    |\n",
      "|    exploration_rate | 0.173    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7000     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68118    |\n",
      "|    total_timesteps  | 696808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 173951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=697000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.172    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 697000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 173999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.172    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7004     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68165    |\n",
      "|    total_timesteps  | 697208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00591  |\n",
      "|    n_updates        | 174051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=697500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.172    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 697500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.096    |\n",
      "|    n_updates        | 174124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.172    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7008     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68208    |\n",
      "|    total_timesteps  | 697608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 174151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=698000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.171    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 698000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 174249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.171    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7012     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68257    |\n",
      "|    total_timesteps  | 698008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 174251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.171    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7016     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68282    |\n",
      "|    total_timesteps  | 698408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 174351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=698500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.171    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 698500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 174374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.55    |\n",
      "|    exploration_rate | 0.17     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7020     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68332    |\n",
      "|    total_timesteps  | 698808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00301  |\n",
      "|    n_updates        | 174451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=699000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.17     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 699000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 174499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.55    |\n",
      "|    exploration_rate | 0.17     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7024     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68376    |\n",
      "|    total_timesteps  | 699208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 174551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=699500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.169    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 699500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000942 |\n",
      "|    n_updates        | 174624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.55    |\n",
      "|    exploration_rate | 0.169    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7028     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68421    |\n",
      "|    total_timesteps  | 699608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 174651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.169    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 700000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00867  |\n",
      "|    n_updates        | 174749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.54    |\n",
      "|    exploration_rate | 0.169    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7032     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68467    |\n",
      "|    total_timesteps  | 700008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00986  |\n",
      "|    n_updates        | 174751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.57    |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7036     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68499    |\n",
      "|    total_timesteps  | 700408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 174851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=700500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 700500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 174874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.56    |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7040     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68550    |\n",
      "|    total_timesteps  | 700808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0079   |\n",
      "|    n_updates        | 174951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=701000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 701000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00526  |\n",
      "|    n_updates        | 174999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.167    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7044     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68606    |\n",
      "|    total_timesteps  | 701208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00515  |\n",
      "|    n_updates        | 175051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=701500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.167    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 701500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0292   |\n",
      "|    n_updates        | 175124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.167    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7048     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68646    |\n",
      "|    total_timesteps  | 701608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 175151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=702000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.166    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 702000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 175249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.52    |\n",
      "|    exploration_rate | 0.166    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7052     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68688    |\n",
      "|    total_timesteps  | 702008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 175251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.166    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7056     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68722    |\n",
      "|    total_timesteps  | 702408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000756 |\n",
      "|    n_updates        | 175351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=702500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.166    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 702500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00466  |\n",
      "|    n_updates        | 175374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.49    |\n",
      "|    exploration_rate | 0.165    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7060     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68768    |\n",
      "|    total_timesteps  | 702808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 175451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=703000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.165    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 703000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0553   |\n",
      "|    n_updates        | 175499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.45    |\n",
      "|    exploration_rate | 0.165    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7064     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68819    |\n",
      "|    total_timesteps  | 703208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 175551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=703500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.165    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 703500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00349  |\n",
      "|    n_updates        | 175624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7068     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68856    |\n",
      "|    total_timesteps  | 703608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00489  |\n",
      "|    n_updates        | 175651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=704000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 704000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 175749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7072     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68907    |\n",
      "|    total_timesteps  | 704008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 175751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7076     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68938    |\n",
      "|    total_timesteps  | 704408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 175851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=704500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.163    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 704500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 175874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.163    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7080     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 68980    |\n",
      "|    total_timesteps  | 704808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 175951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.163    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 705000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0989   |\n",
      "|    n_updates        | 175999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.163    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7084     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69028    |\n",
      "|    total_timesteps  | 705208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 176051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=705500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 705500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0972   |\n",
      "|    n_updates        | 176124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.26    |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7088     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69075    |\n",
      "|    total_timesteps  | 705608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 176151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=706000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 706000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 176249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.24    |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7092     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69113    |\n",
      "|    total_timesteps  | 706008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 176251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.161    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7096     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69146    |\n",
      "|    total_timesteps  | 706408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00823  |\n",
      "|    n_updates        | 176351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=706500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.161    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 706500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 176374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.2     |\n",
      "|    exploration_rate | 0.161    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7100     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69192    |\n",
      "|    total_timesteps  | 706808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 176451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=707000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.16     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 707000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0535   |\n",
      "|    n_updates        | 176499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.2     |\n",
      "|    exploration_rate | 0.16     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7104     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69229    |\n",
      "|    total_timesteps  | 707208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 176551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=707500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.16     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 707500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 176624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.16     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7108     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69274    |\n",
      "|    total_timesteps  | 707608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 176651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=708000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.159    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 708000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000886 |\n",
      "|    n_updates        | 176749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.159    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7112     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69318    |\n",
      "|    total_timesteps  | 708008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 176751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.159    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7116     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69343    |\n",
      "|    total_timesteps  | 708408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 176851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=708500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.159    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 708500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00624  |\n",
      "|    n_updates        | 176874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.158    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7120     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69386    |\n",
      "|    total_timesteps  | 708808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 176951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=709000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.158    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 709000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 176999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.158    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7124     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69423    |\n",
      "|    total_timesteps  | 709208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 177051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=709500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 709500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 177124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7128     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69466    |\n",
      "|    total_timesteps  | 709608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 177151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 710000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 177249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7132     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69510    |\n",
      "|    total_timesteps  | 710008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00454  |\n",
      "|    n_updates        | 177251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.156    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7136     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69534    |\n",
      "|    total_timesteps  | 710408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00937  |\n",
      "|    n_updates        | 177351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=710500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.156    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 710500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 177374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.156    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7140     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69573    |\n",
      "|    total_timesteps  | 710808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 177451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=711000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.156    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 711000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 177499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.155    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7144     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69610    |\n",
      "|    total_timesteps  | 711208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 177551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=711500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.155    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 711500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0885   |\n",
      "|    n_updates        | 177624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.155    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7148     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69649    |\n",
      "|    total_timesteps  | 711608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 177651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=712000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.155    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 712000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00656  |\n",
      "|    n_updates        | 177749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.154    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7152     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69687    |\n",
      "|    total_timesteps  | 712008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00897  |\n",
      "|    n_updates        | 177751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9       |\n",
      "|    exploration_rate | 0.154    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7156     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69712    |\n",
      "|    total_timesteps  | 712408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 177851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=712500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.154    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 712500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 177874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.154    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7160     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69753    |\n",
      "|    total_timesteps  | 712808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 177951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=713000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.153    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 713000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00365  |\n",
      "|    n_updates        | 177999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.153    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7164     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69792    |\n",
      "|    total_timesteps  | 713208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 178051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=713500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.153    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 713500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 178124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.153    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7168     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69831    |\n",
      "|    total_timesteps  | 713608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 178151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=714000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.152    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 714000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0949   |\n",
      "|    n_updates        | 178249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.152    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7172     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69867    |\n",
      "|    total_timesteps  | 714008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00667  |\n",
      "|    n_updates        | 178251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.152    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7176     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69893    |\n",
      "|    total_timesteps  | 714408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0945   |\n",
      "|    n_updates        | 178351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=714500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.152    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 714500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 178374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.151    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7180     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69929    |\n",
      "|    total_timesteps  | 714808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 178451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.151    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 715000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 178499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.11    |\n",
      "|    exploration_rate | 0.151    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7184     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 69968    |\n",
      "|    total_timesteps  | 715208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 178551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=715500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 715500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 178624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7188     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70006    |\n",
      "|    total_timesteps  | 715608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000832 |\n",
      "|    n_updates        | 178651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=716000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 716000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0919   |\n",
      "|    n_updates        | 178749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7192     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70043    |\n",
      "|    total_timesteps  | 716008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00498  |\n",
      "|    n_updates        | 178751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.17    |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7196     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70075    |\n",
      "|    total_timesteps  | 716408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000743 |\n",
      "|    n_updates        | 178851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=716500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 716500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0959   |\n",
      "|    n_updates        | 178874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.17    |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7200     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70112    |\n",
      "|    total_timesteps  | 716808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 178951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=717000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 717000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 178999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.148    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7204     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70154    |\n",
      "|    total_timesteps  | 717208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00067  |\n",
      "|    n_updates        | 179051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=717500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.148    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 717500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0503   |\n",
      "|    n_updates        | 179124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.148    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7208     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70197    |\n",
      "|    total_timesteps  | 717608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 179151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=718000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.147    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 718000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 179249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.25    |\n",
      "|    exploration_rate | 0.147    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7212     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70235    |\n",
      "|    total_timesteps  | 718008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0993   |\n",
      "|    n_updates        | 179251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.147    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7216     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70265    |\n",
      "|    total_timesteps  | 718408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 179351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=718500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.147    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 718500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 179374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.146    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7220     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70308    |\n",
      "|    total_timesteps  | 718808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 179451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=719000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.146    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 719000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 179499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.146    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7224     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70348    |\n",
      "|    total_timesteps  | 719208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00418  |\n",
      "|    n_updates        | 179551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=719500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.146    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 719500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 179624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7228     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70390    |\n",
      "|    total_timesteps  | 719608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00808  |\n",
      "|    n_updates        | 179651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 720000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 179749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.31    |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7232     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70438    |\n",
      "|    total_timesteps  | 720008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0051   |\n",
      "|    n_updates        | 179751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.28    |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7236     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70463    |\n",
      "|    total_timesteps  | 720408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00962  |\n",
      "|    n_updates        | 179851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=720500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.144    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 720500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 179874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.24    |\n",
      "|    exploration_rate | 0.144    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7240     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70506    |\n",
      "|    total_timesteps  | 720808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0039   |\n",
      "|    n_updates        | 179951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=721000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.144    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 721000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 179999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.144    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7244     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70546    |\n",
      "|    total_timesteps  | 721208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 180051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=721500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.143    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 721500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0939   |\n",
      "|    n_updates        | 180124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.15    |\n",
      "|    exploration_rate | 0.143    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7248     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70586    |\n",
      "|    total_timesteps  | 721608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 180151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=722000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.143    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 722000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00506  |\n",
      "|    n_updates        | 180249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.143    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7252     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70629    |\n",
      "|    total_timesteps  | 722008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 180251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.142    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7256     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70656    |\n",
      "|    total_timesteps  | 722408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00874  |\n",
      "|    n_updates        | 180351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=722500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.142    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 722500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 180374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.142    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7260     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70697    |\n",
      "|    total_timesteps  | 722808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0524   |\n",
      "|    n_updates        | 180451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=723000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.141    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 723000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 180499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.141    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7264     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70738    |\n",
      "|    total_timesteps  | 723208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000972 |\n",
      "|    n_updates        | 180551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=723500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.141    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 723500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 180624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.141    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7268     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70778    |\n",
      "|    total_timesteps  | 723608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000806 |\n",
      "|    n_updates        | 180651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=724000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 724000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00433  |\n",
      "|    n_updates        | 180749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7272     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70823    |\n",
      "|    total_timesteps  | 724008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 180751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7276     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70847    |\n",
      "|    total_timesteps  | 724408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0813   |\n",
      "|    n_updates        | 180851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=724500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 724500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 180874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.139    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7280     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70893    |\n",
      "|    total_timesteps  | 724808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0543   |\n",
      "|    n_updates        | 180951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.139    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 725000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0451   |\n",
      "|    n_updates        | 180999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.76    |\n",
      "|    exploration_rate | 0.139    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7284     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70930    |\n",
      "|    total_timesteps  | 725208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 181051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=725500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.138    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 725500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 181124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.138    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7288     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 70977    |\n",
      "|    total_timesteps  | 725608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0797   |\n",
      "|    n_updates        | 181151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=726000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.138    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 726000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 181249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.138    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7292     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71021    |\n",
      "|    total_timesteps  | 726008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 181251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7296     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71046    |\n",
      "|    total_timesteps  | 726408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 181351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=726500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 726500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00282  |\n",
      "|    n_updates        | 181374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7300     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71090    |\n",
      "|    total_timesteps  | 726808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00282  |\n",
      "|    n_updates        | 181451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=727000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 727000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00462  |\n",
      "|    n_updates        | 181499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.54    |\n",
      "|    exploration_rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7304     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71136    |\n",
      "|    total_timesteps  | 727208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 181551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=727500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 727500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 181624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.45    |\n",
      "|    exploration_rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7308     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71184    |\n",
      "|    total_timesteps  | 727608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000864 |\n",
      "|    n_updates        | 181651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=728000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.136    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 728000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 181749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.135    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7312     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71220    |\n",
      "|    total_timesteps  | 728008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00223  |\n",
      "|    n_updates        | 181751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.135    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7316     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71254    |\n",
      "|    total_timesteps  | 728408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 181851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=728500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.135    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 728500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 181874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.135    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7320     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71290    |\n",
      "|    total_timesteps  | 728808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 181951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=729000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.134    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 729000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0948   |\n",
      "|    n_updates        | 181999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.134    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7324     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71334    |\n",
      "|    total_timesteps  | 729208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00428  |\n",
      "|    n_updates        | 182051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=729500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.134    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 729500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 182124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.134    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7328     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71380    |\n",
      "|    total_timesteps  | 729608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0549   |\n",
      "|    n_updates        | 182151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.133    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 730000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 182249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.133    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7332     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71427    |\n",
      "|    total_timesteps  | 730008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0597   |\n",
      "|    n_updates        | 182251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.133    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7336     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71451    |\n",
      "|    total_timesteps  | 730408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00983  |\n",
      "|    n_updates        | 182351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=730500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.133    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 730500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00375  |\n",
      "|    n_updates        | 182374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.132    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7340     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71495    |\n",
      "|    total_timesteps  | 730808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0947   |\n",
      "|    n_updates        | 182451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=731000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.132    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 731000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 182499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.132    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7344     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71536    |\n",
      "|    total_timesteps  | 731208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 182551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=731500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.131    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 731500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00333  |\n",
      "|    n_updates        | 182624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.131    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7348     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71580    |\n",
      "|    total_timesteps  | 731608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0909   |\n",
      "|    n_updates        | 182651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=732000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.131    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 732000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00957  |\n",
      "|    n_updates        | 182749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8       |\n",
      "|    exploration_rate | 0.131    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7352     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71618    |\n",
      "|    total_timesteps  | 732008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 182751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.13     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7356     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71652    |\n",
      "|    total_timesteps  | 732408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000783 |\n",
      "|    n_updates        | 182851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=732500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.13     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 732500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00575  |\n",
      "|    n_updates        | 182874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.13     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7360     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71701    |\n",
      "|    total_timesteps  | 732808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 182951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=733000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.13     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 733000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 182999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.129    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7364     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71738    |\n",
      "|    total_timesteps  | 733208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00327  |\n",
      "|    n_updates        | 183051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=733500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.129    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 733500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00373  |\n",
      "|    n_updates        | 183124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.01    |\n",
      "|    exploration_rate | 0.129    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7368     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71783    |\n",
      "|    total_timesteps  | 733608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00335  |\n",
      "|    n_updates        | 183151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=734000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 734000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 183249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7372     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71831    |\n",
      "|    total_timesteps  | 734008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 183251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7376     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71856    |\n",
      "|    total_timesteps  | 734408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0926   |\n",
      "|    n_updates        | 183351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=734500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 734500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 183374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.01    |\n",
      "|    exploration_rate | 0.127    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7380     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71903    |\n",
      "|    total_timesteps  | 734808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 183451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.127    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 735000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 183499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.97    |\n",
      "|    exploration_rate | 0.127    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7384     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71940    |\n",
      "|    total_timesteps  | 735208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 183551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=735500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.127    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 735500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 183624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7388     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 71982    |\n",
      "|    total_timesteps  | 735608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 183651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=736000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 736000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0008   |\n",
      "|    n_updates        | 183749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.94    |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7392     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72026    |\n",
      "|    total_timesteps  | 736008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00957  |\n",
      "|    n_updates        | 183751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7396     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72059    |\n",
      "|    total_timesteps  | 736408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.136    |\n",
      "|    n_updates        | 183851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=736500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.125    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 736500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 183874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.97    |\n",
      "|    exploration_rate | 0.125    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7400     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72099    |\n",
      "|    total_timesteps  | 736808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 183951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=737000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.125    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 737000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 183999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.125    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7404     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72144    |\n",
      "|    total_timesteps  | 737208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0981   |\n",
      "|    n_updates        | 184051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=737500, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 737500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00414  |\n",
      "|    n_updates        | 184124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.94    |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7408     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72192    |\n",
      "|    total_timesteps  | 737608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 184151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=738000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 738000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000489 |\n",
      "|    n_updates        | 184249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7412     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72238    |\n",
      "|    total_timesteps  | 738008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 184251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.123    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7416     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72263    |\n",
      "|    total_timesteps  | 738408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 184351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=738500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.123    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 738500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00724  |\n",
      "|    n_updates        | 184374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.123    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7420     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72309    |\n",
      "|    total_timesteps  | 738808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 184451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=739000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.122    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 739000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0958   |\n",
      "|    n_updates        | 184499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.122    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7424     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72358    |\n",
      "|    total_timesteps  | 739208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 184551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=739500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.122    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 739500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 184624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.122    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7428     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72396    |\n",
      "|    total_timesteps  | 739608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 184651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 740000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0929   |\n",
      "|    n_updates        | 184749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7432     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72445    |\n",
      "|    total_timesteps  | 740008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 184751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7436     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72480    |\n",
      "|    total_timesteps  | 740408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00625  |\n",
      "|    n_updates        | 184851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=740500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 740500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 184874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.12     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7440     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72517    |\n",
      "|    total_timesteps  | 740808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0934   |\n",
      "|    n_updates        | 184951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=741000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.12     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 741000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00604  |\n",
      "|    n_updates        | 184999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.12     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7444     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72565    |\n",
      "|    total_timesteps  | 741208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00386  |\n",
      "|    n_updates        | 185051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=741500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.119    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 741500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 185124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.119    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7448     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72612    |\n",
      "|    total_timesteps  | 741608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 185151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=742000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.119    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 742000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 185249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.119    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7452     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72655    |\n",
      "|    total_timesteps  | 742008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0813   |\n",
      "|    n_updates        | 185251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72681    |\n",
      "|    total_timesteps  | 742408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 185351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=742500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 742500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 185374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72728    |\n",
      "|    total_timesteps  | 742808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 185451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=743000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 743000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000917 |\n",
      "|    n_updates        | 185499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.117    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7464     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72766    |\n",
      "|    total_timesteps  | 743208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 185551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=743500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.117    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 743500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00596  |\n",
      "|    n_updates        | 185624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.117    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7468     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72812    |\n",
      "|    total_timesteps  | 743608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 185651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=744000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.117    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 744000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0046   |\n",
      "|    n_updates        | 185749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.116    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7472     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72859    |\n",
      "|    total_timesteps  | 744008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 185751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.116    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72883    |\n",
      "|    total_timesteps  | 744408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 185851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=744500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.116    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 744500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000955 |\n",
      "|    n_updates        | 185874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.116    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72932    |\n",
      "|    total_timesteps  | 744808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00677  |\n",
      "|    n_updates        | 185951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.115    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 745000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 185999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.115    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7484     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 72978    |\n",
      "|    total_timesteps  | 745208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0843   |\n",
      "|    n_updates        | 186051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=745500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.115    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 745500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 186124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.115    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73021    |\n",
      "|    total_timesteps  | 745608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 186151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=746000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.114    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 746000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 186249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.114    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73060    |\n",
      "|    total_timesteps  | 746008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.201    |\n",
      "|    n_updates        | 186251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.114    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73093    |\n",
      "|    total_timesteps  | 746408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 186351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=746500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.114    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 746500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 186374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.113    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73142    |\n",
      "|    total_timesteps  | 746808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 186451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=747000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.113    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 747000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 186499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.113    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73179    |\n",
      "|    total_timesteps  | 747208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 186551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=747500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.112    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 747500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000949 |\n",
      "|    n_updates        | 186624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.112    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7508     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73223    |\n",
      "|    total_timesteps  | 747608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00525  |\n",
      "|    n_updates        | 186651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=748000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.112    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 748000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 186749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.112    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73270    |\n",
      "|    total_timesteps  | 748008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 186751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.111    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73297    |\n",
      "|    total_timesteps  | 748408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 186851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=748500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.111    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 748500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 186874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.111    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73342    |\n",
      "|    total_timesteps  | 748808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 186951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=749000, episode_reward=-7.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -7       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.111    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 749000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00958  |\n",
      "|    n_updates        | 186999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.01    |\n",
      "|    exploration_rate | 0.11     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73387    |\n",
      "|    total_timesteps  | 749208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 187051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=749500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.11     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 749500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 187124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.01    |\n",
      "|    exploration_rate | 0.11     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73432    |\n",
      "|    total_timesteps  | 749608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0871   |\n",
      "|    n_updates        | 187151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.109    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 750000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00556  |\n",
      "|    n_updates        | 187249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.109    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73476    |\n",
      "|    total_timesteps  | 750008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0543   |\n",
      "|    n_updates        | 187251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.109    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73502    |\n",
      "|    total_timesteps  | 750408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 187351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=750500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.109    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 750500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00986  |\n",
      "|    n_updates        | 187374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.108    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73547    |\n",
      "|    total_timesteps  | 750808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 187451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=751000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.108    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 751000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00495  |\n",
      "|    n_updates        | 187499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.108    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73593    |\n",
      "|    total_timesteps  | 751208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0301   |\n",
      "|    n_updates        | 187551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=751500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.108    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 751500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 187624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.94    |\n",
      "|    exploration_rate | 0.107    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73645    |\n",
      "|    total_timesteps  | 751608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 187651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=752000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.107    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 752000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 187749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.107    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73683    |\n",
      "|    total_timesteps  | 752008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.005    |\n",
      "|    n_updates        | 187751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.93    |\n",
      "|    exploration_rate | 0.107    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73718    |\n",
      "|    total_timesteps  | 752408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 187851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=752500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.106    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 752500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 187874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.91    |\n",
      "|    exploration_rate | 0.106    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73755    |\n",
      "|    total_timesteps  | 752808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00559  |\n",
      "|    n_updates        | 187951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=753000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.106    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 753000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00953  |\n",
      "|    n_updates        | 187999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.92    |\n",
      "|    exploration_rate | 0.106    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73798    |\n",
      "|    total_timesteps  | 753208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 188051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=753500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.105    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 753500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 188124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.97    |\n",
      "|    exploration_rate | 0.105    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73842    |\n",
      "|    total_timesteps  | 753608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00776  |\n",
      "|    n_updates        | 188151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=754000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.105    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 754000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0849   |\n",
      "|    n_updates        | 188249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.105    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73888    |\n",
      "|    total_timesteps  | 754008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 188251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.104    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73912    |\n",
      "|    total_timesteps  | 754408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00695  |\n",
      "|    n_updates        | 188351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=754500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.104    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 754500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 188374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.104    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 73956    |\n",
      "|    total_timesteps  | 754808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 188451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 755000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 188499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74001    |\n",
      "|    total_timesteps  | 755208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 188551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=755500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 755500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 188624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74046    |\n",
      "|    total_timesteps  | 755608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 188651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=756000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.102    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 756000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 188749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.102    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74086    |\n",
      "|    total_timesteps  | 756008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 188751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.102    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74118    |\n",
      "|    total_timesteps  | 756408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 188851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=756500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.102    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 756500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00607  |\n",
      "|    n_updates        | 188874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.101    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74163    |\n",
      "|    total_timesteps  | 756808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 188951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=757000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.101    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 757000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 188999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.101    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74201    |\n",
      "|    total_timesteps  | 757208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 189051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=757500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 757500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00331  |\n",
      "|    n_updates        | 189124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 7608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74249    |\n",
      "|    total_timesteps  | 757608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00189  |\n",
      "|    n_updates        | 189151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=758000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0999   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 758000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0804   |\n",
      "|    n_updates        | 189249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0999   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74301    |\n",
      "|    total_timesteps  | 758008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 189251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.0994   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74327    |\n",
      "|    total_timesteps  | 758408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00336  |\n",
      "|    n_updates        | 189351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=758500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0993   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 758500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 189374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.0989   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74370    |\n",
      "|    total_timesteps  | 758808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 189451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=759000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0987   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 759000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 189499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.0984   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74419    |\n",
      "|    total_timesteps  | 759208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0795   |\n",
      "|    n_updates        | 189551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=759500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0981   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 759500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.32     |\n",
      "|    n_updates        | 189624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.098    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74456    |\n",
      "|    total_timesteps  | 759608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 189651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0975   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 760000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 189749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.0975   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74505    |\n",
      "|    total_timesteps  | 760008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0517   |\n",
      "|    n_updates        | 189751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.097    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74538    |\n",
      "|    total_timesteps  | 760408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.233    |\n",
      "|    n_updates        | 189851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=760500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0969   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 760500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 189874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.0965   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74584    |\n",
      "|    total_timesteps  | 760808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00485  |\n",
      "|    n_updates        | 189951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=761000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0963   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 761000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.145    |\n",
      "|    n_updates        | 189999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74624    |\n",
      "|    total_timesteps  | 761208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00829  |\n",
      "|    n_updates        | 190051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=761500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0957   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 761500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 190124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.0956   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74671    |\n",
      "|    total_timesteps  | 761608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 190151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=762000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0951   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 762000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 190249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.0951   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74716    |\n",
      "|    total_timesteps  | 762008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00903  |\n",
      "|    n_updates        | 190251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.0946   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74742    |\n",
      "|    total_timesteps  | 762408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00322  |\n",
      "|    n_updates        | 190351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=762500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0945   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 762500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 190374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.0942   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74788    |\n",
      "|    total_timesteps  | 762808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 190451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=763000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0939   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 763000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0799   |\n",
      "|    n_updates        | 190499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.0937   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74833    |\n",
      "|    total_timesteps  | 763208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 190551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=763500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0933   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 763500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 190624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.0932   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74879    |\n",
      "|    total_timesteps  | 763608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 190651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=764000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0928   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 764000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 190749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0927   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74916    |\n",
      "|    total_timesteps  | 764008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 190751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0923   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74950    |\n",
      "|    total_timesteps  | 764408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00639  |\n",
      "|    n_updates        | 190851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=764500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0922   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 764500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 190874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0918   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 74999    |\n",
      "|    total_timesteps  | 764808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 190951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0916   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 765000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00307  |\n",
      "|    n_updates        | 190999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.0913   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75037    |\n",
      "|    total_timesteps  | 765208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00607  |\n",
      "|    n_updates        | 191051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=765500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.091    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 765500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 191124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.0908   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75085    |\n",
      "|    total_timesteps  | 765608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00413  |\n",
      "|    n_updates        | 191151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=766000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0904   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 766000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 191249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.06    |\n",
      "|    exploration_rate | 0.0904   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75131    |\n",
      "|    total_timesteps  | 766008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 191251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.0899   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75159    |\n",
      "|    total_timesteps  | 766408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00604  |\n",
      "|    n_updates        | 191351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=766500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0898   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 766500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 191374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.0894   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75203    |\n",
      "|    total_timesteps  | 766808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 191451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=767000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0892   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 767000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 191499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.0889   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75251    |\n",
      "|    total_timesteps  | 767208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 191551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=767500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0886   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 767500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00369  |\n",
      "|    n_updates        | 191624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.94    |\n",
      "|    exploration_rate | 0.0885   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75298    |\n",
      "|    total_timesteps  | 767608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0983   |\n",
      "|    n_updates        | 191651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=768000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.088    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 768000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 191749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.088    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7712     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75336    |\n",
      "|    total_timesteps  | 768008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 191751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.98    |\n",
      "|    exploration_rate | 0.0875   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7716     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75372    |\n",
      "|    total_timesteps  | 768408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 191851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=768500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0874   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 768500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.253    |\n",
      "|    n_updates        | 191874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.087    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7720     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75422    |\n",
      "|    total_timesteps  | 768808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000385 |\n",
      "|    n_updates        | 191951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=769000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0868   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 769000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000868 |\n",
      "|    n_updates        | 191999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.0866   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7724     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75460    |\n",
      "|    total_timesteps  | 769208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 192051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=769500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0862   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 769500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 192124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.0861   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7728     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75504    |\n",
      "|    total_timesteps  | 769608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 192151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 770000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 192249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.95    |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7732     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75552    |\n",
      "|    total_timesteps  | 770008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 192251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.0851   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7736     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75588    |\n",
      "|    total_timesteps  | 770408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00681  |\n",
      "|    n_updates        | 192351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=770500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.085    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 770500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 192374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.0847   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7740     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75633    |\n",
      "|    total_timesteps  | 770808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 192451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=771000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0844   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 771000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00856  |\n",
      "|    n_updates        | 192499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -7.99    |\n",
      "|    exploration_rate | 0.0842   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7744     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75671    |\n",
      "|    total_timesteps  | 771208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 192551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=771500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0838   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 771500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00365  |\n",
      "|    n_updates        | 192624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.0837   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7748     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75716    |\n",
      "|    total_timesteps  | 771608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0273   |\n",
      "|    n_updates        | 192651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=772000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0833   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 772000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 192749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.0832   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7752     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75762    |\n",
      "|    total_timesteps  | 772008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0816   |\n",
      "|    n_updates        | 192751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.02    |\n",
      "|    exploration_rate | 0.0828   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7756     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75793    |\n",
      "|    total_timesteps  | 772408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 192851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=772500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0827   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 772500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00459  |\n",
      "|    n_updates        | 192874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.0823   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7760     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75833    |\n",
      "|    total_timesteps  | 772808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 192951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=773000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0821   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 773000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0824   |\n",
      "|    n_updates        | 192999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.0818   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7764     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75880    |\n",
      "|    total_timesteps  | 773208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 193051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=773500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0815   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 773500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 193124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.0813   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7768     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75925    |\n",
      "|    total_timesteps  | 773608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 193151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=774000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0809   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 774000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 193249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.0809   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7772     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75972    |\n",
      "|    total_timesteps  | 774008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.323    |\n",
      "|    n_updates        | 193251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.0804   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7776     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 75997    |\n",
      "|    total_timesteps  | 774408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 193351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=774500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0803   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 774500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 193374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.0799   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7780     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76041    |\n",
      "|    total_timesteps  | 774808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00081  |\n",
      "|    n_updates        | 193451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0797   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 775000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 193499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.0794   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7784     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76086    |\n",
      "|    total_timesteps  | 775208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 193551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=775500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0791   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 775500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 193624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.079    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7788     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76134    |\n",
      "|    total_timesteps  | 775608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 193651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=776000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0785   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 776000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 193749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.0785   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7792     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76181    |\n",
      "|    total_timesteps  | 776008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 193751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.078    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7796     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76206    |\n",
      "|    total_timesteps  | 776408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000739 |\n",
      "|    n_updates        | 193851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=776500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0779   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 776500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 193874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.0775   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7800     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76255    |\n",
      "|    total_timesteps  | 776808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 193951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=777000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0773   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 777000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00445  |\n",
      "|    n_updates        | 193999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.0771   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7804     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76301    |\n",
      "|    total_timesteps  | 777208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 194051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=777500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0767   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 777500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00284  |\n",
      "|    n_updates        | 194124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.0766   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7808     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76343    |\n",
      "|    total_timesteps  | 777608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 194151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=778000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0761   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 778000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 194249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.0761   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7812     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76385    |\n",
      "|    total_timesteps  | 778008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 194251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.0756   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7816     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76417    |\n",
      "|    total_timesteps  | 778408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 194351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=778500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0755   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 778500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 194374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0752   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7820     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76466    |\n",
      "|    total_timesteps  | 778808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00097  |\n",
      "|    n_updates        | 194451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=779000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0749   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 779000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 194499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0747   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7824     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76521    |\n",
      "|    total_timesteps  | 779208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 194551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=779500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0743   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 779500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 194624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0742   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7828     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76573    |\n",
      "|    total_timesteps  | 779608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.341    |\n",
      "|    n_updates        | 194651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0738   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 780000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 194749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.0737   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7832     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76617    |\n",
      "|    total_timesteps  | 780008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0654   |\n",
      "|    n_updates        | 194751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0733   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7836     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76643    |\n",
      "|    total_timesteps  | 780408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 194851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=780500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0732   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 780500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00793  |\n",
      "|    n_updates        | 194874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0728   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7840     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76684    |\n",
      "|    total_timesteps  | 780808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 194951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=781000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0726   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 781000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 194999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0723   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7844     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76732    |\n",
      "|    total_timesteps  | 781208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 195051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=781500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.072    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 781500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0029   |\n",
      "|    n_updates        | 195124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0718   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7848     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76779    |\n",
      "|    total_timesteps  | 781608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 195151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=782000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0714   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 782000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 195249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0714   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7852     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76823    |\n",
      "|    total_timesteps  | 782008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0803   |\n",
      "|    n_updates        | 195251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0709   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7856     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76854    |\n",
      "|    total_timesteps  | 782408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 195351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=782500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0708   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 782500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00513  |\n",
      "|    n_updates        | 195374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.0704   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7860     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76894    |\n",
      "|    total_timesteps  | 782808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 195451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=783000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0702   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 783000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 195499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0699   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7864     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76946    |\n",
      "|    total_timesteps  | 783208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 195551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=783500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0696   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 783500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 195624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0695   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7868     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 76990    |\n",
      "|    total_timesteps  | 783608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 195651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=784000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.069    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 784000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 195749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.069    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7872     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77035    |\n",
      "|    total_timesteps  | 784008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 195751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0685   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7876     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77061    |\n",
      "|    total_timesteps  | 784408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00359  |\n",
      "|    n_updates        | 195851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=784500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0684   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 784500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 195874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.068    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7880     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77108    |\n",
      "|    total_timesteps  | 784808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 195951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0678   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 785000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 195999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0676   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7884     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77150    |\n",
      "|    total_timesteps  | 785208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00448  |\n",
      "|    n_updates        | 196051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=785500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0672   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 785500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 196124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0671   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7888     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77191    |\n",
      "|    total_timesteps  | 785608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 196151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=786000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0666   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 786000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0736   |\n",
      "|    n_updates        | 196249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0666   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7892     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77238    |\n",
      "|    total_timesteps  | 786008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00452  |\n",
      "|    n_updates        | 196251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0661   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7896     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77273    |\n",
      "|    total_timesteps  | 786408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.548    |\n",
      "|    n_updates        | 196351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=786500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.066    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 786500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 196374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0657   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7900     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77311    |\n",
      "|    total_timesteps  | 786808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.289    |\n",
      "|    n_updates        | 196451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=787000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0654   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 787000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.075    |\n",
      "|    n_updates        | 196499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.0652   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7904     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77355    |\n",
      "|    total_timesteps  | 787208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 196551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=787500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0648   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 787500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 196624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0647   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7908     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77398    |\n",
      "|    total_timesteps  | 787608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 196651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=788000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0643   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 788000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 196749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.0642   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7912     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77444    |\n",
      "|    total_timesteps  | 788008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 196751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.0638   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7916     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77479    |\n",
      "|    total_timesteps  | 788408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 196851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=788500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0637   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 788500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00406  |\n",
      "|    n_updates        | 196874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.05    |\n",
      "|    exploration_rate | 0.0633   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7920     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77523    |\n",
      "|    total_timesteps  | 788808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 196951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=789000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0631   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 789000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 196999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.0628   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7924     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77562    |\n",
      "|    total_timesteps  | 789208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 197051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=789500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0625   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 789500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 197124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.03    |\n",
      "|    exploration_rate | 0.0623   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7928     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77612    |\n",
      "|    total_timesteps  | 789608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 197151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0619   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 790000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 197249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.01    |\n",
      "|    exploration_rate | 0.0619   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7932     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77662    |\n",
      "|    total_timesteps  | 790008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0525   |\n",
      "|    n_updates        | 197251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.04    |\n",
      "|    exploration_rate | 0.0614   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7936     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77687    |\n",
      "|    total_timesteps  | 790408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.306    |\n",
      "|    n_updates        | 197351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=790500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0613   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 790500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00587  |\n",
      "|    n_updates        | 197374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.0609   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7940     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77737    |\n",
      "|    total_timesteps  | 790808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 197451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=791000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0607   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 791000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 197499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.0604   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7944     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77783    |\n",
      "|    total_timesteps  | 791208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 197551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=791500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0601   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 791500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 197624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.06     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7948     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77826    |\n",
      "|    total_timesteps  | 791608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 197651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=792000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0595   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 792000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 197749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.0595   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7952     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77872    |\n",
      "|    total_timesteps  | 792008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00837  |\n",
      "|    n_updates        | 197751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.059    |\n",
      "| time/               |          |\n",
      "|    episodes         | 7956     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77897    |\n",
      "|    total_timesteps  | 792408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 197851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=792500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0589   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 792500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0723   |\n",
      "|    n_updates        | 197874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.0585   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7960     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77943    |\n",
      "|    total_timesteps  | 792808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 197951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=793000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0583   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 793000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 197999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.0581   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7964     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 77993    |\n",
      "|    total_timesteps  | 793208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 198051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=793500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0577   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 793500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 198124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0576   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7968     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78041    |\n",
      "|    total_timesteps  | 793608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 198151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=794000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0571   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 794000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 198249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0571   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7972     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78089    |\n",
      "|    total_timesteps  | 794008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 198251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0566   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7976     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78114    |\n",
      "|    total_timesteps  | 794408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000959 |\n",
      "|    n_updates        | 198351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=794500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0565   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 794500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 198374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0562   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7980     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78160    |\n",
      "|    total_timesteps  | 794808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0935   |\n",
      "|    n_updates        | 198451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=795000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0559   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 795000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0736   |\n",
      "|    n_updates        | 198499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.0557   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7984     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78205    |\n",
      "|    total_timesteps  | 795208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 198551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=795500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0553   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 795500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 198624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0552   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7988     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78249    |\n",
      "|    total_timesteps  | 795608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.14     |\n",
      "|    n_updates        | 198651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=796000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0548   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 796000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00227  |\n",
      "|    n_updates        | 198749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0547   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7992     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78299    |\n",
      "|    total_timesteps  | 796008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 198751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.0543   |\n",
      "| time/               |          |\n",
      "|    episodes         | 7996     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78324    |\n",
      "|    total_timesteps  | 796408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 198851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=796500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0542   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 796500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 198874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.0538   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8000     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78373    |\n",
      "|    total_timesteps  | 796808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 198951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=797000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0536   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 797000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0046   |\n",
      "|    n_updates        | 198999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.0533   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8004     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78421    |\n",
      "|    total_timesteps  | 797208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 199051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=797500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.053    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 797500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 199124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.0528   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8008     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78468    |\n",
      "|    total_timesteps  | 797608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 199151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=798000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0524   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 798000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 199249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.0524   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8012     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78511    |\n",
      "|    total_timesteps  | 798008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 199251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.0519   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8016     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78538    |\n",
      "|    total_timesteps  | 798408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 199351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=798500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0518   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 798500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 199374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.0514   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8020     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78583    |\n",
      "|    total_timesteps  | 798808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 199451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=799000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0512   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 799000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.306    |\n",
      "|    n_updates        | 199499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.0509   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8024     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78625    |\n",
      "|    total_timesteps  | 799208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.553    |\n",
      "|    n_updates        | 199551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=799500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0506   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 799500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 199624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.0505   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8028     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78672    |\n",
      "|    total_timesteps  | 799608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 199651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 800000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 199749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.19    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8032     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78723    |\n",
      "|    total_timesteps  | 800008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0976   |\n",
      "|    n_updates        | 199751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8036     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78747    |\n",
      "|    total_timesteps  | 800408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00724  |\n",
      "|    n_updates        | 199851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=800500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 800500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00391  |\n",
      "|    n_updates        | 199874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8040     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78794    |\n",
      "|    total_timesteps  | 800808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0751   |\n",
      "|    n_updates        | 199951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=801000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 801000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0071   |\n",
      "|    n_updates        | 199999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.07    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8044     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78842    |\n",
      "|    total_timesteps  | 801208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 200051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=801500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 801500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 200124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.08    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8048     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78888    |\n",
      "|    total_timesteps  | 801608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 200151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=802000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 802000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 200249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8052     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78926    |\n",
      "|    total_timesteps  | 802008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 200251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8056     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 78963    |\n",
      "|    total_timesteps  | 802408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0677   |\n",
      "|    n_updates        | 200351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=802500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 802500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 200374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8060     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79010    |\n",
      "|    total_timesteps  | 802808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 200451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=803000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 803000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 200499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8064     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79047    |\n",
      "|    total_timesteps  | 803208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 200551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=803500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 803500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 200624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8068     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79093    |\n",
      "|    total_timesteps  | 803608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0694   |\n",
      "|    n_updates        | 200651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=804000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 804000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 200749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8072     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79136    |\n",
      "|    total_timesteps  | 804008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 200751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8076     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79171    |\n",
      "|    total_timesteps  | 804408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.187    |\n",
      "|    n_updates        | 200851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=804500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 804500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 200874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8080     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79216    |\n",
      "|    total_timesteps  | 804808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00487  |\n",
      "|    n_updates        | 200951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=805000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 805000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0651   |\n",
      "|    n_updates        | 200999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8084     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79262    |\n",
      "|    total_timesteps  | 805208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 201051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=805500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 805500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 201124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8088     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79307    |\n",
      "|    total_timesteps  | 805608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 201151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=806000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 806000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000708 |\n",
      "|    n_updates        | 201249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8092     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79353    |\n",
      "|    total_timesteps  | 806008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0612   |\n",
      "|    n_updates        | 201251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8096     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79382    |\n",
      "|    total_timesteps  | 806408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00255  |\n",
      "|    n_updates        | 201351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=806500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 806500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00579  |\n",
      "|    n_updates        | 201374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8100     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79427    |\n",
      "|    total_timesteps  | 806808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 201451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=807000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 807000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 201499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.41    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8104     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79469    |\n",
      "|    total_timesteps  | 807208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000812 |\n",
      "|    n_updates        | 201551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=807500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 807500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 201624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.45    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8108     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79516    |\n",
      "|    total_timesteps  | 807608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0634   |\n",
      "|    n_updates        | 201651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=808000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 808000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00863  |\n",
      "|    n_updates        | 201749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.45    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8112     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79562    |\n",
      "|    total_timesteps  | 808008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 201751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.48    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8116     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79587    |\n",
      "|    total_timesteps  | 808408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 201851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=808500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 808500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 201874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.53    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8120     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79633    |\n",
      "|    total_timesteps  | 808808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 201951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=809000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 809000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 201999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.56    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8124     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79677    |\n",
      "|    total_timesteps  | 809208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 202051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=809500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 809500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 202124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8128     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79723    |\n",
      "|    total_timesteps  | 809608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 202151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 810000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 202249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8132     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79763    |\n",
      "|    total_timesteps  | 810008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0732   |\n",
      "|    n_updates        | 202251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8136     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79795    |\n",
      "|    total_timesteps  | 810408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 202351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=810500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 810500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00763  |\n",
      "|    n_updates        | 202374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8140     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79840    |\n",
      "|    total_timesteps  | 810808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 202451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=811000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 811000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00284  |\n",
      "|    n_updates        | 202499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8144     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79883    |\n",
      "|    total_timesteps  | 811208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 202551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=811500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 811500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00619  |\n",
      "|    n_updates        | 202624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8148     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79923    |\n",
      "|    total_timesteps  | 811608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00564  |\n",
      "|    n_updates        | 202651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=812000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 812000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 202749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8152     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79967    |\n",
      "|    total_timesteps  | 812008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 202751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8156     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 79992    |\n",
      "|    total_timesteps  | 812408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 202851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=812500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 812500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 202874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8160     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80040    |\n",
      "|    total_timesteps  | 812808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 202951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=813000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 813000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 202999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8164     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80090    |\n",
      "|    total_timesteps  | 813208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00427  |\n",
      "|    n_updates        | 203051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=813500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 813500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 203124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8168     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80136    |\n",
      "|    total_timesteps  | 813608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 203151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=814000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 814000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 203249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.84    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8172     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80173    |\n",
      "|    total_timesteps  | 814008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 203251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8176     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80210    |\n",
      "|    total_timesteps  | 814408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.579    |\n",
      "|    n_updates        | 203351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=814500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 814500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.414    |\n",
      "|    n_updates        | 203374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8180     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80248    |\n",
      "|    total_timesteps  | 814808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 203451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=815000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 815000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 203499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8184     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80293    |\n",
      "|    total_timesteps  | 815208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 203551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=815500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 815500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 203624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8188     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80336    |\n",
      "|    total_timesteps  | 815608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000621 |\n",
      "|    n_updates        | 203651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=816000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 816000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0936   |\n",
      "|    n_updates        | 203749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8192     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80383    |\n",
      "|    total_timesteps  | 816008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 203751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8196     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80408    |\n",
      "|    total_timesteps  | 816408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 203851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=816500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 816500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.299    |\n",
      "|    n_updates        | 203874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8200     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80456    |\n",
      "|    total_timesteps  | 816808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 203951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=817000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 817000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 203999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8204     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80502    |\n",
      "|    total_timesteps  | 817208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000491 |\n",
      "|    n_updates        | 204051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=817500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 817500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.288    |\n",
      "|    n_updates        | 204124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8208     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80547    |\n",
      "|    total_timesteps  | 817608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 204151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=818000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 818000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 204249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8212     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80592    |\n",
      "|    total_timesteps  | 818008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 204251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8216     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80617    |\n",
      "|    total_timesteps  | 818408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 204351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=818500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 818500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000716 |\n",
      "|    n_updates        | 204374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8220     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80669    |\n",
      "|    total_timesteps  | 818808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 204451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=819000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 819000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 204499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8224     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80715    |\n",
      "|    total_timesteps  | 819208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 204551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=819500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 819500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 204624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8228     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80762    |\n",
      "|    total_timesteps  | 819608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 204651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 820000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 204749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8232     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80800    |\n",
      "|    total_timesteps  | 820008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0738   |\n",
      "|    n_updates        | 204751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8236     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80833    |\n",
      "|    total_timesteps  | 820408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 204851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=820500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 820500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 204874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8240     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80879    |\n",
      "|    total_timesteps  | 820808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 204951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=821000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 821000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 204999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8244     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80926    |\n",
      "|    total_timesteps  | 821208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 205051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=821500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 821500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00598  |\n",
      "|    n_updates        | 205124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8248     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 80971    |\n",
      "|    total_timesteps  | 821608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.489    |\n",
      "|    n_updates        | 205151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=822000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 822000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.227    |\n",
      "|    n_updates        | 205249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8252     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81021    |\n",
      "|    total_timesteps  | 822008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 205251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8256     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81047    |\n",
      "|    total_timesteps  | 822408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000733 |\n",
      "|    n_updates        | 205351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=822500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 822500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 205374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8260     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81093    |\n",
      "|    total_timesteps  | 822808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.313    |\n",
      "|    n_updates        | 205451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=823000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 823000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.633    |\n",
      "|    n_updates        | 205499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8264     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81136    |\n",
      "|    total_timesteps  | 823208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 205551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=823500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 823500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00724  |\n",
      "|    n_updates        | 205624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8268     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81185    |\n",
      "|    total_timesteps  | 823608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00375  |\n",
      "|    n_updates        | 205651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=824000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 824000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000921 |\n",
      "|    n_updates        | 205749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8272     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81223    |\n",
      "|    total_timesteps  | 824008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 205751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8276     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81258    |\n",
      "|    total_timesteps  | 824408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 205851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=824500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 824500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.232    |\n",
      "|    n_updates        | 205874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8280     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81306    |\n",
      "|    total_timesteps  | 824808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 205951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=825000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 825000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00506  |\n",
      "|    n_updates        | 205999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8284     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81343    |\n",
      "|    total_timesteps  | 825208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 206051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=825500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 825500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 206124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8288     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81390    |\n",
      "|    total_timesteps  | 825608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.307    |\n",
      "|    n_updates        | 206151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=826000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 826000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.315    |\n",
      "|    n_updates        | 206249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8292     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81439    |\n",
      "|    total_timesteps  | 826008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 206251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8296     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81463    |\n",
      "|    total_timesteps  | 826408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0631   |\n",
      "|    n_updates        | 206351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=826500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 826500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.311    |\n",
      "|    n_updates        | 206374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8300     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81508    |\n",
      "|    total_timesteps  | 826808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00367  |\n",
      "|    n_updates        | 206451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=827000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 827000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00943  |\n",
      "|    n_updates        | 206499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8304     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81558    |\n",
      "|    total_timesteps  | 827208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 206551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=827500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 827500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 206624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8308     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81606    |\n",
      "|    total_timesteps  | 827608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 206651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=828000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 828000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 206749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8312     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81652    |\n",
      "|    total_timesteps  | 828008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 206751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8316     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81677    |\n",
      "|    total_timesteps  | 828408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 206851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=828500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 828500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 206874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8320     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81724    |\n",
      "|    total_timesteps  | 828808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 206951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=829000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 829000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 206999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8324     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81770    |\n",
      "|    total_timesteps  | 829208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 207051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=829500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 829500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0928   |\n",
      "|    n_updates        | 207124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8328     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81820    |\n",
      "|    total_timesteps  | 829608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.259    |\n",
      "|    n_updates        | 207151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 830000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 207249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8332     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81858    |\n",
      "|    total_timesteps  | 830008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0752   |\n",
      "|    n_updates        | 207251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8336     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81895    |\n",
      "|    total_timesteps  | 830408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00635  |\n",
      "|    n_updates        | 207351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=830500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 830500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 207374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8340     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81943    |\n",
      "|    total_timesteps  | 830808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 207451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=831000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 831000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 207499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8344     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 81984    |\n",
      "|    total_timesteps  | 831208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 207551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=831500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 831500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 207624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8348     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82032    |\n",
      "|    total_timesteps  | 831608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 207651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=832000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 832000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 207749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8352     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82075    |\n",
      "|    total_timesteps  | 832008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 207751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8356     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82101    |\n",
      "|    total_timesteps  | 832408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.31     |\n",
      "|    n_updates        | 207851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=832500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 832500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 207874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8360     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82145    |\n",
      "|    total_timesteps  | 832808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 207951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=833000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 833000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 207999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8364     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82192    |\n",
      "|    total_timesteps  | 833208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 208051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=833500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 833500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 208124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8368     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82240    |\n",
      "|    total_timesteps  | 833608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00389  |\n",
      "|    n_updates        | 208151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=834000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 834000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00496  |\n",
      "|    n_updates        | 208249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8372     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82286    |\n",
      "|    total_timesteps  | 834008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 208251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8376     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82311    |\n",
      "|    total_timesteps  | 834408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 208351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=834500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 834500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 208374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8380     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82355    |\n",
      "|    total_timesteps  | 834808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 208451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=835000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 835000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.199    |\n",
      "|    n_updates        | 208499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8384     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82403    |\n",
      "|    total_timesteps  | 835208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 208551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=835500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 835500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.307    |\n",
      "|    n_updates        | 208624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8388     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82453    |\n",
      "|    total_timesteps  | 835608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000884 |\n",
      "|    n_updates        | 208651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=836000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 836000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 208749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8392     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82491    |\n",
      "|    total_timesteps  | 836008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 208751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8396     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82528    |\n",
      "|    total_timesteps  | 836408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 208851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=836500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 836500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 208874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.08    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8400     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82576    |\n",
      "|    total_timesteps  | 836808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 208951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=837000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 837000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 208999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.08    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8404     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82614    |\n",
      "|    total_timesteps  | 837208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 209051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=837500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 837500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 209124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8408     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82661    |\n",
      "|    total_timesteps  | 837608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00371  |\n",
      "|    n_updates        | 209151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=838000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 838000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00319  |\n",
      "|    n_updates        | 209249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8412     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82711    |\n",
      "|    total_timesteps  | 838008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 209251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8416     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82737    |\n",
      "|    total_timesteps  | 838408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 209351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=838500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 838500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00348  |\n",
      "|    n_updates        | 209374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8420     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82787    |\n",
      "|    total_timesteps  | 838808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 209451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=839000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 839000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 209499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8424     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82837    |\n",
      "|    total_timesteps  | 839208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0976   |\n",
      "|    n_updates        | 209551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=839500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 839500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 209624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.15    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8428     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82886    |\n",
      "|    total_timesteps  | 839608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.313    |\n",
      "|    n_updates        | 209651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 840000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.252    |\n",
      "|    n_updates        | 209749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8432     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82930    |\n",
      "|    total_timesteps  | 840008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.308    |\n",
      "|    n_updates        | 209751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.15    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8436     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 82958    |\n",
      "|    total_timesteps  | 840408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 209851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=840500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 840500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0948   |\n",
      "|    n_updates        | 209874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8440     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83000    |\n",
      "|    total_timesteps  | 840808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00931  |\n",
      "|    n_updates        | 209951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=841000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 841000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00426  |\n",
      "|    n_updates        | 209999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.14    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8444     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83044    |\n",
      "|    total_timesteps  | 841208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 210051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=841500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 841500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00294  |\n",
      "|    n_updates        | 210124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8448     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83085    |\n",
      "|    total_timesteps  | 841608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 210151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=842000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 842000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 210249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.13    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8452     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83132    |\n",
      "|    total_timesteps  | 842008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.302    |\n",
      "|    n_updates        | 210251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83166    |\n",
      "|    total_timesteps  | 842408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 210351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=842500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 842500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 210374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83217    |\n",
      "|    total_timesteps  | 842808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000925 |\n",
      "|    n_updates        | 210451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=843000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 843000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.3      |\n",
      "|    n_updates        | 210499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8464     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83255    |\n",
      "|    total_timesteps  | 843208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 210551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=843500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 843500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 210624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8468     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83302    |\n",
      "|    total_timesteps  | 843608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 210651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=844000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 844000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 210749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8472     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83346    |\n",
      "|    total_timesteps  | 844008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 210751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.07    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83372    |\n",
      "|    total_timesteps  | 844408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 210851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=844500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 844500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 210874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83417    |\n",
      "|    total_timesteps  | 844808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00859  |\n",
      "|    n_updates        | 210951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=845000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 845000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00457  |\n",
      "|    n_updates        | 210999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.08    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8484     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83466    |\n",
      "|    total_timesteps  | 845208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.271    |\n",
      "|    n_updates        | 211051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=845500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 845500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 211124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83510    |\n",
      "|    total_timesteps  | 845608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000791 |\n",
      "|    n_updates        | 211151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=846000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 846000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.299    |\n",
      "|    n_updates        | 211249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83558    |\n",
      "|    total_timesteps  | 846008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 211251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.06    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83583    |\n",
      "|    total_timesteps  | 846408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 211351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=846500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 846500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 211374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83631    |\n",
      "|    total_timesteps  | 846808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 211451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=847000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 847000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000975 |\n",
      "|    n_updates        | 211499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.01    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83676    |\n",
      "|    total_timesteps  | 847208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000848 |\n",
      "|    n_updates        | 211551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=847500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 847500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000983 |\n",
      "|    n_updates        | 211624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8508     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83725    |\n",
      "|    total_timesteps  | 847608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 211651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=848000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 848000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 211749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83772    |\n",
      "|    total_timesteps  | 848008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00886  |\n",
      "|    n_updates        | 211751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83797    |\n",
      "|    total_timesteps  | 848408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 211851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=848500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 848500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000723 |\n",
      "|    n_updates        | 211874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83847    |\n",
      "|    total_timesteps  | 848808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.471    |\n",
      "|    n_updates        | 211951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=849000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 849000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 211999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83894    |\n",
      "|    total_timesteps  | 849208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 212051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=849500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 849500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 212124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83937    |\n",
      "|    total_timesteps  | 849608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 212151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 850000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000787 |\n",
      "|    n_updates        | 212249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 83980    |\n",
      "|    total_timesteps  | 850008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 212251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84014    |\n",
      "|    total_timesteps  | 850408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.297    |\n",
      "|    n_updates        | 212351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=850500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 850500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00908  |\n",
      "|    n_updates        | 212374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84051    |\n",
      "|    total_timesteps  | 850808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00264  |\n",
      "|    n_updates        | 212451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=851000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 851000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 212499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84098    |\n",
      "|    total_timesteps  | 851208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000941 |\n",
      "|    n_updates        | 212551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=851500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 851500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000785 |\n",
      "|    n_updates        | 212624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84145    |\n",
      "|    total_timesteps  | 851608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 212651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=852000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 852000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 212749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84191    |\n",
      "|    total_timesteps  | 852008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 212751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.73    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84216    |\n",
      "|    total_timesteps  | 852408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 212851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=852500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 852500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00506  |\n",
      "|    n_updates        | 212874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84263    |\n",
      "|    total_timesteps  | 852808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 212951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=853000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 853000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 212999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.65    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84313    |\n",
      "|    total_timesteps  | 853208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 213051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=853500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 853500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 213124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84355    |\n",
      "|    total_timesteps  | 853608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 213151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=854000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 854000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 213249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.59    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84401    |\n",
      "|    total_timesteps  | 854008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 213251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84426    |\n",
      "|    total_timesteps  | 854408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 213351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=854500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 854500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.296    |\n",
      "|    n_updates        | 213374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84471    |\n",
      "|    total_timesteps  | 854808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 213451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=855000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 855000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 213499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.46    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84517    |\n",
      "|    total_timesteps  | 855208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 213551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=855500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 855500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 213624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.42    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84562    |\n",
      "|    total_timesteps  | 855608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 213651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=856000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 856000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000697 |\n",
      "|    n_updates        | 213749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.39    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84606    |\n",
      "|    total_timesteps  | 856008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.496    |\n",
      "|    n_updates        | 213751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.35    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84631    |\n",
      "|    total_timesteps  | 856408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00391  |\n",
      "|    n_updates        | 213851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=856500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 856500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 213874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84680    |\n",
      "|    total_timesteps  | 856808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000888 |\n",
      "|    n_updates        | 213951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=857000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 857000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 213999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84723    |\n",
      "|    total_timesteps  | 857208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00489  |\n",
      "|    n_updates        | 214051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=857500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 857500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000723 |\n",
      "|    n_updates        | 214124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84772    |\n",
      "|    total_timesteps  | 857608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.268    |\n",
      "|    n_updates        | 214151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=858000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 858000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.243    |\n",
      "|    n_updates        | 214249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84819    |\n",
      "|    total_timesteps  | 858008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 214251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84844    |\n",
      "|    total_timesteps  | 858408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 214351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=858500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 858500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 214374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84890    |\n",
      "|    total_timesteps  | 858808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00431  |\n",
      "|    n_updates        | 214451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=859000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 859000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000625 |\n",
      "|    n_updates        | 214499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84939    |\n",
      "|    total_timesteps  | 859208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 214551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=859500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 859500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 214624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 84987    |\n",
      "|    total_timesteps  | 859608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000825 |\n",
      "|    n_updates        | 214651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 860000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000715 |\n",
      "|    n_updates        | 214749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85034    |\n",
      "|    total_timesteps  | 860008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 214751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85059    |\n",
      "|    total_timesteps  | 860408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 214851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=860500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 860500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00446  |\n",
      "|    n_updates        | 214874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85102    |\n",
      "|    total_timesteps  | 860808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.288    |\n",
      "|    n_updates        | 214951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=861000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 861000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 214999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85148    |\n",
      "|    total_timesteps  | 861208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.268    |\n",
      "|    n_updates        | 215051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=861500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 861500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 215124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85194    |\n",
      "|    total_timesteps  | 861608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 215151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=862000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 862000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 215249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.09    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85240    |\n",
      "|    total_timesteps  | 862008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00264  |\n",
      "|    n_updates        | 215251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.11    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85265    |\n",
      "|    total_timesteps  | 862408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000638 |\n",
      "|    n_updates        | 215351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=862500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 862500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 215374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85313    |\n",
      "|    total_timesteps  | 862808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.265    |\n",
      "|    n_updates        | 215451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=863000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 863000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.289    |\n",
      "|    n_updates        | 215499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85363    |\n",
      "|    total_timesteps  | 863208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 215551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=863500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 863500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.29     |\n",
      "|    n_updates        | 215624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85411    |\n",
      "|    total_timesteps  | 863608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 215651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=864000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 864000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 215749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85448    |\n",
      "|    total_timesteps  | 864008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000908 |\n",
      "|    n_updates        | 215751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85486    |\n",
      "|    total_timesteps  | 864408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 215851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=864500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 864500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 215874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.29    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85534    |\n",
      "|    total_timesteps  | 864808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 215951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=865000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 865000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 215999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85580    |\n",
      "|    total_timesteps  | 865208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.29     |\n",
      "|    n_updates        | 216051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=865500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 865500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 216124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85622    |\n",
      "|    total_timesteps  | 865608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 216151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=866000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 866000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.285    |\n",
      "|    n_updates        | 216249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85671    |\n",
      "|    total_timesteps  | 866008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 216251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.41    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85699    |\n",
      "|    total_timesteps  | 866408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00614  |\n",
      "|    n_updates        | 216351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=866500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 866500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 216374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.42    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85742    |\n",
      "|    total_timesteps  | 866808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000911 |\n",
      "|    n_updates        | 216451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=867000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 867000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000762 |\n",
      "|    n_updates        | 216499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.42    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85785    |\n",
      "|    total_timesteps  | 867208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 216551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=867500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 867500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00223  |\n",
      "|    n_updates        | 216624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85832    |\n",
      "|    total_timesteps  | 867608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 216651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=868000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 868000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.265    |\n",
      "|    n_updates        | 216749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8712     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85880    |\n",
      "|    total_timesteps  | 868008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 216751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.46    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8716     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85905    |\n",
      "|    total_timesteps  | 868408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000749 |\n",
      "|    n_updates        | 216851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=868500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 868500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 216874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.48    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8720     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 85955    |\n",
      "|    total_timesteps  | 868808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00578  |\n",
      "|    n_updates        | 216951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=869000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 869000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 216999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8724     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86003    |\n",
      "|    total_timesteps  | 869208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 217051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=869500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 869500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.157    |\n",
      "|    n_updates        | 217124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8728     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86051    |\n",
      "|    total_timesteps  | 869608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 217151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 870000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 217249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.51    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8732     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86089    |\n",
      "|    total_timesteps  | 870008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00322  |\n",
      "|    n_updates        | 217251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.52    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8736     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86124    |\n",
      "|    total_timesteps  | 870408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00438  |\n",
      "|    n_updates        | 217351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=870500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 870500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.268    |\n",
      "|    n_updates        | 217374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.52    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8740     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86171    |\n",
      "|    total_timesteps  | 870808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 217451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=871000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 871000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 217499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.53    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8744     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86215    |\n",
      "|    total_timesteps  | 871208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 217551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=871500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 871500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.288    |\n",
      "|    n_updates        | 217624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.53    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8748     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86260    |\n",
      "|    total_timesteps  | 871608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 217651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=872000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 872000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.543    |\n",
      "|    n_updates        | 217749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8752     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86310    |\n",
      "|    total_timesteps  | 872008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 217751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.54    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8756     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86334    |\n",
      "|    total_timesteps  | 872408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.564    |\n",
      "|    n_updates        | 217851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=872500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 872500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00742  |\n",
      "|    n_updates        | 217874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.52    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8760     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86380    |\n",
      "|    total_timesteps  | 872808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000793 |\n",
      "|    n_updates        | 217951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=873000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 873000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 217999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.51    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8764     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86428    |\n",
      "|    total_timesteps  | 873208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.28     |\n",
      "|    n_updates        | 218051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=873500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 873500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000857 |\n",
      "|    n_updates        | 218124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8768     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86477    |\n",
      "|    total_timesteps  | 873608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 218151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=874000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 874000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 218249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.48    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8772     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86526    |\n",
      "|    total_timesteps  | 874008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 218251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8776     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86553    |\n",
      "|    total_timesteps  | 874408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 218351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=874500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 874500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 218374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8780     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86601    |\n",
      "|    total_timesteps  | 874808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 218451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=875000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 875000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 218499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8784     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86652    |\n",
      "|    total_timesteps  | 875208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 218551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=875500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 875500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.265    |\n",
      "|    n_updates        | 218624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.43    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8788     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86713    |\n",
      "|    total_timesteps  | 875608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 218651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=876000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 876000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 218749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8792     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86772    |\n",
      "|    total_timesteps  | 876008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 218751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8796     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86799    |\n",
      "|    total_timesteps  | 876408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 218851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=876500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 876500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00645  |\n",
      "|    n_updates        | 218874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8800     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86850    |\n",
      "|    total_timesteps  | 876808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000997 |\n",
      "|    n_updates        | 218951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=877000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 877000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 218999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8804     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86898    |\n",
      "|    total_timesteps  | 877208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 219051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=877500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 877500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 219124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.36    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8808     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86943    |\n",
      "|    total_timesteps  | 877608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 219151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=878000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 878000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000696 |\n",
      "|    n_updates        | 219249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.38    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8812     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 86988    |\n",
      "|    total_timesteps  | 878008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000469 |\n",
      "|    n_updates        | 219251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8816     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87013    |\n",
      "|    total_timesteps  | 878408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0066   |\n",
      "|    n_updates        | 219351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=878500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 878500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 219374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8820     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87062    |\n",
      "|    total_timesteps  | 878808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 219451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=879000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 879000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000659 |\n",
      "|    n_updates        | 219499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8824     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87105    |\n",
      "|    total_timesteps  | 879208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 219551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=879500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 879500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 219624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.32    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8828     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87145    |\n",
      "|    total_timesteps  | 879608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000779 |\n",
      "|    n_updates        | 219651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 880000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00486  |\n",
      "|    n_updates        | 219749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8832     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87187    |\n",
      "|    total_timesteps  | 880008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 219751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8836     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87222    |\n",
      "|    total_timesteps  | 880408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 219851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=880500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 880500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 219874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8840     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87259    |\n",
      "|    total_timesteps  | 880808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000847 |\n",
      "|    n_updates        | 219951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=881000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 881000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 219999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8844     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87304    |\n",
      "|    total_timesteps  | 881208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 220051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=881500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 881500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.28     |\n",
      "|    n_updates        | 220124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8848     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87350    |\n",
      "|    total_timesteps  | 881608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000662 |\n",
      "|    n_updates        | 220151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=882000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 882000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 220249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8852     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87395    |\n",
      "|    total_timesteps  | 882008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 220251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.27    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8856     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87434    |\n",
      "|    total_timesteps  | 882408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.442    |\n",
      "|    n_updates        | 220351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=882500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 882500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000969 |\n",
      "|    n_updates        | 220374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.29    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8860     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87471    |\n",
      "|    total_timesteps  | 882808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 220451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=883000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 883000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 220499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8864     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87521    |\n",
      "|    total_timesteps  | 883208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000698 |\n",
      "|    n_updates        | 220551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=883500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 883500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000607 |\n",
      "|    n_updates        | 220624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8868     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87568    |\n",
      "|    total_timesteps  | 883608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 220651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=884000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 884000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 220749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8872     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87614    |\n",
      "|    total_timesteps  | 884008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 220751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8876     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87641    |\n",
      "|    total_timesteps  | 884408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 220851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=884500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 884500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 220874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8880     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87684    |\n",
      "|    total_timesteps  | 884808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 220951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=885000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 885000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 220999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8884     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87732    |\n",
      "|    total_timesteps  | 885208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.314    |\n",
      "|    n_updates        | 221051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=885500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 885500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 221124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8888     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87781    |\n",
      "|    total_timesteps  | 885608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 221151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=886000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 886000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 221249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8892     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87828    |\n",
      "|    total_timesteps  | 886008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000834 |\n",
      "|    n_updates        | 221251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8896     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87853    |\n",
      "|    total_timesteps  | 886408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 221351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=886500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 886500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 221374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8900     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87899    |\n",
      "|    total_timesteps  | 886808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 221451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=887000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 887000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 221499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8904     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87944    |\n",
      "|    total_timesteps  | 887208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 221551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=887500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 887500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.005    |\n",
      "|    n_updates        | 221624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8908     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 87986    |\n",
      "|    total_timesteps  | 887608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 221651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=888000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 888000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00909  |\n",
      "|    n_updates        | 221749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8912     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88031    |\n",
      "|    total_timesteps  | 888008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 221751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8916     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88062    |\n",
      "|    total_timesteps  | 888408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000506 |\n",
      "|    n_updates        | 221851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=888500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 888500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 221874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8920     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88105    |\n",
      "|    total_timesteps  | 888808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 221951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=889000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 889000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000957 |\n",
      "|    n_updates        | 221999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8924     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88157    |\n",
      "|    total_timesteps  | 889208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000702 |\n",
      "|    n_updates        | 222051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=889500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 889500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 222124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8928     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88203    |\n",
      "|    total_timesteps  | 889608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000879 |\n",
      "|    n_updates        | 222151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 890000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.812    |\n",
      "|    n_updates        | 222249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8932     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88252    |\n",
      "|    total_timesteps  | 890008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.474    |\n",
      "|    n_updates        | 222251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8936     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88277    |\n",
      "|    total_timesteps  | 890408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00437  |\n",
      "|    n_updates        | 222351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=890500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 890500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.271    |\n",
      "|    n_updates        | 222374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.17    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8940     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88321    |\n",
      "|    total_timesteps  | 890808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 222451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=891000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 891000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 222499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8944     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88368    |\n",
      "|    total_timesteps  | 891208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00189  |\n",
      "|    n_updates        | 222551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=891500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 891500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 222624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8948     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88417    |\n",
      "|    total_timesteps  | 891608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.268    |\n",
      "|    n_updates        | 222651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=892000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 892000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 222749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.23    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8952     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88466    |\n",
      "|    total_timesteps  | 892008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 222751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.26    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8956     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88491    |\n",
      "|    total_timesteps  | 892408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 222851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=892500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 892500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 222874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.28    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8960     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88543    |\n",
      "|    total_timesteps  | 892808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 222951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=893000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 893000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 222999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8964     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88590    |\n",
      "|    total_timesteps  | 893208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 223051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=893500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 893500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000616 |\n",
      "|    n_updates        | 223124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8968     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88641    |\n",
      "|    total_timesteps  | 893608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 223151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=894000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 894000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 223249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8972     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88692    |\n",
      "|    total_timesteps  | 894008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 223251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.39    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8976     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88717    |\n",
      "|    total_timesteps  | 894408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 223351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=894500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 894500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 223374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8980     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88765    |\n",
      "|    total_timesteps  | 894808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 223451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=895000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 895000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000627 |\n",
      "|    n_updates        | 223499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8984     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88813    |\n",
      "|    total_timesteps  | 895208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 223551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=895500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 895500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 223624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.41    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8988     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88860    |\n",
      "|    total_timesteps  | 895608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 223651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=896000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 896000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000687 |\n",
      "|    n_updates        | 223749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.44    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8992     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88903    |\n",
      "|    total_timesteps  | 896008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.272    |\n",
      "|    n_updates        | 223751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.46    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8996     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88931    |\n",
      "|    total_timesteps  | 896408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 223851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=896500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 896500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 223874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.45    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9000     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 88975    |\n",
      "|    total_timesteps  | 896808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 223951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=897000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 897000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 223999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.51    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9004     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89016    |\n",
      "|    total_timesteps  | 897208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 224051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=897500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 897500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000565 |\n",
      "|    n_updates        | 224124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.54    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9008     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89067    |\n",
      "|    total_timesteps  | 897608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.002    |\n",
      "|    n_updates        | 224151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=898000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 898000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 224249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9012     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89116    |\n",
      "|    total_timesteps  | 898008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 224251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9016     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89142    |\n",
      "|    total_timesteps  | 898408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 224351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=898500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 898500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 224374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9020     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89191    |\n",
      "|    total_timesteps  | 898808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000996 |\n",
      "|    n_updates        | 224451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=899000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 899000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 224499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9024     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89239    |\n",
      "|    total_timesteps  | 899208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 224551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=899500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 899500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 224624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9028     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89288    |\n",
      "|    total_timesteps  | 899608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 224651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 900000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 224749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.67    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9032     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89335    |\n",
      "|    total_timesteps  | 900008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0262   |\n",
      "|    n_updates        | 224751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.66    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9036     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89360    |\n",
      "|    total_timesteps  | 900408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 224851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=900500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 900500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 224874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9040     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89406    |\n",
      "|    total_timesteps  | 900808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.396    |\n",
      "|    n_updates        | 224951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=901000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 901000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 224999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.72    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9044     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89453    |\n",
      "|    total_timesteps  | 901208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 225051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=901500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 901500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 225124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9048     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89500    |\n",
      "|    total_timesteps  | 901608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000823 |\n",
      "|    n_updates        | 225151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=902000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 902000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.252    |\n",
      "|    n_updates        | 225249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.83    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9052     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89546    |\n",
      "|    total_timesteps  | 902008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 225251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9056     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89571    |\n",
      "|    total_timesteps  | 902408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 225351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=902500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 902500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00336  |\n",
      "|    n_updates        | 225374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.89    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9060     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89624    |\n",
      "|    total_timesteps  | 902808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 225451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=903000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 903000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 225499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.93    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9064     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89666    |\n",
      "|    total_timesteps  | 903208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000992 |\n",
      "|    n_updates        | 225551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=903500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 903500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.562    |\n",
      "|    n_updates        | 225624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9068     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89708    |\n",
      "|    total_timesteps  | 903608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000762 |\n",
      "|    n_updates        | 225651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=904000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 904000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 225749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9072     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89753    |\n",
      "|    total_timesteps  | 904008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 225751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.04    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9076     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89789    |\n",
      "|    total_timesteps  | 904408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000337 |\n",
      "|    n_updates        | 225851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=904500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 904500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0032   |\n",
      "|    n_updates        | 225874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.05    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9080     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89830    |\n",
      "|    total_timesteps  | 904808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 225951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=905000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 905000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 225999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.12    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9084     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89870    |\n",
      "|    total_timesteps  | 905208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 226051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=905500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 905500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000941 |\n",
      "|    n_updates        | 226124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9088     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89916    |\n",
      "|    total_timesteps  | 905608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 226151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=906000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 906000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 226249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9092     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89966    |\n",
      "|    total_timesteps  | 906008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 226251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.24    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9096     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 89990    |\n",
      "|    total_timesteps  | 906408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 226351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=906500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 906500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 226374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9100     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90032    |\n",
      "|    total_timesteps  | 906808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00386  |\n",
      "|    n_updates        | 226451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=907000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 907000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00354  |\n",
      "|    n_updates        | 226499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.32    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9104     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90075    |\n",
      "|    total_timesteps  | 907208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 226551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=907500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 907500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 226624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9108     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90112    |\n",
      "|    total_timesteps  | 907608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 226651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=908000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 908000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00375  |\n",
      "|    n_updates        | 226749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9112     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90161    |\n",
      "|    total_timesteps  | 908008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 226751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.37    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9116     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90198    |\n",
      "|    total_timesteps  | 908408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 226851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=908500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 908500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 226874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.38    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9120     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90236    |\n",
      "|    total_timesteps  | 908808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.268    |\n",
      "|    n_updates        | 226951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=909000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 909000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00784  |\n",
      "|    n_updates        | 226999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9124     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90280    |\n",
      "|    total_timesteps  | 909208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.53     |\n",
      "|    n_updates        | 227051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=909500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 909500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 227124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9128     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90325    |\n",
      "|    total_timesteps  | 909608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 227151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 910000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 227249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.44    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9132     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90372    |\n",
      "|    total_timesteps  | 910008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.529    |\n",
      "|    n_updates        | 227251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.44    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9136     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90398    |\n",
      "|    total_timesteps  | 910408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 227351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=910500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 910500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 227374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9140     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90445    |\n",
      "|    total_timesteps  | 910808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 227451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=911000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 911000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 227499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.34    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9144     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90490    |\n",
      "|    total_timesteps  | 911208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 227551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=911500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 911500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0006   |\n",
      "|    n_updates        | 227624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.27    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9148     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90528    |\n",
      "|    total_timesteps  | 911608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.424    |\n",
      "|    n_updates        | 227651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=912000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 912000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 227749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.21    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9152     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90575    |\n",
      "|    total_timesteps  | 912008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000497 |\n",
      "|    n_updates        | 227751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9156     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90610    |\n",
      "|    total_timesteps  | 912408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000974 |\n",
      "|    n_updates        | 227851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=912500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 912500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000665 |\n",
      "|    n_updates        | 227874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9160     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90648    |\n",
      "|    total_timesteps  | 912808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000852 |\n",
      "|    n_updates        | 227951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=913000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 913000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 227999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9164     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90695    |\n",
      "|    total_timesteps  | 913208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.259    |\n",
      "|    n_updates        | 228051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=913500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 913500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 228124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9168     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90742    |\n",
      "|    total_timesteps  | 913608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.505    |\n",
      "|    n_updates        | 228151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=914000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 914000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.398    |\n",
      "|    n_updates        | 228249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9172     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90790    |\n",
      "|    total_timesteps  | 914008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 228251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9176     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90815    |\n",
      "|    total_timesteps  | 914408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.259    |\n",
      "|    n_updates        | 228351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=914500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 914500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 228374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.85    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9180     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90863    |\n",
      "|    total_timesteps  | 914808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 228451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=915000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 915000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 228499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.81    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9184     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90912    |\n",
      "|    total_timesteps  | 915208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 228551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=915500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 915500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 228624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.79    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9188     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90957    |\n",
      "|    total_timesteps  | 915608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000991 |\n",
      "|    n_updates        | 228651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=916000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 916000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 228749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.75    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9192     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 90997    |\n",
      "|    total_timesteps  | 916008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000501 |\n",
      "|    n_updates        | 228751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.71    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9196     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91026    |\n",
      "|    total_timesteps  | 916408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 228851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=916500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 916500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 228874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.69    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9200     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91071    |\n",
      "|    total_timesteps  | 916808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0009   |\n",
      "|    n_updates        | 228951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=917000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 917000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 228999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9204     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91120    |\n",
      "|    total_timesteps  | 917208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 229051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=917500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 917500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000845 |\n",
      "|    n_updates        | 229124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9208     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91157    |\n",
      "|    total_timesteps  | 917608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 229151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=918000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 918000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 229249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9212     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91205    |\n",
      "|    total_timesteps  | 918008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 229251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9216     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91237    |\n",
      "|    total_timesteps  | 918408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 229351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=918500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 918500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.523    |\n",
      "|    n_updates        | 229374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9220     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91283    |\n",
      "|    total_timesteps  | 918808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 229451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=919000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 919000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0991   |\n",
      "|    n_updates        | 229499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9224     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91328    |\n",
      "|    total_timesteps  | 919208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00349  |\n",
      "|    n_updates        | 229551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=919500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 919500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000423 |\n",
      "|    n_updates        | 229624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9228     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91372    |\n",
      "|    total_timesteps  | 919608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 229651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 920000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.255    |\n",
      "|    n_updates        | 229749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9232     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91418    |\n",
      "|    total_timesteps  | 920008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00477  |\n",
      "|    n_updates        | 229751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9236     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91443    |\n",
      "|    total_timesteps  | 920408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000849 |\n",
      "|    n_updates        | 229851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=920500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 920500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.254    |\n",
      "|    n_updates        | 229874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9240     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91489    |\n",
      "|    total_timesteps  | 920808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 229951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=921000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 921000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 229999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9244     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91535    |\n",
      "|    total_timesteps  | 921208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 230051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=921500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 921500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 230124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9248     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91577    |\n",
      "|    total_timesteps  | 921608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00794  |\n",
      "|    n_updates        | 230151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=922000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 922000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.55     |\n",
      "|    n_updates        | 230249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.63    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9252     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91621    |\n",
      "|    total_timesteps  | 922008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 230251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.62    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9256     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91645    |\n",
      "|    total_timesteps  | 922408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 230351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=922500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 922500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000901 |\n",
      "|    n_updates        | 230374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9260     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91690    |\n",
      "|    total_timesteps  | 922808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000483 |\n",
      "|    n_updates        | 230451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=923000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 923000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0297   |\n",
      "|    n_updates        | 230499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.61    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9264     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91737    |\n",
      "|    total_timesteps  | 923208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 230551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=923500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 923500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 230624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9268     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91783    |\n",
      "|    total_timesteps  | 923608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0979   |\n",
      "|    n_updates        | 230651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=924000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 924000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00088  |\n",
      "|    n_updates        | 230749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.57    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9272     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91826    |\n",
      "|    total_timesteps  | 924008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 230751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.55    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9276     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91854    |\n",
      "|    total_timesteps  | 924408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 230851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=924500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 924500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 230874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.53    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9280     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91900    |\n",
      "|    total_timesteps  | 924808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 230951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=925000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 925000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 230999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9284     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91948    |\n",
      "|    total_timesteps  | 925208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000595 |\n",
      "|    n_updates        | 231051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=925500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 925500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 231124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9288     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 91994    |\n",
      "|    total_timesteps  | 925608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 231151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=926000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 926000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0098   |\n",
      "|    n_updates        | 231249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.43    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9292     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92035    |\n",
      "|    total_timesteps  | 926008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 231251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.41    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9296     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92067    |\n",
      "|    total_timesteps  | 926408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 231351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=926500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 926500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 231374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.37    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9300     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92109    |\n",
      "|    total_timesteps  | 926808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 231451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=927000, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 927000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000741 |\n",
      "|    n_updates        | 231499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.34    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9304     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92148    |\n",
      "|    total_timesteps  | 927208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 231551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=927500, episode_reward=-9.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -9       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 927500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 231624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.31    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9308     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92198    |\n",
      "|    total_timesteps  | 927608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 231651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=928000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 928000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000706 |\n",
      "|    n_updates        | 231749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.24    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9312     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92245    |\n",
      "|    total_timesteps  | 928008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.544    |\n",
      "|    n_updates        | 231751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9316     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92270    |\n",
      "|    total_timesteps  | 928408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 231851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=928500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 928500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.507    |\n",
      "|    n_updates        | 231874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9320     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92318    |\n",
      "|    total_timesteps  | 928808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0049   |\n",
      "|    n_updates        | 231951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=929000, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 929000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000314 |\n",
      "|    n_updates        | 231999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.15    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9324     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92363    |\n",
      "|    total_timesteps  | 929208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00722  |\n",
      "|    n_updates        | 232051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=929500, episode_reward=-8.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -8       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 929500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00189  |\n",
      "|    n_updates        | 232124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.14    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9328     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92400    |\n",
      "|    total_timesteps  | 929608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000431 |\n",
      "|    n_updates        | 232151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 930000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 232249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9332     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92449    |\n",
      "|    total_timesteps  | 930008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.272    |\n",
      "|    n_updates        | 232251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9336     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92487    |\n",
      "|    total_timesteps  | 930408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.253    |\n",
      "|    n_updates        | 232351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=930500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 930500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.249    |\n",
      "|    n_updates        | 232374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.18    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9340     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92525    |\n",
      "|    total_timesteps  | 930808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000669 |\n",
      "|    n_updates        | 232451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=931000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 931000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00046  |\n",
      "|    n_updates        | 232499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9344     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92576    |\n",
      "|    total_timesteps  | 931208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.345    |\n",
      "|    n_updates        | 232551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=931500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 931500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00308  |\n",
      "|    n_updates        | 232624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.33    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9348     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92623    |\n",
      "|    total_timesteps  | 931608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 232651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=932000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 932000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 232749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.41    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9352     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92671    |\n",
      "|    total_timesteps  | 932008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00259  |\n",
      "|    n_updates        | 232751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.47    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9356     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92696    |\n",
      "|    total_timesteps  | 932408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000916 |\n",
      "|    n_updates        | 232851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=932500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 932500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 232874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.52    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9360     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92743    |\n",
      "|    total_timesteps  | 932808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000882 |\n",
      "|    n_updates        | 232951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=933000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 933000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000916 |\n",
      "|    n_updates        | 232999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9364     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92784    |\n",
      "|    total_timesteps  | 933208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 233051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=933500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 933500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 233124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.68    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9368     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92833    |\n",
      "|    total_timesteps  | 933608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000263 |\n",
      "|    n_updates        | 233151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=934000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 934000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 233249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9372     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92882    |\n",
      "|    total_timesteps  | 934008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 233251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9376     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92924    |\n",
      "|    total_timesteps  | 934408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 233351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=934500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 934500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 233374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9380     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 92976    |\n",
      "|    total_timesteps  | 934808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 233451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=935000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 935000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 233499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -8.94    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9384     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93031    |\n",
      "|    total_timesteps  | 935208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 233551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=935500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 935500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.259    |\n",
      "|    n_updates        | 233624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.02    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9388     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93085    |\n",
      "|    total_timesteps  | 935608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00757  |\n",
      "|    n_updates        | 233651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=936000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 936000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.507    |\n",
      "|    n_updates        | 233749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9392     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93137    |\n",
      "|    total_timesteps  | 936008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000967 |\n",
      "|    n_updates        | 233751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.17    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9396     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93177    |\n",
      "|    total_timesteps  | 936408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 233851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=936500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 936500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.129    |\n",
      "|    n_updates        | 233874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.23    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9400     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93228    |\n",
      "|    total_timesteps  | 936808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 233951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=937000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 937000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0355   |\n",
      "|    n_updates        | 233999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.29    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9404     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93283    |\n",
      "|    total_timesteps  | 937208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000755 |\n",
      "|    n_updates        | 234051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=937500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 937500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 234124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.35    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9408     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93340    |\n",
      "|    total_timesteps  | 937608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00816  |\n",
      "|    n_updates        | 234151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=938000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 938000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 234249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.43    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9412     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93395    |\n",
      "|    total_timesteps  | 938008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 234251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9416     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93424    |\n",
      "|    total_timesteps  | 938408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.25     |\n",
      "|    n_updates        | 234351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=938500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 938500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 234374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.56    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9420     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93477    |\n",
      "|    total_timesteps  | 938808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000126 |\n",
      "|    n_updates        | 234451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=939000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 939000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000697 |\n",
      "|    n_updates        | 234499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.63    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9424     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93524    |\n",
      "|    total_timesteps  | 939208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 234551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=939500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 939500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 234624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9428     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93572    |\n",
      "|    total_timesteps  | 939608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 234651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 940000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00296  |\n",
      "|    n_updates        | 234749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9432     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93622    |\n",
      "|    total_timesteps  | 940008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00623  |\n",
      "|    n_updates        | 234751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.81    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9436     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93657    |\n",
      "|    total_timesteps  | 940408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.575    |\n",
      "|    n_updates        | 234851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=940500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 940500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00291  |\n",
      "|    n_updates        | 234874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9440     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93705    |\n",
      "|    total_timesteps  | 940808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 234951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=941000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 941000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.244    |\n",
      "|    n_updates        | 234999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.83    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9444     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93756    |\n",
      "|    total_timesteps  | 941208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.129    |\n",
      "|    n_updates        | 235051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=941500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 941500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0615   |\n",
      "|    n_updates        | 235124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9448     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93807    |\n",
      "|    total_timesteps  | 941608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 235151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=942000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 942000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00076  |\n",
      "|    n_updates        | 235249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9452     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93858    |\n",
      "|    total_timesteps  | 942008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 235251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9456     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93899    |\n",
      "|    total_timesteps  | 942408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 235351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=942500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 942500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 235374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.85    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9460     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93954    |\n",
      "|    total_timesteps  | 942808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000712 |\n",
      "|    n_updates        | 235451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=943000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 943000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 235499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.84    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9464     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 93996    |\n",
      "|    total_timesteps  | 943208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 235551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=943500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 943500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 235624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.84    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9468     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94045    |\n",
      "|    total_timesteps  | 943608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 235651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=944000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 944000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00075  |\n",
      "|    n_updates        | 235749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.85    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9472     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94097    |\n",
      "|    total_timesteps  | 944008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 235751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.85    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9476     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94136    |\n",
      "|    total_timesteps  | 944408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000984 |\n",
      "|    n_updates        | 235851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=944500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 944500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 235874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9480     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94187    |\n",
      "|    total_timesteps  | 944808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000596 |\n",
      "|    n_updates        | 235951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=945000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 945000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 235999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9484     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94239    |\n",
      "|    total_timesteps  | 945208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 236051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=945500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 945500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 236124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9488     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94290    |\n",
      "|    total_timesteps  | 945608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 236151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=946000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 946000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 236249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9492     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94343    |\n",
      "|    total_timesteps  | 946008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00095  |\n",
      "|    n_updates        | 236251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9496     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94368    |\n",
      "|    total_timesteps  | 946408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.29     |\n",
      "|    n_updates        | 236351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=946500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 946500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000662 |\n",
      "|    n_updates        | 236374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.89    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9500     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94422    |\n",
      "|    total_timesteps  | 946808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 236451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=947000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 947000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 236499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9504     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94475    |\n",
      "|    total_timesteps  | 947208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.249    |\n",
      "|    n_updates        | 236551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=947500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 947500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000756 |\n",
      "|    n_updates        | 236624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.93    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9508     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94535    |\n",
      "|    total_timesteps  | 947608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 236651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=948000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 948000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00162  |\n",
      "|    n_updates        | 236749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.93    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9512     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94595    |\n",
      "|    total_timesteps  | 948008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 236751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.93    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9516     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94623    |\n",
      "|    total_timesteps  | 948408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 236851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=948500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 948500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 236874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9520     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94669    |\n",
      "|    total_timesteps  | 948808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000978 |\n",
      "|    n_updates        | 236951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=949000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 949000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000917 |\n",
      "|    n_updates        | 236999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9524     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94721    |\n",
      "|    total_timesteps  | 949208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 237051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=949500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 949500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 237124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9528     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94771    |\n",
      "|    total_timesteps  | 949608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 237151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 950000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00462  |\n",
      "|    n_updates        | 237249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.94    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9532     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94823    |\n",
      "|    total_timesteps  | 950008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00843  |\n",
      "|    n_updates        | 237251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.94    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9536     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94850    |\n",
      "|    total_timesteps  | 950408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 237351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=950500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 950500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 237374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9540     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94896    |\n",
      "|    total_timesteps  | 950808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 237451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=951000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 951000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 237499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9544     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94945    |\n",
      "|    total_timesteps  | 951208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 237551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=951500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 951500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 237624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9548     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 94994    |\n",
      "|    total_timesteps  | 951608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 237651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=952000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 952000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00031  |\n",
      "|    n_updates        | 237749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9552     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95040    |\n",
      "|    total_timesteps  | 952008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000465 |\n",
      "|    n_updates        | 237751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9556     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95071    |\n",
      "|    total_timesteps  | 952408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 237851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=952500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 952500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000637 |\n",
      "|    n_updates        | 237874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9560     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95117    |\n",
      "|    total_timesteps  | 952808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 237951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=953000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 953000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00206  |\n",
      "|    n_updates        | 237999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9564     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95160    |\n",
      "|    total_timesteps  | 953208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 238051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=953500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 953500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 238124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9568     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95210    |\n",
      "|    total_timesteps  | 953608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000428 |\n",
      "|    n_updates        | 238151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=954000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 954000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000745 |\n",
      "|    n_updates        | 238249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9572     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95258    |\n",
      "|    total_timesteps  | 954008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000833 |\n",
      "|    n_updates        | 238251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9576     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95294    |\n",
      "|    total_timesteps  | 954408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 238351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=954500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 954500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 238374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9580     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95335    |\n",
      "|    total_timesteps  | 954808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 238451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=955000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 955000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 238499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9584     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95382    |\n",
      "|    total_timesteps  | 955208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00223  |\n",
      "|    n_updates        | 238551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=955500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 955500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 238624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9588     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95431    |\n",
      "|    total_timesteps  | 955608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 238651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=956000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 956000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000529 |\n",
      "|    n_updates        | 238749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9592     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95480    |\n",
      "|    total_timesteps  | 956008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 238751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9596     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95507    |\n",
      "|    total_timesteps  | 956408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 238851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=956500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 956500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 238874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9600     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95556    |\n",
      "|    total_timesteps  | 956808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 238951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=957000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 957000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.239    |\n",
      "|    n_updates        | 238999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9604     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95607    |\n",
      "|    total_timesteps  | 957208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.145    |\n",
      "|    n_updates        | 239051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=957500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 957500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000623 |\n",
      "|    n_updates        | 239124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9608     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95657    |\n",
      "|    total_timesteps  | 957608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000973 |\n",
      "|    n_updates        | 239151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=958000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 958000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.239    |\n",
      "|    n_updates        | 239249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9612     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95706    |\n",
      "|    total_timesteps  | 958008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 239251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9616     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95732    |\n",
      "|    total_timesteps  | 958408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 239351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=958500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 958500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 239374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9620     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95778    |\n",
      "|    total_timesteps  | 958808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 239451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=959000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 959000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 239499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9624     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95830    |\n",
      "|    total_timesteps  | 959208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 239551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=959500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 959500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 239624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9628     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95870    |\n",
      "|    total_timesteps  | 959608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 239651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 960000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 239749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9632     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95917    |\n",
      "|    total_timesteps  | 960008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 239751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9636     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 95953    |\n",
      "|    total_timesteps  | 960408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 239851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=960500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 960500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.3      |\n",
      "|    n_updates        | 239874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9640     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96005    |\n",
      "|    total_timesteps  | 960808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 239951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=961000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 961000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 239999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9644     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96045    |\n",
      "|    total_timesteps  | 961208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 240051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=961500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 961500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 240124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9648     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96091    |\n",
      "|    total_timesteps  | 961608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 240151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=962000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 962000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 240249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9652     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96138    |\n",
      "|    total_timesteps  | 962008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 240251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9656     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96173    |\n",
      "|    total_timesteps  | 962408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 240351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=962500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 962500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000804 |\n",
      "|    n_updates        | 240374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9660     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96212    |\n",
      "|    total_timesteps  | 962808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 240451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=963000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 963000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000938 |\n",
      "|    n_updates        | 240499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9664     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96263    |\n",
      "|    total_timesteps  | 963208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 240551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=963500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 963500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00088  |\n",
      "|    n_updates        | 240624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9668     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96312    |\n",
      "|    total_timesteps  | 963608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0832   |\n",
      "|    n_updates        | 240651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=964000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 964000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000819 |\n",
      "|    n_updates        | 240749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9672     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96363    |\n",
      "|    total_timesteps  | 964008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000771 |\n",
      "|    n_updates        | 240751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9676     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96390    |\n",
      "|    total_timesteps  | 964408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 240851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=964500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 964500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00392  |\n",
      "|    n_updates        | 240874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9680     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96438    |\n",
      "|    total_timesteps  | 964808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000868 |\n",
      "|    n_updates        | 240951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=965000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 965000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 240999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9684     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96485    |\n",
      "|    total_timesteps  | 965208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00448  |\n",
      "|    n_updates        | 241051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=965500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 965500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 241124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9688     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96535    |\n",
      "|    total_timesteps  | 965608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 241151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=966000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 966000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 241249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9692     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96586    |\n",
      "|    total_timesteps  | 966008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000781 |\n",
      "|    n_updates        | 241251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9696     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96613    |\n",
      "|    total_timesteps  | 966408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.237    |\n",
      "|    n_updates        | 241351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=966500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 966500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000531 |\n",
      "|    n_updates        | 241374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9700     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96668    |\n",
      "|    total_timesteps  | 966808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 241451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=967000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 967000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 241499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9704     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96714    |\n",
      "|    total_timesteps  | 967208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 241551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=967500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 967500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 241624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9708     |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 96758    |\n",
      "|    total_timesteps  | 967608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000938 |\n",
      "|    n_updates        | 241651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=968000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 968000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 241749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9712     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 96809    |\n",
      "|    total_timesteps  | 968008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 241751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9716     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 96847    |\n",
      "|    total_timesteps  | 968408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 241851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=968500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 968500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 241874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9720     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 96887    |\n",
      "|    total_timesteps  | 968808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.299    |\n",
      "|    n_updates        | 241951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=969000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 969000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 241999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9724     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 96940    |\n",
      "|    total_timesteps  | 969208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000808 |\n",
      "|    n_updates        | 242051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=969500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 969500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 242124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9728     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 96986    |\n",
      "|    total_timesteps  | 969608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000964 |\n",
      "|    n_updates        | 242151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 970000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 242249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9732     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97034    |\n",
      "|    total_timesteps  | 970008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 242251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9736     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97059    |\n",
      "|    total_timesteps  | 970408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000971 |\n",
      "|    n_updates        | 242351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=970500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 970500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 242374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9740     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97105    |\n",
      "|    total_timesteps  | 970808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 242451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=971000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 971000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.237    |\n",
      "|    n_updates        | 242499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9744     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97152    |\n",
      "|    total_timesteps  | 971208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 242551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=971500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 971500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 242624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9748     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97189    |\n",
      "|    total_timesteps  | 971608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 242651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=972000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 972000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 242749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9752     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97238    |\n",
      "|    total_timesteps  | 972008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 242751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9756     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97263    |\n",
      "|    total_timesteps  | 972408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00468  |\n",
      "|    n_updates        | 242851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=972500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 972500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 242874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9760     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97310    |\n",
      "|    total_timesteps  | 972808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 242951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=973000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 973000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 242999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9764     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97359    |\n",
      "|    total_timesteps  | 973208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 243051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=973500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 973500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.23     |\n",
      "|    n_updates        | 243124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.97    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9768     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97405    |\n",
      "|    total_timesteps  | 973608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.573    |\n",
      "|    n_updates        | 243151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=974000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 974000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 243249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9772     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97444    |\n",
      "|    total_timesteps  | 974008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000378 |\n",
      "|    n_updates        | 243251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.94    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9776     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97479    |\n",
      "|    total_timesteps  | 974408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000834 |\n",
      "|    n_updates        | 243351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=974500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 974500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 243374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9780     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97516    |\n",
      "|    total_timesteps  | 974808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00419  |\n",
      "|    n_updates        | 243451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=975000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 975000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 243499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.91    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9784     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97566    |\n",
      "|    total_timesteps  | 975208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 243551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=975500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 975500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000625 |\n",
      "|    n_updates        | 243624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.89    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9788     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97613    |\n",
      "|    total_timesteps  | 975608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000489 |\n",
      "|    n_updates        | 243651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=976000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 976000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00319  |\n",
      "|    n_updates        | 243749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.89    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9792     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97648    |\n",
      "|    total_timesteps  | 976008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 243751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.89    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9796     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97682    |\n",
      "|    total_timesteps  | 976408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 243851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=976500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 976500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.288    |\n",
      "|    n_updates        | 243874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.86    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9800     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97724    |\n",
      "|    total_timesteps  | 976808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 243951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=977000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 977000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 243999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.81    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9804     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97764    |\n",
      "|    total_timesteps  | 977208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0022   |\n",
      "|    n_updates        | 244051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=977500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 977500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 244124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9808     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97806    |\n",
      "|    total_timesteps  | 977608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 244151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=978000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 978000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000811 |\n",
      "|    n_updates        | 244249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.78    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9812     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97849    |\n",
      "|    total_timesteps  | 978008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000704 |\n",
      "|    n_updates        | 244251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.77    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9816     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97876    |\n",
      "|    total_timesteps  | 978408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 244351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=978500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 978500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 244374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.75    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9820     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97921    |\n",
      "|    total_timesteps  | 978808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 244451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=979000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 979000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000662 |\n",
      "|    n_updates        | 244499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9824     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 97968    |\n",
      "|    total_timesteps  | 979208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 244551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=979500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 979500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 244624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9828     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98014    |\n",
      "|    total_timesteps  | 979608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.293    |\n",
      "|    n_updates        | 244651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 980000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00067  |\n",
      "|    n_updates        | 244749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9832     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98051    |\n",
      "|    total_timesteps  | 980008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00385  |\n",
      "|    n_updates        | 244751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9836     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98087    |\n",
      "|    total_timesteps  | 980408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 244851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=980500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 980500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 244874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9840     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98132    |\n",
      "|    total_timesteps  | 980808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 244951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=981000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 981000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 244999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9844     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98169    |\n",
      "|    total_timesteps  | 981208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00056  |\n",
      "|    n_updates        | 245051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=981500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 981500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 245124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9848     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98213    |\n",
      "|    total_timesteps  | 981608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 245151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=982000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 982000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 245249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.65    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9852     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98255    |\n",
      "|    total_timesteps  | 982008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000699 |\n",
      "|    n_updates        | 245251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9856     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98290    |\n",
      "|    total_timesteps  | 982408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 245351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=982500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 982500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 245374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9860     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98329    |\n",
      "|    total_timesteps  | 982808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 245451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=983000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 983000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 245499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9864     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98375    |\n",
      "|    total_timesteps  | 983208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 245551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=983500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 983500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 245624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.64    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9868     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98423    |\n",
      "|    total_timesteps  | 983608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 245651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=984000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 984000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 245749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.66    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9872     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98462    |\n",
      "|    total_timesteps  | 984008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00058  |\n",
      "|    n_updates        | 245751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9876     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98494    |\n",
      "|    total_timesteps  | 984408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000807 |\n",
      "|    n_updates        | 245851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=984500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 984500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 245874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9880     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98541    |\n",
      "|    total_timesteps  | 984808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000842 |\n",
      "|    n_updates        | 245951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=985000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 985000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000739 |\n",
      "|    n_updates        | 245999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9884     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98578    |\n",
      "|    total_timesteps  | 985208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00196  |\n",
      "|    n_updates        | 246051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=985500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 985500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 246124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9888     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98624    |\n",
      "|    total_timesteps  | 985608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 246151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=986000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 986000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 246249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9892     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98672    |\n",
      "|    total_timesteps  | 986008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 246251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9896     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98697    |\n",
      "|    total_timesteps  | 986408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 246351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=986500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 986500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000915 |\n",
      "|    n_updates        | 246374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.76    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9900     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98744    |\n",
      "|    total_timesteps  | 986808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000465 |\n",
      "|    n_updates        | 246451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=987000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 987000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 246499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.81    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9904     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98790    |\n",
      "|    total_timesteps  | 987208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.424    |\n",
      "|    n_updates        | 246551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=987500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 987500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00086  |\n",
      "|    n_updates        | 246624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.82    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9908     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98827    |\n",
      "|    total_timesteps  | 987608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 246651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=988000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 988000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 246749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.84    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9912     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98876    |\n",
      "|    total_timesteps  | 988008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 246751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.85    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9916     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98901    |\n",
      "|    total_timesteps  | 988408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000923 |\n",
      "|    n_updates        | 246851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=988500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 988500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.228    |\n",
      "|    n_updates        | 246874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9920     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98948    |\n",
      "|    total_timesteps  | 988808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 246951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=989000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 989000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000691 |\n",
      "|    n_updates        | 246999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9924     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 98996    |\n",
      "|    total_timesteps  | 989208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 247051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=989500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 989500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000443 |\n",
      "|    n_updates        | 247124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.95    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9928     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99033    |\n",
      "|    total_timesteps  | 989608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 247151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 990000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000586 |\n",
      "|    n_updates        | 247249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9932     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99078    |\n",
      "|    total_timesteps  | 990008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00537  |\n",
      "|    n_updates        | 247251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9936     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99110    |\n",
      "|    total_timesteps  | 990408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 247351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=990500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 990500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 247374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9940     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99152    |\n",
      "|    total_timesteps  | 990808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00045  |\n",
      "|    n_updates        | 247451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=991000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 991000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 247499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9944     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99200    |\n",
      "|    total_timesteps  | 991208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000577 |\n",
      "|    n_updates        | 247551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=991500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 991500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.233    |\n",
      "|    n_updates        | 247624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9948     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99253    |\n",
      "|    total_timesteps  | 991608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 247651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=992000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 992000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.223    |\n",
      "|    n_updates        | 247749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9952     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99302    |\n",
      "|    total_timesteps  | 992008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00356  |\n",
      "|    n_updates        | 247751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9956     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99325    |\n",
      "|    total_timesteps  | 992408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 247851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=992500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 992500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 247874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9960     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99363    |\n",
      "|    total_timesteps  | 992808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 247951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=993000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 993000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 247999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9964     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99402    |\n",
      "|    total_timesteps  | 993208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 248051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=993500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 993500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 248124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9968     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99435    |\n",
      "|    total_timesteps  | 993608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 248151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=994000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 994000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000991 |\n",
      "|    n_updates        | 248249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9972     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99474    |\n",
      "|    total_timesteps  | 994008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 248251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9976     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99499    |\n",
      "|    total_timesteps  | 994408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.396    |\n",
      "|    n_updates        | 248351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=994500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 994500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 248374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9980     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99538    |\n",
      "|    total_timesteps  | 994808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000997 |\n",
      "|    n_updates        | 248451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=995000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 995000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 248499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9984     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99579    |\n",
      "|    total_timesteps  | 995208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000968 |\n",
      "|    n_updates        | 248551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=995500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 995500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 248624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9988     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99622    |\n",
      "|    total_timesteps  | 995608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000956 |\n",
      "|    n_updates        | 248651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=996000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 996000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 248749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9992     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99662    |\n",
      "|    total_timesteps  | 996008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 248751   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9996     |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99687    |\n",
      "|    total_timesteps  | 996408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 248851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=996500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 996500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00328  |\n",
      "|    n_updates        | 248874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10000    |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99729    |\n",
      "|    total_timesteps  | 996808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000769 |\n",
      "|    n_updates        | 248951   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=997000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 997000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000585 |\n",
      "|    n_updates        | 248999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10004    |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99762    |\n",
      "|    total_timesteps  | 997208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 249051   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=997500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 997500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 249124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10008    |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99803    |\n",
      "|    total_timesteps  | 997608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 249151   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=998000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 998000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 249249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10012    |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99837    |\n",
      "|    total_timesteps  | 998008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000775 |\n",
      "|    n_updates        | 249251   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10016    |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99865    |\n",
      "|    total_timesteps  | 998408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000554 |\n",
      "|    n_updates        | 249351   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=998500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 998500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 249374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10020    |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99902    |\n",
      "|    total_timesteps  | 998808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 249451   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=999000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 999000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000671 |\n",
      "|    n_updates        | 249499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10024    |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99941    |\n",
      "|    total_timesteps  | 999208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00052  |\n",
      "|    n_updates        | 249551   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=999500, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 999500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000599 |\n",
      "|    n_updates        | 249624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10028    |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 99975    |\n",
      "|    total_timesteps  | 999608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00289  |\n",
      "|    n_updates        | 249651   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=-10.00 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | -10      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 249749   |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = SokobanEnvFixated()\n",
    "test_env = SokobanEnvFixated()\n",
    "\n",
    "# Define the A2C model\n",
    "model = DQN(CnnPolicy, \n",
    "            env, \n",
    "            tensorboard_log=\"./tensorboard_logs/\",\n",
    "            learning_starts=1000,\n",
    "            buffer_size=100000,\n",
    "            exploration_fraction=0.8,\n",
    "            verbose=1)\n",
    "\n",
    "eval_callback = EvalCallback(test_env, \n",
    "                             best_model_save_path='./models/',\n",
    "                             eval_freq=500,\n",
    "                             deterministic=True,\n",
    "                             render=False)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=1000000,\n",
    "            callback=eval_callback,\n",
    "            tb_log_name=\"log_sokoban_dqn_fixated_env\")\n",
    "env.close()\n",
    "\n",
    "# Run TensorBoard\n",
    "# In the terminal, run: tensorboard --logdir=./03_resource/03_DRL/tensorboard_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roger\\Documents\\Projekte\\vm-code-generation-with-knowledge-graph\\venv\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 15.36GB > 4.81GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: → → → ↓ ← ↓ ← ↑ ← ↑ ↑ ← ↓ ← ↓ → ← ← ↓ ↓ ↓ → ↑ ↑ → ↑ ← ↑ ← ↓ ↓ \t Total: 31\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = DQN.load(\"./models/model_sokoban_dqn_fixated_env_2\")\n",
    "\n",
    "# Create test enviroment\n",
    "test_env = SokobanEnvFixated()\n",
    "\n",
    "# Run the model in the test environment\n",
    "obs = test_env.reset()\n",
    "done = False\n",
    "actions = []\n",
    "while not done:\n",
    "    action, _states = model.predict(obs, deterministic = True)\n",
    "    actions.append(int(action))  # Get action from model\n",
    "    obs, reward, done, info = test_env.step(int(action))  # Apply action\n",
    "\n",
    "# Print actions\n",
    "actionDict = {0:\"□\", 1:\"↑\", 2:\"↓\", 3:\"←\", 4:\"→\"}\n",
    "print(\"Actions:\", \" \".join(actionDict.get(action) for action in actions), \"\\t Total:\", len(actions))\n",
    "\n",
    "render_state(test_env)\n",
    "test_env.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
