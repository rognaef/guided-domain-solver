{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b6e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from graph_parser_json import parse_stackup_to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91af6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    username=\"neo4j\",  # default username for Neo4j Desktop\n",
    "    password=\"12345678\",  # replace with your actual password\n",
    "    refresh_schema=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f88b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_graph(graph):\n",
    "    \"\"\"Delete all nodes and relationships in the Neo4j database.\"\"\"\n",
    "    clean_query = \"MATCH (n) DETACH DELETE n\"\n",
    "    graph.query(clean_query)\n",
    "    print(\"Graph cleaned: All nodes and relationships deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0f347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph cleaned: All nodes and relationships deleted.\n"
     ]
    }
   ],
   "source": [
    "# First clean the graph\n",
    "clean_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39edeba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation completed: Stackup structure imported into Neo4j\n"
     ]
    }
   ],
   "source": [
    "# Parse JSON and create graph\n",
    "graph = parse_stackup_to_graph('single_layer_v1.json', graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e331fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cypher_query(instruction, model_name=\"qwen2.5-coder:32b\", graph=None):\n",
    "    \"\"\"Generate a Cypher query with schema awareness\"\"\"\n",
    "    llm = ChatOllama(model=model_name)\n",
    "\n",
    "    # Get schema information if graph is provided\n",
    "    schema_info = \"\"\n",
    "    if graph:\n",
    "        # Get node labels\n",
    "        labels_result = graph.query(\"CALL db.labels()\")\n",
    "        node_labels = [record[\"label\"] for record in labels_result]\n",
    "\n",
    "        # Get relationship types\n",
    "        rel_result = graph.query(\"CALL db.relationshipTypes()\")\n",
    "        rel_types = [record[\"relationshipType\"] for record in rel_result]\n",
    "\n",
    "        schema_info = f\"\"\"\n",
    "        Available node labels: {', '.join(node_labels)}\n",
    "        Available relationship types: {', '.join(rel_types)}\n",
    "        \"\"\"\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "    You are an expert in converting natural language instructions to Cypher queries for Neo4j.\n",
    "\n",
    "    {schema_info}\n",
    "\n",
    "    Given the following instruction, create a valid Cypher query using only the relationship types\n",
    "    and node labels that exist in the database.\n",
    "\n",
    "    Instruction: {{instruction}}\n",
    "\n",
    "    Return only the Cypher query without any explanations or markdown formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"instruction\"])\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"instruction\": instruction})\n",
    "\n",
    "    if hasattr(result, \"content\"):\n",
    "        return result.content.strip()\n",
    "    return str(result).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a2ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fomulate_response(graph_response, instruction, model_name=\"llama3.2:latest\"):\n",
    "    llm = ChatOllama(model=model_name)\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "        Formulate a compact answer with short explanation to the following instruction based on the graph response.\n",
    "        Graph response: {graph_response}\n",
    "        Instruction: {instruction}\n",
    "        \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"instruction\", \"graph_response\"]\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\n",
    "        \"instruction\": instruction,\n",
    "        \"graph_response\": str(graph_response)\n",
    "    })\n",
    "\n",
    "    if hasattr(result, \"content\"):\n",
    "        return result.content.strip()\n",
    "    return str(result).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73387cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_execute_query(graph, instruction, max_retries=2):\n",
    "    \"\"\"Execute a query with retry logic if it fails\"\"\"\n",
    "    for attempt in range(max_retries + 1):\n",
    "        cypher_query = generate_cypher_query(instruction, graph=graph)\n",
    "\n",
    "        print(f\"Attempt {attempt+1}: {cypher_query}\")\n",
    "        response = graph.query(cypher_query)\n",
    "\n",
    "        if response:\n",
    "            response = fomulate_response(response, instruction)\n",
    "\n",
    "            return response, cypher_query\n",
    "\n",
    "    return None, cypher_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983014d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: MATCH (l:Layer {name: 'Layer2'})-[:THICKNESS]->(v:Variable)\n",
      "RETURN v.value\n",
      "Successful query: MATCH (l:Layer {name: 'Layer2'})-[:THICKNESS]->(v:Variable)\n",
      "RETURN v.value\n",
      "Query result: Based on the provided graph response, I can extract the necessary information.\n",
      "\n",
      "The graph contains a single entry for Layer2 with a key-value pair of 'value' and '2.728mil'. Since there is only one layer in the graph, we can assume that it is the only thickness value available.\n",
      "\n",
      "Therefore, the return statement would be:\n",
      "\n",
      "`Return: 2.728 mil`\n"
     ]
    }
   ],
   "source": [
    "# Example: Convert a natural language instruction to a Cypher query\n",
    "instruction = \"Return the value of Layer2: thickness.\"\n",
    "\n",
    "result, cypher_query = safe_execute_query(graph, instruction)\n",
    "print(f\"Successful query: {cypher_query}\")\n",
    "print(\"Query result:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
